\chapter{Cơ sở lý thuyết}

\section{Khái niệm về concept drift và phân loại}

\subsection{Định nghĩa concept drift}

Concept drift, hay còn gọi là sự trôi dạt khái niệm, đề cập đến những thay đổi trong phân phối dữ liệu được tạo ra theo thời gian, đặc biệt là trong môi trường động và thay đổi theo thời gian, chẳng hạn như trong ứng dụng về IoT~\cite{ramakrishnan2014enabling}. Cụ thể hơn, sự trôi dạt khái niệm là một vấn đề trong đó các mối quan hệ thống kê giữa các giá trị đầu vào và giá trị mục tiêu bị thay đổi theo thời gian theo cách không thể dự đoán được~\cite{schlimmer1986incremental}.

Sự trôi dạt khái niệm có thể dẫn đến hiệu suất giảm trong quá trình vận hành thực tế của mô hình học máy, điều này trái ngược với hiệu suất được đánh giá trên tập dữ liệu thử nghiệm tĩnh trong quá trình phát triển.

\subsection{Phân loại các loại concept drift}

Có nhiều loại trôi dạt khác nhau, tùy thuộc vào các yếu tố dữ liệu đang thay đổi. Các loại chính của sự trôi dạt khái niệm bao gồm~\cite{sciencedirect2024drift, hovakimyan2024evolving}:

Phân loại theo sự thay đổi phân phối:
\textbf{Sự trôi dạt ảo (Virtual Drift):} Còn được gọi là sự dịch chuyển biến phụ (covariate shift), đề cập đến tình huống mà sự thay đổi xảy ra trong phân phối các trường hợp đầu vào $P(X)$, trong khi xác suất hậu nghiệm của các giá trị mục tiêu $P(Y|X)$ vẫn không đổi~\cite{moreno2012unifying}.

\textbf{Sự trôi dạt thực (Real Drift):} Sự thay đổi trong xác suất hậu nghiệm của các giá trị mục tiêu (tức là các lớp) $P(Y|X)$ được gọi là sự trôi dạt thực. Sự trôi dạt thực có thể không ảnh hưởng đến sự phân phối các trường hợp đầu vào $P(X)$. Ví dụ, người ta có thể đề cập đến sự thay đổi trong sở thích của người dùng khi họ theo dõi các kênh tin tức phát trực tuyến, trong khi sự phân phối các mục tin tức nhận được thường không thay đổi~\cite{gama2014survey}.

Phân loại theo mô hình thay đổi theo thời gian:
\textbf{Sự trôi dạt đột ngột (Abrupt Drift):} Biểu thị trường hợp khi sự phân phối dữ liệu thay đổi đột ngột tại một thời điểm cụ thể. Drift đột ngột dễ nhận biết nhưng đòi hỏi cơ chế phát hiện và thích ứng nhanh để tránh suy giảm hiệu suất nghiêm trọng~\cite{basseville1993detection}.

\textbf{Sự trôi dạt dần dần (Gradual Drift):} Sự trôi dạt dần dần biểu thị trường hợp khi sự phân phối dữ liệu thay đổi dần dần theo thời gian qua một khoảng thời gian chuyển tiếp. Trong giai đoạn chuyển tiếp này, dữ liệu có thể đến từ cả phân phối cũ và phân phối mới với tỷ lệ thay đổi dần~\cite{gama2014survey}.

\textbf{Sự trôi dạt tăng dần (Incremental Drift):} Thể hiện sự tiến hóa dần dần của phân phối dữ liệu theo từng bước nhỏ liên tục. Ví dụ như sự tiến hóa dần dần của hệ thống đề xuất người dùng ngày càng tiến hóa và nhiều hơn dựa trên sự thay đổi sở thích của người dùng theo thời gian~\cite{hovakimyan2024evolving}.

\textbf{Sự trôi dạt lặp lại (Recurrent Drift):} Trôi dạt lặp lại là khi dữ liệu quay trở lại trạng thái cũ sau một thời gian, hoặc lặp lại theo chu kỳ. Những thay đổi trong dữ liệu không phải mới mà đã từng xảy ra trước đó. Ví dụ như xu hướng thời trang thay đổi theo mùa, tuần hoàn theo từng năm~\cite{hovakimyan2024evolving}.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{image/distribution_based_concept_drift.png}
\caption{Phân loại dựa trên sự thay đổi phân phối}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{image/patern_based_concept_drift.png}
\caption{Phân loại dựa trên sự thay đổi theo thời gian}
\end{figure}

\subsection{Ảnh hưởng của concept drift}

Sự trôi dạt khái niệm có thể ảnh hưởng lớn đến hiệu suất của mô hình dự đoán, đặc biệt là khi mô hình học từ luồng dữ liệu. Một loạt các dịch vụ/ứng dụng trong bối cảnh hệ thống và mạng truyền thông có thể bị cản trở bởi sự trôi dạt khái niệm như~\cite{ramakrishnan2014enabling}:

\begin{itemize}
    \item \textbf{Hệ thống phát hiện xâm nhập (IDS):} Các mẫu tấn công mạng liên tục thay đổi, đòi hỏi IDS phải thích ứng với các mối đe dọa mới
    \item \textbf{Hệ thống phân loại và dự đoán lưu lượng:} Mẫu lưu lượng mạng thay đổi theo thời gian, ảnh hưởng đến độ chính xác dự đoán
    \item \textbf{Industrial IoT (IIoT):} Đặc biệt trong các kỹ thuật bảo trì dựa trên tình trạng (Condition-Based Maintenance - CBM) được sử dụng để dự đoán các điều kiện bất thường và thời gian bảo trì thông qua phân tích dữ liệu IIoT~\cite{jourdan2021machine}
    \item \textbf{Thành phố thông minh:} Dữ liệu được thu thập cho nhiều mục đích như đảm bảo an ninh mạng, dự đoán ô nhiễm không khí, dự đoán giao thông đường bộ và dự báo tải điện
\end{itemize}

Sự phân phối các mẫu lỗi có thể thay đổi theo thời gian do máy móc lão hóa và quy trình bảo trì. Do đó, một kỹ thuật CBM không có khả năng xử lý sự trôi dạt khái niệm sẽ hoạt động kém~\cite{jourdan2021machine}. Thật vậy, sự trôi dạt khái niệm có thể ảnh hưởng đến hiệu quả và tính mạnh mẽ của phân tích luồng dữ liệu~\cite{tripathi2021ensuring}.

Trong môi trường không cố định, có một số cân nhắc mà các mô hình dự đoán phải tính đến để phát hiện và tự thích ứng với sự trôi dạt khái niệm, nếu không, hiệu suất của các mô hình này sẽ giảm sút về độ chính xác và độ mạnh mẽ. Theo thời gian, một mô hình dự đoán có thể cần cập nhật các tham số và cấu trúc của nó bằng cách kết hợp các dữ liệu huấn luyện mới hoặc thay thế hoàn toàn mô hình cũ để xử lý sự trôi dạt khái niệm.

\section{Cách tiếp cận nghiên cứu}

Chương này trình bày khung phương pháp luận để điều tra phát hiện concept drift sử dụng phương pháp Shape Drift Detector (ShapeDD). Nghiên cứu này tập trung vào việc hiểu các nền tảng lý thuyết của ShapeDD, triển khai thuật toán cho các kịch bản drift khác nhau, và thực hiện đánh giá thực nghiệm toàn diện để đánh giá hiệu quả của nó trên các loại concept drift khác nhau.

Phương pháp luận nghiên cứu bao gồm ba thành phần chính: (1) phân tích lý thuyết của thuật toán ShapeDD và các nền tảng Maximum Mean Discrepancy (MMD) cơ bản, (2) triển khai và tối ưu hóa hệ thống phát hiện cho các bộ dữ liệu tổng hợp và thực tế, và (3) đánh giá thực nghiệm toàn diện trên các mẫu drift và cấu hình tham số khác nhau.

\section{Nền tảng lý thuyết của Shape Drift Detector}

\subsection{Maximum Mean Discrepancy (MMD)}

Shape Drift Detector (ShapeDD) dựa trên Maximum Mean Discrepancy (MMD)~\cite{gretton2012kernel}, một thước đo thống kê được sử dụng để so sánh hai phân phối xác suất $P$ và $Q$. Ý tưởng cốt lõi là ánh xạ dữ liệu từ không gian gốc vào không gian feature cao chiều nơi việc so sánh trở nên nhạy cảm hơn với sự khác biệt phân phối.

\subsubsection{Định nghĩa và intuition}

MMD đo lường khoảng cách giữa hai phân phối bằng cách tìm hàm $f$ có thể phân biệt tốt nhất giữa chúng. Nếu hai phân phối giống nhau, giá trị kỳ vọng của bất kỳ hàm nào áp dụng lên chúng sẽ giống nhau. Ngược lại, nếu khác nhau, sẽ tồn tại một hàm cho phép phân biệt rõ ràng.

MMD được định nghĩa chính thức như:
\begin{equation}
\text{MMD}(P, Q) = \sup_{f \in \mathcal{F}} \left| \mathbb{E}_{X \sim P}[f(X)] - \mathbb{E}_{Y \sim Q}[f(Y)] \right|
\end{equation}

trong đó:
\begin{itemize}
    \item $P$ và $Q$ là hai phân phối cần được so sánh
    \item $X \sim P$ đại diện cho biến ngẫu nhiên được lấy mẫu từ phân phối $P$
    \item $Y \sim Q$ đại diện cho biến ngẫu nhiên được lấy mẫu từ phân phối $Q$
    \item $\mathcal{F}$ là một lớp hàm $f$ sao cho $\|f\|_{\mathcal{H}} \leq 1$ trong Reproducing Kernel Hilbert Space (RKHS)~\cite{scholkopf2002learning}
    \item $\sup$ biểu thị supremum (cận trên nhỏ nhất)
\end{itemize}

\textbf{Intuition:} Trong không gian ban đầu, hai phân phối có thể khó phân biệt. Bằng cách ánh xạ vào RKHS thông qua hàm kernel~\cite{scholkopf2002learning}, các cấu trúc phức tạp của phân phối trở nên rõ ràng hơn. MMD đo lường khoảng cách giữa "trung bình" (mean embedding) của hai phân phối trong không gian này.

\subsubsection{Kernel trick và RKHS}

Trong thực tế, việc tìm supremum trên $\mathcal{F}$ là không khả thi về mặt tính toán. Do đó, MMD thường được triển khai trong RKHS~\cite{scholkopf2002learning} sử dụng kernel trick với hàm kernel $k(x, y)$:

\begin{equation}
k(x, y) = \langle \phi(x), \phi(y) \rangle_{\mathcal{H}}
\end{equation}

trong đó $\phi(x)$ ánh xạ điểm $x$ vào RKHS $\mathcal{H}$ và $\langle \cdot, \cdot \rangle_{\mathcal{H}}$ là tích vô hướng trong $\mathcal{H}$.

\textbf{Lựa chọn kernel phổ biến:} Gaussian RBF kernel được sử dụng rộng rãi nhất do tính chất universal (có thể xấp xỉ bất kỳ hàm liên tục nào):

\begin{equation}
k(x, y) = \exp\left(-\frac{\|x - y\|^2}{2\sigma^2}\right)
\end{equation}

Tham số $\sigma$ (bandwidth) điều khiển độ nhạy: giá trị nhỏ tập trung vào sự khác biệt cục bộ, giá trị lớn nắm bắt cấu trúc toàn cục.

\subsubsection{Công thức tính toán}

MMD bình phương trong RKHS trở thành:
\begin{equation}
\text{MMD}^2(P, Q) = \mathbb{E}_{X, X' \sim P}[k(X, X')] + \mathbb{E}_{Y, Y' \sim Q}[k(Y, Y')] - 2\mathbb{E}_{X \sim P, Y \sim Q}[k(X, Y)]
\end{equation}

\textbf{Giải thích ba thành phần:}
\begin{itemize}
    \item \textbf{Thành phần 1:} $\mathbb{E}_{X, X' \sim P}[k(X, X')]$ - độ tương đồng trung bình giữa các điểm trong phân phối $P$
    \item \textbf{Thành phần 2:} $\mathbb{E}_{Y, Y' \sim Q}[k(Y, Y')]$ - độ tương đồng trung bình giữa các điểm trong phân phối $Q$
    \item \textbf{Thành phần 3:} $-2\mathbb{E}_{X \sim P, Y \sim Q}[k(X, Y)]$ - độ tương đồng chéo giữa hai phân phối (có dấu âm)
\end{itemize}

Nếu $P = Q$, ba thành phần này cân bằng nhau và $\text{MMD}^2 = 0$. Nếu $P \neq Q$, sự khác biệt trong cấu trúc nội bộ và tương tác chéo dẫn đến $\text{MMD}^2 > 0$.

\subsubsection{Ước lượng thực nghiệm}

Để ước tính thực nghiệm với mẫu $\{x_i\}_{i=1}^n$ từ $P$ và $\{y_j\}_{j=1}^m$ từ $Q$:

\begin{equation}
\widehat{\text{MMD}}^2 = \frac{1}{n(n-1)} \sum_{i \neq j} k(x_i, x_j) + \frac{1}{m(m-1)} \sum_{i \neq j} k(y_i, y_j) - \frac{2}{nm} \sum_{i,j} k(x_i, y_j)
\end{equation}

\textbf{Tính chất thống kê:} $\widehat{\text{MMD}}^2$ là unbiased estimator của $\text{MMD}^2$ với phương sai giảm theo tốc độ $O(1/n + 1/m)$ khi kích thước mẫu tăng.

\textbf{Ví dụ minh họa:} Xét hai phân phối 1D:
\begin{itemize}
    \item $P = \mathcal{N}(0, 1)$ - phân phối chuẩn tâm 0, phương sai 1
    \item $Q = \mathcal{N}(2, 1)$ - phân phối chuẩn tâm 2, phương sai 1
\end{itemize}

Với Gaussian kernel ($\sigma = 1$), MMD sẽ nắm bắt được sự dịch chuyển trung bình (mean shift) giữa hai phân phối. Khi $n, m \to \infty$, $\widehat{\text{MMD}}^2$ hội tụ về giá trị dương phản ánh khoảng cách thực giữa $P$ và $Q$.

\subsection{Các phương pháp phát hiện drift cơ bản}

Các phương pháp phát hiện drift cơ bản đã được trình bày chi tiết trong Chương 2. Để cung cấp ngữ cảnh cho ShapeDD, chúng ta tóm tắt ngắn gọn các đặc điểm chính:

\textbf{Phương pháp dựa trên hiệu suất mô hình:} DDM, EDDM, MDDM, FHDDMS theo dõi các thống kê lỗi của mô hình và phát hiện drift khi hiệu suất giảm đáng kể. Các phương pháp này phụ thuộc vào nhãn ground truth và có thể bị trễ trong việc phát hiện do cần thu thập đủ lỗi.

\textbf{Phương pháp dựa trên cửa sổ thích ứng:} ADWIN điều chỉnh động kích thước cửa sổ dựa trên sự thay đổi được quan sát, đạt được cân bằng giữa độ nhạy và ổn định với đảm bảo lý thuyết $O(\log W)$ về bộ nhớ.

\textbf{Phương pháp dựa trên độc lập thống kê:} DAWIDD phát hiện drift thông qua việc đo lường sự phụ thuộc giữa features và thời gian, cho phép phát hiện sớm mà không cần nhãn.

So với các phương pháp này, ShapeDD mang lại góc nhìn khác biệt bằng cách sử dụng Maximum Mean Discrepancy (MMD) để so sánh trực tiếp phân phối dữ liệu trong không gian kernel, kết hợp với kỹ thuật phát hiện hình dạng (shape detection) để giảm nhiễu và tăng độ chính xác định vị drift.

\subsection{Thuật toán Shape Drift Detector}

Shape Drift Detector (ShapeDD)~\cite{hinder2024survey_partA} là một detector drift dựa trên meta-statistic hoạt động thông qua quá trình đa giai đoạn để xác định concept drift trong luồng dữ liệu. Thuật toán sử dụng MMD như thước đo thống kê cốt lõi và theo một cách tiếp cận có hệ thống bao gồm bốn giai đoạn chính. Điểm mạnh của ShapeDD nằm ở khả năng lọc nhiễu thông qua việc phát hiện "hình dạng" (shape) đặc trưng của drift trong chuỗi thống kê MMD.

\subsubsection{Động lực và ý tưởng cốt lõi}

Nhiều phương pháp phát hiện drift truyền thống dựa trên việc đo lường độ lệch giữa phân phối mẫu trong hai cửa sổ thời gian liên tiếp (ví dụ: cửa sổ hiện tại và cửa sổ tham chiếu). Tuy nhiên, do số lượng mẫu trong mỗi cửa sổ thường hạn chế, phép đo độ lệch này có nhiễu đáng kể – khó phân biệt được sự khác biệt do drift thực sự gây ra so với dao động ngẫu nhiên bên trong phân phối.

\textbf{Cốt lõi của ShapeDD} nằm ở việc khai thác đặc trưng hình dạng của tín hiệu drift để nhận biết điểm thay đổi. Phương pháp sử dụng khái niệm \textit{độ lớn drift} (drift magnitude) $\sigma_{d,l}(t)$ được định nghĩa:

\begin{equation}
\sigma_{d,l}(t) = d\Big(p_{[t-2l,t-l]},\,p_{[t-l,t]}\Big)
\label{eq:drift-magnitude-core}
\end{equation}

trong đó $p_{[a,b]}$ là phân phối dữ liệu trung bình trên đoạn thời gian $[a,b]$, và $d(\cdot,\cdot)$ là một độ đo khoảng cách giữa hai phân phối (ví dụ: MMD, khoảng cách Hellinger, KL divergence).

\textbf{Hình dạng tam giác đặc trưng:} Khi xảy ra drift đột ngột tại thời điểm $t_0$, độ lớn drift $\sigma(t)$ có hình dạng đặc trưng dạng tam giác: tăng lên rồi giảm xuống trong khoảng thời gian tương ứng với độ dài cửa sổ $l$. Với drift đột ngột thay đổi phân phối từ $P$ sang $Q$ tại $t_0=0$, lý thuyết chỉ ra:

\begin{equation}
\sigma(t) = \lVert P - Q \rVert \cdot \max\left(0,\,1 - \frac{|\,l - t\,|}{\,l\,}\right)
\label{eq:triangle-shape-core}
\end{equation}

với $\lVert P - Q\rVert$ là độ lớn thay đổi phân phối và phần hình dạng $h_l(t) = \max(0,\,1 - |l-t|/l)$ chỉ phụ thuộc vào $l$. Biểu thức này mô tả một "mũi nhọn" hình tam giác: $\sigma(t)$ bằng 0 ngoài khoảng $[0,2l]$, đạt cực đại tại $t = l$ (đúng một độ dài cửa sổ sau thời điểm drift), và thay đổi tuyến tính giữa 0 và đỉnh.

\textbf{Bộ lọc hình dạng:} Để phát hiện mẫu tam giác này, ShapeDD sử dụng bộ lọc trọng số $h'_l(t)$ (đạo hàm của $h_l$):

\begin{equation}
h'_l(t) = \begin{cases}
+1, & t \in [0, l) \\
-1, & t \in (l, 2l] \\
0, & \text{ngoài } [0,2l]
\end{cases}
\end{equation}

Khi tích chập $\hat{\sigma}(t)$ với $h'_l$, tại vùng quanh drift thật, kết quả tạo thành hàm có đoạn dương rồi đoạn âm. Thời điểm đổi dấu từ dương sang âm chính là vị trí drift $t_0$ cần tìm. Nhờ việc khớp hàm dạng tham số $h_l$, chuỗi tín hiệu drift được "nén" lại chỉ còn vài tham số ($t_0$ và biên độ $s$ cho mỗi sự kiện), giảm thiểu ảnh hưởng nhiễu dao động cục bộ.

\subsubsection{Giai đoạn 1: Thu thập dữ liệu (Data Collection)}

Giai đoạn đầu tiên bao gồm thu thập dữ liệu sử dụng kỹ thuật cửa sổ trượt. ShapeDD sử dụng chiến lược cửa sổ đôi (double window) với kích thước $2l_1$ để so sánh hai đoạn dữ liệu liên tiếp:

\begin{itemize}
    \item \textbf{Cửa sổ tham chiếu}: $l_1$ điểm dữ liệu đầu tiên $[t-2l_1+1, t-l_1]$
    \item \textbf{Cửa sổ hiện tại}: $l_1$ điểm dữ liệu tiếp theo $[t-l_1+1, t]$
\end{itemize}

Đối với luồng dữ liệu $\mathcal{S} = \{x_1, x_2, \ldots, x_n\}$, chúng ta duy trì cửa sổ trượt $W_t$ có kích thước tổng cộng $2l_1$ tại thời điểm $t$:
\begin{equation}
W_t = \{x_{t-2l_1+1}, x_{t-2l_1+2}, \ldots, x_t\}
\end{equation}

\textbf{Lựa chọn kích thước cửa sổ $l_1$:} Đây là tham số quan trọng nhất của ShapeDD:
\begin{itemize}
    \item $l_1$ nhỏ (50-100): Nhạy với drift nhanh nhưng dễ bị nhiễu
    \item $l_1$ trung bình (200-500): Cân bằng giữa độ nhạy và ổn định
    \item $l_1$ lớn (>500): Ổn định nhưng trễ phát hiện cao
    \item \textbf{Adaptive sizing}: $l_1 = \alpha \times \text{stream\_length}$ với $\alpha \in [0.03, 0.10]$ điều chỉnh tự động theo độ dài luồng
\end{itemize}

\subsubsection{Giai đoạn 2: Xây dựng feature (Feature Construction)}

Trong giai đoạn này, chúng ta xây dựng ma trận tương đồng (similarity matrix) sử dụng hàm kernel để nắm bắt mối quan hệ giữa các điểm dữ liệu. Gaussian RBF kernel thường được sử dụng:

\begin{equation}
k(x_i, x_j) = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right)
\end{equation}

Điều này tạo ra ma trận kernel đối xứng $K \in \mathbb{R}^{2l_1 \times 2l_1}$ trong đó $K_{ij} = k(x_i, x_j)$ biểu thị sự tương đồng giữa các điểm dữ liệu $x_i$ và $x_j$.

\textbf{Lựa chọn bandwidth $\sigma$:} Có thể sử dụng median heuristic để tự động chọn $\sigma$:
\begin{equation}
\sigma = \text{median}\left(\{\|x_i - x_j\| : i, j \in W_t, i \neq j\}\right)
\end{equation}

Phương pháp này đảm bảo kernel thích nghi với scale của dữ liệu.

\textbf{Hiệu quả tính toán:} Ma trận kernel có thể được cập nhật tăng dần khi cửa sổ trượt:
\begin{itemize}
    \item Tính toán đầy đủ: $O(l_1^2)$ cho mỗi cửa sổ
    \item Cập nhật tăng dần: Chỉ cần tính $O(l_1)$ phần tử mới khi thêm điểm dữ liệu
\end{itemize}

\subsubsection{Giai đoạn 3: Tính toán sự khác biệt (Difference Computation)}

Cốt lõi của ShapeDD bao gồm tính toán sự khác biệt thống kê giữa hai nửa của cửa sổ trượt sử dụng MMD có trọng số. Chúng ta định nghĩa hàm trọng số $w(t)$ tạo ra trọng số tương phản (+1 và -1) cho hai nửa của cửa sổ:

\begin{equation}
w(t) = \begin{cases}
+\frac{1}{l_1} & \text{nếu } t \in [1, l_1] \quad \text{(cửa sổ tham chiếu)} \\
-\frac{1}{l_1} & \text{nếu } t \in [l_1+1, 2l_1] \quad \text{(cửa sổ hiện tại)}
\end{cases}
\end{equation}

Thống kê MMD có trọng số sau đó được tính như:
\begin{equation}
\text{MMD}^2_t = \sum_{i,j=1}^{2l_1} w_i w_j K_{ij}
\end{equation}

\textbf{Giải thích công thức:} Khai triển ra, ta có:
\begin{align}
\text{MMD}^2_t = &\frac{1}{l_1^2} \sum_{i,j=1}^{l_1} K_{ij} \quad \text{(tương đồng trong cửa sổ tham chiếu)} \nonumber \\
+ &\frac{1}{l_1^2} \sum_{i,j=l_1+1}^{2l_1} K_{ij} \quad \text{(tương đồng trong cửa sổ hiện tại)} \nonumber \\
- &\frac{2}{l_1^2} \sum_{i=1}^{l_1} \sum_{j=l_1+1}^{2l_1} K_{ij} \quad \text{(tương đồng chéo)}
\end{align}

Đây chính là công thức MMD giữa hai phân phối được định nghĩa bởi hai nửa cửa sổ.

Tính toán này được thực hiện trên toàn bộ luồng dữ liệu sử dụng phương pháp cửa sổ trượt, tạo ra chuỗi thời gian các giá trị MMD: $\{\text{MMD}^2_1, \text{MMD}^2_2, \ldots, \text{MMD}^2_T\}$.

\textbf{Ý nghĩa của chuỗi MMD:} Khi drift xảy ra tại thời điểm $t_d$:
\begin{itemize}
    \item Trước drift ($t < t_d - l_1$): Cả hai nửa cửa sổ đều từ phân phối cũ $\Rightarrow$ $\text{MMD}^2_t \approx 0$
    \item Tại drift ($t_d - l_1 \leq t \leq t_d$): Cửa sổ tham chiếu từ phân phối cũ, cửa sổ hiện tại từ phân phối mới $\Rightarrow$ $\text{MMD}^2_t$ tăng mạnh
    \item Sau drift ($t > t_d + l_1$): Cả hai nửa đều từ phân phối mới $\Rightarrow$ $\text{MMD}^2_t \approx 0$
\end{itemize}

Điều này tạo ra hình dạng tam giác (triangular shape) đặc trưng trong chuỗi MMD tại vị trí drift.

\subsubsection{Giai đoạn 4: Xác thực thống kê (Statistical Validation)}

Giai đoạn cuối cùng bao gồm hai bước: phát hiện hình dạng (shape detection) và xác thực thống kê.

\textbf{Bước 4.1: Shape Detection qua Convolution}

Để phát hiện hình dạng tam giác, ShapeDD sử dụng bộ lọc convolution $h'_l$ được thiết kế để nhạy với biên tăng-giảm:

\begin{equation}
h'_l(t) = \begin{cases}
+1 & \text{nếu } t \in [0, l] \\
-1 & \text{nếu } t \in (l, 2l]
\end{cases}
\end{equation}

Tín hiệu shape được tính bằng convolution:
\begin{equation}
\text{shape}_t = (h'_l * \text{MMD}^2)(t) = \sum_{i=0}^{2l} h'_l(i) \cdot \text{MMD}^2_{t-i}
\end{equation}

\textbf{Zero-crossing detection:} Drift candidate được xác định khi tín hiệu shape đổi dấu (từ dương sang âm hoặc ngược lại):
\begin{equation}
\text{Candidate}(t) = \text{sign}(\text{shape}_t) \neq \text{sign}(\text{shape}_{t-1})
\end{equation}

\textbf{Bước 4.2: Permutation Test}

Mỗi drift candidate được xác thực bằng permutation test~\cite{good2005permutation} để loại bỏ false positive:

\begin{enumerate}
    \item Tính $\text{MMD}^2_{\text{obs}}$ từ dữ liệu gốc tại vị trí candidate
    \item Lặp $N_{\text{perm}}$ lần (thường 1000-5000):
    \begin{enumerate}
        \item Hoán vị ngẫu nhiên nhãn của hai nửa cửa sổ
        \item Tính $\text{MMD}^2_{\text{perm}}$ với dữ liệu hoán vị
    \end{enumerate}
    \item Tính p-value:
    \begin{equation}
    p\text{-value} = \frac{\#\{\text{MMD}^2_{\text{perm}} \geq \text{MMD}^2_{\text{obs}}\}}{N_{\text{perm}}}
    \end{equation}
    \item Nếu $p\text{-value} < \alpha$ (thường $\alpha = 0.05$), chấp nhận drift
\end{enumerate}

\textbf{Tại sao permutation test hiệu quả?} Nếu không có drift thực sự, việc hoán vị nhãn không nên thay đổi nhiều $\text{MMD}^2$. Nếu có drift, $\text{MMD}^2_{\text{obs}}$ sẽ lớn hơn đáng kể so với các giá trị permutation.

\textbf{Độ phức tạp tính toán:} Permutation test là bước tốn thời gian nhất: $O(N_{\text{perm}} \cdot l_1^2)$. Tuy nhiên, vì chỉ áp dụng cho các candidate (không phải mọi thời điểm), chi phí trung bình vẫn chấp nhận được.

\subsubsection{Ưu điểm nổi bật của ShapeDD}

ShapeDD mang lại một số ưu điểm quan trọng so với các phương pháp phát hiện drift truyền thống:

\begin{enumerate}
    \item \textbf{Khử nhiễu và giảm báo động giả:} Nhờ cơ chế lọc shape, ShapeDD giảm đáng kể số lần báo động sai do nhiễu thống kê. Thay vì phản ứng với mọi dao động nhỏ trong tín hiệu, phương pháp chỉ tập trung vào các biến động có hình dạng phù hợp với drift thật. Kết quả thực nghiệm cho thấy ShapeDD giảm trung bình khoảng \textbf{20 lần báo động giả} so với phương pháp dùng trực tiếp MMD không lọc shape, chứng tỏ tính ổn định vượt trội trong môi trường nhiều nhiễu.

    \item \textbf{Độ chính xác định vị cao:} ShapeDD có khả năng xác định chính xác thời điểm xảy ra drift. Nhờ việc khớp dạng tam giác, phương pháp định vị điểm thay đổi gần như trùng khớp với vị trí drift thực (sai lệch chỉ khoảng $\pm l$ hoặc ít hơn, có thể hiệu chỉnh). Trong khi nhiều phương pháp cửa sổ đôi khác chỉ báo động đang có drift trong một khoảng nào đó, ShapeDD cung cấp trực tiếp thời điểm drift với độ trễ rất nhỏ.

    \item \textbf{Hiệu suất phát hiện cao:} Trên các bộ dữ liệu chuẩn (như SEA, STAGGER, Hyperplane) và dữ liệu thực tế, ShapeDD đạt hiệu năng phát hiện drift tương đương hoặc cao hơn các thuật toán đầu bảng. Chỉ số $\beta$-score (tỷ lệ TP/FP có trọng số) của ShapeDD thường vượt trội so với phương pháp so sánh. Đặc biệt, ShapeDD luôn vượt hơn phương pháp MMD thuần và phương pháp drift magnitude truyền thống về mọi mặt.

    \item \textbf{Thích ứng với nhiều kịch bản drift:} Mặc dù giả định lý thuyết ban đầu tập trung vào drift đột ngột, ShapeDD trong thực nghiệm tỏ ra linh hoạt trước nhiều kiểu drift khác nhau. Nhờ việc có thể kết hợp nhiều độ dài cửa sổ và nhiều độ đo, phương pháp có thể bắt được cả những thay đổi nhanh lẫn chậm. ShapeDD thừa hưởng tính chất phát hiện chắc chắn (surely detecting): nếu drift đủ rõ ràng và tách biệt, phương pháp đảm bảo sẽ phát hiện nhờ tính hợp lệ thống kê của kiểm định kernel two-sample.

    \item \textbf{Tính toán hiệu quả:} Thuật toán ShapeDD được triển khai tối ưu để chạy online với chi phí tuyến tính $O(l)$ theo kích thước cửa sổ trên mỗi mẫu mới. Việc tận dụng tích chập qua cumulative sum giúp tìm điểm drift trong một lượt quét mà không cần thuật toán tối ưu phức tạp lặp đi lặp lại. ShapeDD đủ nhẹ để áp dụng trong thời gian thực trên luồng dữ liệu tốc độ cao.
\end{enumerate}

\subsubsection{Hạn chế và điều kiện áp dụng hiệu quả}

Bên cạnh ưu điểm, ShapeDD cũng có một số hạn chế và điều kiện cần lưu ý:

\begin{itemize}
    \item \textbf{Giả định drift rời rạc và đột ngột:} Lý thuyết hình dạng của ShapeDD giả định mỗi khoảng thời gian chỉ có tối đa một sự kiện drift rõ ràng. Nếu các drift xảy ra liên tục hoặc quá gần nhau (khoảng cách giữa hai lần thay đổi nhỏ hơn độ dài $2l$ của cửa sổ), các mẫu hình tam giác có thể chồng lấn khiến bộ lọc shape không còn nhận dạng đúng được. ShapeDD phù hợp nhất khi các thay đổi lớn diễn ra cách nhau một khoảng đủ dài so với $l$.

    \item \textbf{Hạn chế với drift liên tục (gradual drift):} Trong trường hợp concept drift xảy ra một cách từ từ liên tục (ví dụ mô hình trôi nhẹ dần theo thời gian không có điểm cắt rạch ròi), hình dạng tam giác đặc trưng sẽ không còn rõ nét. Nếu phân phối thay đổi dần, tín hiệu $\sigma(t)$ sẽ không tạo thành mũi nhọn mà chỉ nhô lên rất thoải, khiến cách tiếp cận shape có thể kém nhạy hoặc phải đợi đến khi đủ lớn mới báo (dẫn tới trễ). ShapeDD phát huy tốt nhất với các drift kiểu đột ngột hoặc giai đoạn (sudden/step drift).

    \item \textbf{Lựa chọn độ dài cửa sổ $l$:} Hiệu quả của ShapeDD phụ thuộc vào tham số $l$. Nếu $l$ quá nhỏ, ước lượng $\hat{\sigma}(t)$ rất nhiễu, khiến khớp shape khó phân biệt tín hiệu; ngược lại nếu $l$ quá lớn, hiệu ứng drift bị làm mờ và còn gây tăng độ trễ phát hiện. Một giải pháp an toàn là kết hợp nhiều $l$ như ShapeDD đề xuất sẵn, nhằm đảm bảo không bỏ sót. Tuy nhiên, việc dùng nhiều cửa sổ cũng làm tăng chi phí tính toán và độ phức tạp triển khai.

    \item \textbf{Tham số kiểm định và ngưỡng:} ShapeDD yêu cầu đặt ngưỡng cho kiểm định (mức ý nghĩa $\alpha$) và ngưỡng cho biên độ $s$. Nếu đặt ngưỡng quá cao (nghiêm ngặt), phương pháp có thể bỏ lỡ những drift nhẹ; nếu đặt quá thấp, sẽ tăng nguy cơ báo động giả. Việc chọn các ngưỡng này cần hiệu chỉnh cẩn thận, thường thông qua cross-validation hoặc dựa vào chỉ số đánh giá tổng hợp như $\beta$-score.

    \item \textbf{Trường hợp dữ liệu nhiều chiều phức tạp:} Mặc dù MMD với kernel Gaussian có ưu điểm không phụ thuộc số chiều, nhưng trong thực tế khi phân phối thay đổi chỉ trên một phần không gian đặc trưng, hoặc drift chỉ ảnh hưởng một vài thuộc tính, thì việc phát hiện có thể khó khăn hơn (tín hiệu drift yếu vì khoảng cách toàn cục nhỏ). Khi đó, có thể cần kết hợp ShapeDD với phương pháp lựa chọn đặc trưng hoặc kiểm định theo từng chiều.
\end{itemize}

\subsubsection{So sánh với các phương pháp phát hiện drift khác}

\textbf{ShapeDD vs DDM:} DDM (Drift Detection Method) là phương pháp giám sát lỗi phân loại theo thời gian và đưa ra cảnh báo drift khi tỷ lệ lỗi tăng vượt ngưỡng dựa trên mô hình Bernoulli. So với DDM, ShapeDD có những khác biệt quan trọng:
\begin{itemize}
    \item ShapeDD hoạt động \textit{không cần nhãn} (unsupervised), trực tiếp phát hiện thay đổi phân phối dữ liệu thay vì chờ sai số mô hình tăng. DDM chỉ hữu dụng trong bối cảnh giám sát (supervised) và phụ thuộc vào chất lượng mô hình hiện tại.
    \item Về độ chính xác thời gian, ShapeDD thường xác định điểm drift \textit{nhanh và chính xác hơn}. DDM có xu hướng phát hiện muộn – nó đợi đủ bằng chứng sai số tăng mới kích hoạt. ShapeDD phản ứng ngay khi phân phối bắt đầu lệch, chỉ lệch khoảng nửa độ dài cửa sổ $l$.
    \item ShapeDD khắc phục được vấn đề nhiễu và không phụ thuộc trực tiếp vào hiệu năng mô hình, trong khi DDM có thể nhạy cảm với các dao động ngẫu nhiên trong lỗi.
\end{itemize}

\textbf{ShapeDD vs ADWIN:} ADWIN (Adaptive Windowing) là phương pháp dựa trên trượt cửa sổ với kích thước thay đổi thích ứng. ADWIN luôn duy trì một cửa sổ dữ liệu có thể mở rộng, và thu hẹp lại khi kiểm định thống kê phát hiện phân phối ở đầu và cuối cửa sổ khác nhau đáng kể.
\begin{itemize}
    \item Ưu điểm của ShapeDD so với ADWIN là \textit{giảm thiểu kiểm định nhiều lần}: ADWIN phải kiểm tra rất nhiều điểm cắt có thể trong cửa sổ lớn, dễ gặp vấn đề multiple testing làm tăng xác suất báo sai. ShapeDD chỉ xem xét vài điểm ứng viên do shape filter chọn lọc, giảm hẳn nguy cơ báo trùng lặp hoặc báo giả liên tục.
    \item ShapeDD cho phép \textit{định vị chính xác} điểm drift (cung cấp trực tiếp $t_0$), còn ADWIN thường chỉ biết "một thay đổi đã xảy ra" và phải ước lượng điểm cắt – độ chính xác có thể kém hơn.
    \item Về khả năng thích ứng, ADWIN nổi bật trong xử lý drift dần dần: nó có thể từ từ thu hẹp/gia tăng cửa sổ. Trong tình huống drift đột ngột, ADWIN thường phải chờ tích lũy đủ bằng chứng, nên có thể trễ hơn ShapeDD.
\end{itemize}

\textbf{ShapeDD vs HDDM:} HDDM (Hellinger Distance Drift Detection) sử dụng khoảng cách Hellinger tích lũy để phát hiện drift. Kết quả so sánh với HDDM cho thấy ShapeDD thường cho $\beta$-score cao hơn, đặc biệt trong trường hợp nhiễu lớn (HDDM có thể báo nhiều false positive hơn). Tuy nhiên, HDDM trong một số trường hợp phát hiện được drift nhỏ tốt hơn (vì tích lũy dần dần), dẫn đến xác suất phát hiện nhỉnh hơn khi cửa sổ rất nhỏ.

\textbf{Đánh giá tổng quát:} Điểm độc đáo của ShapeDD là khai thác cấu trúc hình dạng lý thuyết của tín hiệu drift – một khía cạnh mà hầu hết phương pháp khác chưa tận dụng. Nhờ đó, ShapeDD đạt được cân bằng tốt giữa độ nhạy và độ đặc hiệu: nhạy vì dùng các độ đo mạnh như MMD, đặc hiệu vì yêu cầu khuôn dạng đặc trưng mới báo động. Trên tổng thể nhiều bộ dữ liệu, ShapeDD được đánh giá cao nhờ ổn định và chính xác, đặc biệt về phương diện giảm thiểu báo động sai và định vị đúng thời điểm thay đổi.

\section{Thuật toán phát hiện drift cải tiến}

\subsection{ShapeDD SNR-Adaptive: Phương pháp hybrid thích ứng với tỷ lệ tín hiệu-nhiễu}

Phần này trình bày phương pháp cải tiến ShapeDD SNR-Adaptive - một đóng góp nghiên cứu chính của luận văn này. Phương pháp này mở rộng ShapeDD gốc bằng cách tự động điều chỉnh chiến lược phát hiện dựa trên đặc trưng Signal-to-Noise Ratio (SNR) của môi trường dữ liệu.

\subsubsection{Phát hiện quan trọng: Ảnh hưởng của tỷ lệ tín hiệu-nhiễu (SNR)}

Qua quá trình thử nghiệm và đánh giá với nhiều tập dữ liệu khác nhau, Nghiên cứu phát hiện một kết quả quan trọng: \textbf{không có chiến lược phát hiện drift duy nhất là tối ưu cho mọi môi trường SNR}.

Kết quả thực nghiệm cho thấy:

\textbf{Môi trường SNR cao} (tín hiệu drift mạnh, nhiễu thấp):
\begin{itemize}
    \item Phương pháp ShapeDD\_Adaptive\_v2 với ngưỡng tích cực (aggressive) đạt hiệu suất cao nhất
    \item Đạt recall cao bằng cách phát hiện được tất cả các sự kiện drift với ít báo động giả
    \item Ví dụ: enhanced\_sea (F1=0.947), stagger (F1=0.952)
\end{itemize}

\textbf{Môi trường SNR thấp} (tín hiệu drift yếu, nhiễu cao):
\begin{itemize}
    \item Phương pháp ShapeDD gốc với ngưỡng bảo thủ (conservative) vượt trội
    \item Đạt precision cao bằng cách chờ tín hiệu rõ ràng vượt ngưỡng nhiễu
    \item Ví dụ: gen\_random\_mild (F1=0.842), gen\_random\_moderate (F1=0.900)
\end{itemize}

\subsubsection{Nền tảng lý thuyết: Lý thuyết phát hiện tín hiệu}

Kết quả này phản ánh một nguyên lý cơ bản trong lý thuyết phát hiện tín hiệu (Signal Detection Theory) và tiêu chuẩn Neyman-Pearson~\cite{neyman1933problem}:

\begin{equation}
\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}
\end{equation}

trong đó:
\begin{itemize}
    \item $\sigma^2_{\text{signal}}$: phương sai của tín hiệu drift (độ biến thiên giữa các cửa sổ)
    \item $\sigma^2_{\text{noise}}$: phương sai nhiễu nội tại trong dữ liệu
\end{itemize}

\textbf{Đánh đổi Precision-Recall theo SNR:}

\begin{itemize}
    \item \textbf{Ngưỡng tích cực (thấp):}
    \begin{itemize}
        \item Recall cao (phát hiện nhiều drift)
        \item Nguy cơ báo động giả trên nhiễu (False Positive tăng)
        \item Phù hợp khi SNR cao
    \end{itemize}

    \item \textbf{Ngưỡng bảo thủ (cao):}
    \begin{itemize}
        \item Precision cao (ít báo động giả)
        \item Nguy cơ bỏ lỡ tín hiệu yếu (False Negative tăng)
        \item Phù hợp khi SNR thấp
    \end{itemize}
\end{itemize}

\subsubsection{Giải pháp: Phương pháp hybrid thích ứng SNR}

Để khắc phục hạn chế của các chiến lược đơn lẻ, Luận văn đề xuất phương pháp \textbf{ShapeDD SNR-Adaptive} - một thuật toán hybrid tự động chọn chiến lược phát hiện dựa trên SNR ước lượng của môi trường:

\textbf{Thuật toán ước lượng SNR:}

\begin{algorithm}[H]
\caption{Ước lượng SNR từ luồng dữ liệu}
\begin{algorithmic}[1]
\REQUIRE Dữ liệu $X$, kích thước cửa sổ $w$, số mẫu $k$
\ENSURE Ước lượng SNR
\STATE Chia $X$ thành $k$ cửa sổ kích thước $w$
\STATE Tính trung bình mỗi cửa sổ: $\mu_1, \mu_2, ..., \mu_k$
\STATE Tính phương sai giữa các cửa sổ: $\sigma^2_{\text{signal}} = \text{Var}(\mu_1, ..., \mu_k)$
\STATE Tính phương sai trung bình trong mỗi cửa sổ: $\sigma^2_{\text{noise}} = \frac{1}{k}\sum_{i=1}^{k}\text{Var}(X_i)$
\RETURN $\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}$
\end{algorithmic}
\end{algorithm}

\textbf{Logic lựa chọn chiến lược:}

\begin{algorithm}[H]
\caption{ShapeDD SNR-Adaptive}
\begin{algorithmic}[1]
\REQUIRE Dữ liệu $X$, ngưỡng SNR $\tau$, độ nhạy $s$
\ENSURE Kết quả phát hiện drift
\STATE $\text{SNR}_{\text{est}} \leftarrow$ \texttt{estimate\_snr}$(X)$
\IF{$\text{SNR}_{\text{est}} > \tau$}
    \STATE \textit{// Môi trường SNR cao - sử dụng chiến lược tích cực}
    \RETURN \texttt{shape\_adaptive\_v2}$(X, \text{sensitivity}=s)$
\ELSE
    \STATE \textit{// Môi trường SNR thấp - sử dụng chiến lược bảo thủ}
    \RETURN \texttt{shape}$(X)$ \textit{// ShapeDD gốc}
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/snr_adaptive_architecture.png}
\caption{Kiến trúc hệ thống ShapeDD SNR-Adaptive. Hệ thống ước lượng SNR từ luồng dữ liệu đầu vào, sau đó chọn chiến lược phát hiện thích ứng (aggressive hoặc conservative) dựa trên ngưỡng $\tau=0.010$. Chiến lược aggressive sử dụng ShapeDD\_Adaptive\_v2 với độ nhạy medium, trong khi chiến lược conservative sử dụng ShapeDD gốc. Phân bố thực nghiệm cho thấy 58.7\% aggressive và 41.3\% conservative, đạt F1=0.697 và xếp hạng 4/18.}
\label{fig:snr_adaptive_architecture}
\end{figure}

\subsubsection{Ưu điểm của phương pháp SNR-Adaptive}

Phương pháp hybrid này mang lại các lợi ích sau:

\begin{enumerate}
    \item \textbf{Robust trên nhiều môi trường:} Tự động thích ứng với đặc điểm SNR của dữ liệu
    \item \textbf{Tối ưu F1-score:} Kết hợp điểm mạnh của cả hai chiến lược
    \item \textbf{Không cần điều chỉnh thủ công:} Tự động ước lượng và lựa chọn chiến lược
    \item \textbf{Nền tảng lý thuyết vững chắc:} Dựa trên lý thuyết phát hiện tín hiệu
\end{enumerate}

\subsubsection{Tối ưu hóa tham số dựa trên đánh giá thực nghiệm}

Qua quá trình đánh giá ban đầu, Nghiên cứu quan sát thấy rằng việc lựa chọn tham số (ngưỡng SNR $\tau$ và độ nhạy $s$) có ảnh hưởng đáng kể đến hiệu suất phát hiện. Phân tích lý thuyết và thực nghiệm cho thấy:

\textbf{Hiệu ứng pha loãng SNR trong môi trường buffer:}

Khi sử dụng buffer trượt (sliding buffer) với kích thước lớn (750 mẫu) để phát hiện drift, SNR quan sát được thấp hơn đáng kể so với SNR lý thuyết:

\begin{itemize}
    \item SNR lý thuyết (drift độc lập): 0.4 - 4.0
    \item SNR quan sát trong buffer: 0.005 - 0.020
    \item Nguyên nhân: Buffer chứa dữ liệu hỗn hợp [Ổn định: 90\%] [Drift: 10\%] [Ổn định: ...]
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/buffer_dilution.png}
\caption{Hiệu ứng pha loãng SNR trong môi trường buffer. (Trên) Thành phần buffer 750 mẫu chứa dữ liệu hỗn hợp: 90\% ổn định (xanh lam) và 10\% drift (đỏ), dẫn đến SNR quan sát thấp hơn đáng kể. (Dưới) So sánh SNR lý thuyết (0.4-4.0) với SNR quan sát trong buffer (0.005-0.020), chênh lệch khoảng 100 lần do hiệu ứng pha loãng. Đây là lý do ngưỡng $\tau$ phải được hiệu chỉnh xuống 0.010 thay vì sử dụng giá trị lý thuyết.}
\label{fig:buffer_dilution}
\end{figure}

\textbf{Cơ sở lý thuyết cho việc tối ưu tham số:}

Theo tiêu chuẩn Neyman-Pearson~\cite{neyman1933problem} trong lý thuyết phát hiện tín hiệu, ngưỡng tối ưu là ngưỡng cân bằng giữa tỷ lệ false positive (Type I error) và false negative (Type II error) khi chi phí của chúng tương đương. Điều này tương ứng với việc sử dụng cân bằng khoảng 50\% chiến lược tích cực và 50\% chiến lược bảo thủ, đạt được điểm cân bằng tối ưu giữa precision và recall.

\textbf{Cấu hình tham số tối ưu:}

Dựa trên lý thuyết và kết quả thực nghiệm, Luận văn điều chỉnh tham số như sau:

\begin{table}[H]
\centering
\caption{So sánh cấu hình tham số}
\begin{tabular}{lcccc}
\toprule
\textbf{Cấu hình} & \textbf{$\tau$} & \textbf{$s$} & \textbf{Chiến lược tích cực} & \textbf{F1 (TB 8 datasets)} \\
\midrule
Ban đầu & 0.008 & high & 64.7\% & 0.545 \\
Tối ưu & 0.010 & medium & 58.7\% & \textbf{0.562} \\
\midrule
\textbf{Cải thiện} & +25\% & - & $\rightarrow$ 50\% & \textbf{+3.1\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/strategy_selection.png}
\caption{Phân bố lựa chọn chiến lược của ShapeDD SNR-Adaptive. (Trên) Biểu đồ tròn cho thấy 58.7\% lựa chọn chiến lược aggressive (tích cực) và 41.3\% conservative (bảo thủ), gần với mục tiêu cân bằng 50/50 theo tiêu chuẩn Neyman-Pearson. (Dưới) So sánh cân bằng chiến lược giữa các cấu hình: v1 (threshold=0.008, 64.7\% aggressive), v2 (threshold=0.010, 58.7\% aggressive) và tối ưu lý thuyết (50\%). Cấu hình v2 đạt cân bằng tốt nhất với độ lệch chỉ 8.7\% so với mục tiêu.}
\label{fig:strategy_selection}
\end{figure}

Lý do lựa chọn:
\begin{itemize}
    \item \textbf{Ngưỡng $\tau = 0.010$:} Đạt cân bằng 50/50 theo tiêu chuẩn Neyman-Pearson, phù hợp với SNR quan sát trong buffer (0.005-0.020)
    \item \textbf{Độ nhạy $s = \text{medium}$:} Giảm false positive trong môi trường SNR bị pha loãng bởi buffer, đồng thời duy trì recall tốt
\end{itemize}

\textbf{Kết quả thực nghiệm} (Chi tiết trong Chương \ref{chap:experiments}):

\begin{table}[H]
\centering
\caption{So sánh hiệu suất các phương pháp ShapeDD (F1-score)}
\begin{tabular}{lcccc}
\toprule
\textbf{Phương pháp} & \textbf{F1 (TB)} & \textbf{Detection Rate} & \textbf{Xếp hạng} & \textbf{Đặc điểm} \\
\midrule
ShapeDD\_Adaptive\_None & 0.571 & 63.8\% & 1/18 & Bảo thủ, không lọc \\
\textbf{ShapeDD\_SNR\_Adaptive} & \textbf{0.562} & \textbf{61.2\%} & \textbf{2/18} & \textbf{Hybrid thích ứng} \\
ShapeDD\_Adaptive\_v2\_None & 0.557 & 63.8\% & 3/18 & v2, không lọc \\
ShapeDD (gốc) & 0.544 & 68.8\% & 4/18 & Bảo thủ 100\% \\
DAWIDD & 0.515 & 80.0\% & 5/18 & Baseline \\
ADWIN & 0.507 & 58.3\% & 6/18 & Streaming \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/optimization_comparison.png}
\caption{So sánh hiệu suất trước và sau tối ưu hóa tham số. Ba panel cho thấy sự cải thiện của cấu hình v2 so với v1: (Trái) F1-score trung bình tăng từ 0.545 lên 0.562 (+3.1\%), (Giữa) Detection rate tăng từ 58.8\% lên 61.2\%, (Phải) Balance Score cải thiện từ 14.7 xuống 8.7 (càng gần 0 càng cân bằng). Việc điều chỉnh threshold từ 0.008 lên 0.010 và sensitivity từ high xuống medium đã mang lại cải thiện đáng kể trên tất cả các chỉ số đánh giá (trung bình 8 datasets).}
\label{fig:optimization_comparison}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/threshold_sensitivity.png}
\caption{Phân tích độ nhạy ngưỡng SNR. (Trái) Cân bằng chiến lược thay đổi theo ngưỡng, cho thấy threshold=0.010 (đường đỏ đứt) đạt 58.7\% gần với mục tiêu 50\% (đường xanh đứt). (Phải) F1-score dự kiến theo ngưỡng, với điểm peak ở vùng 0.008-0.012. Các điểm dữ liệu thực nghiệm (v1 ở 0.008 với F1=0.545, v2 ở 0.010 với F1=0.562) được đánh dấu rõ ràng, xác nhận rằng threshold=0.010 nằm trong vùng tối ưu (trung bình trên 8 datasets).}
\label{fig:threshold_sensitivity}
\end{figure}

\textbf{Phân tích kết quả:}

Phương pháp SNR-Adaptive với cấu hình tối ưu đạt F1 = 0.562 (trung bình trên 8 datasets), xếp hạng 2/18 phương pháp được đánh giá - một kết quả rất tốt trong comprehensive benchmark. Phương pháp này đạt được:

\begin{itemize}
    \item \textbf{Tính thích ứng cân bằng:} Sử dụng 58.7\% chiến lược tích cực và 41.3\% chiến lược bảo thủ, gần với mục tiêu 50/50 theo Neyman-Pearson
    \item \textbf{Hiệu suất xuất sắc:} Xếp hạng 2/18 (top 11\%) và vượt qua cả ShapeDD gốc (rank 4/18)
    \item \textbf{Đạt hạng 1 trên drift cường độ cao:} F1=0.727 trên gen\_random\_severe, ties for 1st place
    \item \textbf{Nền tảng lý thuyết vững chắc:} Tham số được tối ưu dựa trên tiêu chuẩn Neyman-Pearson~\cite{neyman1933problem}
    \item \textbf{Khả năng tối ưu hóa:} Cải thiện 3.1\% F1-score so với cấu hình ban đầu (0.545 → 0.562)
    \item \textbf{MTTD cạnh tranh:} 31.4 samples, nhanh hơn ADWIN (68.8), DAWIDD (41.2), MMD (37.9)
\end{itemize}

Kết quả này chứng minh tính khả thi của việc sử dụng SNR để tự động lựa chọn chiến lược phát hiện. Chi tiết đánh giá toàn diện trên 8 datasets xem Chapter 4, Section 4.6 (Thí nghiệm 2).

\subsection{Khung chiến lược thích ứng}

\subsection{Phương pháp Meta-Learning}

Luận văn phát triển khung meta-learning tự động lựa chọn chiến lược thích ứng dựa trên đặc trưng drift được phát hiện:

\textbf{Trích xuất feature:} Đối với mỗi episode drift được phát hiện, nghiên cứu trích xuất feature mô tả:
\begin{itemize}
    \item Mức độ drift: $|\Delta(t_1, t_2)|$
    \item Tốc độ drift: $\frac{|\Delta(t_1, t_2)|}{t_2 - t_1}$
    \item Chiều bị ảnh hưởng: Số lượng feature cho thấy thay đổi đáng kể
    \item Ngữ cảnh lịch sử: Các mẫu drift trước đây và kết quả thích ứng
\end{itemize}

\textbf{Lựa chọn chiến lược:} Meta-classifier được huấn luyện trên các episode drift lịch sử dự đoán chiến lược thích ứng phù hợp nhất:

\begin{equation}
s^* = \arg\max_{s \in \mathcal{S}} P(s|\mathbf{f}_{\text{drift}})
\end{equation}

trong đó $\mathbf{f}_{\text{drift}}$ biểu thị các feature drift được trích xuất và $\mathcal{S}$ là tập hợp các chiến lược thích ứng có sẵn.

\subsection{Quản lý cửa sổ thích ứng}

Luận văn đề xuất chiến lược quản lý cửa sổ thích ứng điều chỉnh kích thước cửa sổ dựa trên đặc trưng drift:

\begin{equation}
w_{\text{size}}(t) = w_{\text{base}} \cdot \exp(-\lambda \cdot \Delta(t))
\end{equation}

trong đó $w_{\text{base}}$ là kích thước cửa sổ cơ sở, $\lambda$ là tham số suy giảm, và $\Delta(t)$ là mức độ drift được phát hiện.

\section{Nền tảng xử lý luồng dữ liệu phân tán với Apache Kafka}

Trong bối cảnh triển khai hệ thống phát hiện concept drift thời gian thực, việc lựa chọn một nền tảng xử lý luồng dữ liệu (stream processing platform) mạnh mẽ và đáng tin cậy là rất quan trọng. Apache Kafka~\cite{kreps2011kafka} đã trở thành nền tảng tiêu chuẩn công nghiệp cho xử lý luồng dữ liệu phân tán, được sử dụng rộng rãi trong các hệ thống big data và real-time analytics. Phần này trình bày nền tảng lý thuyết của Apache Kafka làm cơ sở cho việc triển khai hệ thống phát hiện drift trong Chương~\ref{chap:proposed-model}.

\subsection{Kiến trúc Apache Kafka}

Apache Kafka là một hệ thống xử lý tin nhắn phân tán (distributed messaging system) được thiết kế để xử lý luồng dữ liệu thời gian thực với khối lượng lớn (high-throughput)~\cite{kreps2011kafka}. Kafka được phát triển ban đầu tại LinkedIn và sau đó trở thành một dự án mã nguồn mở của Apache Software Foundation.

\subsubsection{Các thành phần chính}

Kiến trúc Kafka bao gồm các thành phần chính sau~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Producer (Nhà sản xuất):} Ứng dụng gửi dữ liệu (messages) vào Kafka. Producer chịu trách nhiệm chọn partition nào sẽ nhận message trong một topic, có thể dựa trên round-robin hoặc semantic partitioning.

    \item \textbf{Consumer (Người tiêu dùng):} Ứng dụng đọc và xử lý dữ liệu từ Kafka. Consumer theo dõi vị trí đọc của mình (offset) trong mỗi partition, cho phép đọc lại dữ liệu khi cần thiết.

    \item \textbf{Broker (Máy chủ):} Các server Kafka lưu trữ và quản lý messages. Một Kafka cluster bao gồm nhiều broker để đảm bảo tính khả dụng cao (high availability) và khả năng mở rộng (scalability).

    \item \textbf{Topic:} Danh mục hoặc feed name mà messages được publish vào. Mỗi topic được chia thành các partition để hỗ trợ tính song song (parallelism) và khả năng mở rộng.

    \item \textbf{Partition:} Mỗi partition là một chuỗi có thứ tự, bất biến (immutable) các messages được liên tục append vào. Messages trong partition được gán một số định danh tuần tự gọi là offset.

    \item \textbf{ZooKeeper:} Hệ thống phối hợp phân tán (distributed coordination) quản lý metadata của Kafka cluster, theo dõi trạng thái của broker và consumer.
\end{itemize}

\subsubsection{Mô hình Producer-Consumer}

Kafka sử dụng mô hình publish-subscribe, trong đó~\cite{kleppmann2015kafka}:

\begin{enumerate}
    \item \textbf{Producers} publish messages vào các topic mà không cần biết ai sẽ consume chúng
    \item \textbf{Consumers} subscribe vào các topic và nhận messages theo thứ tự mà chúng được written
    \item Mỗi consumer thuộc về một \textbf{consumer group}, và mỗi message chỉ được deliver tới một consumer trong group
    \item Kafka duy trì offset cho mỗi consumer, cho phép consumer đọc lại (replay) messages khi cần
\end{enumerate}

Mô hình này cho phép nhiều producer và consumer hoạt động độc lập, tạo ra một hệ thống decoupled và có khả năng mở rộng cao.

\subsection{Đặc điểm kỹ thuật của Kafka}

\subsubsection{High Throughput và Low Latency}

Kafka được thiết kế để xử lý hàng triệu messages mỗi giây với độ trễ thấp~\cite{hiraman2018apache}. Điều này đạt được thông qua:

\begin{itemize}
    \item \textbf{Sequential I/O:} Kafka ghi messages vào disk theo thứ tự tuần tự, tận dụng đặc điểm của modern disk để đạt hiệu suất cao
    \item \textbf{Zero-copy:} Sử dụng sendfile() system call để chuyển dữ liệu trực tiếp từ disk đến network socket mà không cần copy qua user space
    \item \textbf{Batching:} Messages được gom lại thành batch để giảm network overhead
    \item \textbf{Compression:} Hỗ trợ nén messages (Gzip, Snappy, LZ4) để giảm băng thông mạng và dung lượng lưu trữ
\end{itemize}

\subsubsection{Tính bền vững và đáng tin cậy (Durability và Reliability)}

Kafka đảm bảo tính bền vững của dữ liệu thông qua~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Replication:} Mỗi partition có thể được replicate trên nhiều broker. Một partition có một leader và nhiều follower. Writes và reads đều đi qua leader, trong khi follower replicate dữ liệu.

    \item \textbf{In-Sync Replicas (ISR):} Tập hợp các replica đang synchronized với leader. Message chỉ được coi là committed khi tất cả ISR đã replicate nó.

    \item \textbf{Acknowledgment levels:} Producer có thể cấu hình mức độ acknowledgment:
    \begin{itemize}
        \item \texttt{acks=0}: Producer không đợi acknowledgment (fastest, least reliable)
        \item \texttt{acks=1}: Leader ghi vào log local trước khi ack (balanced)
        \item \texttt{acks=all}: Tất cả ISR replicate trước khi ack (slowest, most reliable)
    \end{itemize}
\end{itemize}

\subsubsection{Khả năng mở rộng (Scalability)}

Kafka scale theo chiều ngang (horizontal scaling) thông qua:

\begin{itemize}
    \item \textbf{Partitioning:} Mỗi topic có thể chia thành nhiều partition, mỗi partition có thể nằm trên broker khác nhau
    \item \textbf{Consumer groups:} Nhiều consumer trong cùng group có thể xử lý song song các partition khác nhau
    \item \textbf{Broker addition:} Có thể thêm broker mới vào cluster và rebalance partition
\end{itemize}

\subsection{Kafka Streams và Stream Processing}

Kafka Streams là một thư viện client-side để xây dựng ứng dụng xử lý luồng dữ liệu và microservices~\cite{kleppmann2015kafka}. Các đặc điểm chính:

\begin{itemize}
    \item \textbf{Stateful processing:} Hỗ trợ xử lý stateful với state stores được back bởi Kafka topics
    \item \textbf{Windowing:} Hỗ trợ windowing operations (tumbling, hopping, sliding, session windows)
    \item \textbf{Exactly-once semantics:} Đảm bảo mỗi message được xử lý đúng một lần, ngay cả khi có failure
    \item \textbf{Interactive queries:} Cho phép query trực tiếp state của streaming application
\end{itemize}

\subsection{Kafka trong hệ thống phát hiện Concept Drift}

Kafka đặc biệt phù hợp cho hệ thống phát hiện concept drift vì các lý do sau:

\begin{enumerate}
    \item \textbf{Real-time streaming:} Kafka cung cấp low-latency streaming cần thiết cho phát hiện drift real-time

    \item \textbf{Replay capability:} Khả năng đọc lại messages cho phép re-train models hoặc re-analyze drift events

    \item \textbf{Buffering:} Kafka có thể buffer dữ liệu trong thời gian dài (configurable retention), hỗ trợ các thuật toán cần sliding windows như ShapeDD

    \item \textbf{Scalability:} Có thể scale để xử lý volume lớn của IoT sensors hoặc streaming data sources

    \item \textbf{Decoupling:} Tách biệt data ingestion, drift detection, và model adaptation thành các microservices độc lập

    \item \textbf{Fault tolerance:} Replication và distributed architecture đảm bảo hệ thống không bị mất dữ liệu khi có failure
\end{enumerate}

Trong Chương~\ref{chap:proposed-model}, Luận văn trình bày cách triển khai hệ thống phát hiện drift sử dụng Kafka, với:
\begin{itemize}
    \item Producer gửi streaming data vào Kafka topic
    \item Consumer thực hiện drift detection (ShapeDD) trên sliding window
    \item Adaptor component cập nhật model khi phát hiện drift
    \item Tất cả các component communicate qua Kafka topics để đảm bảo tính decoupled và scalable
\end{itemize}

Kiến trúc này cho phép hệ thống xử lý high-volume streaming data trong thời gian thực, phát hiện concept drift với độ trễ thấp, và thích ứng nhanh chóng với sự thay đổi trong phân phối dữ liệu.
