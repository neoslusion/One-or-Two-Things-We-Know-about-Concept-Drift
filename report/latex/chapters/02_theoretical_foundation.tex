\chapter{Cơ sở lý thuyết}

\section{Khái niệm về concept drift và phân loại}

\subsection{Khái niệm về concept drift}

Concept drift, hay còn gọi là sự trôi dạt khái niệm, đề cập đến những thay đổi trong phân phối dữ liệu được tạo ra, đặc biệt là trong môi trường động và thay đổi theo thời gian, chẳng hạn như trong ứng dụng về IoT~\cite{ramakrishnan2014enabling} hoặc trong công nghiệp nơi dữ liệu luôn được tạo ra theo thời gian và thay đổi liên tục tùy theo môi trường làm việc khác nhau. Cụ thể hơn, sự trôi dạt khái niệm là một vấn đề trong đó các mối quan hệ thống kê giữa các giá trị đầu vào và giá trị mục tiêu bị thay đổi theo thời gian theo cách không thể dự đoán được~\cite{schlimmer1986incremental}.

Sự trôi dạt khái niệm có thể dẫn đến hiệu suất giảm trong quá trình vận hành thực tế của mô hình học máy, do bản chất của dữ liệu đầu vào đã bị thay đổi so với khi mô hình học máy được huấn luyện, điều này trái ngược với hiệu suất được đánh giá trên tập dữ liệu thử nghiệm tĩnh trong quá trình phát triển.
\subsection{Phân loại các loại concept drift}
Có nhiều loại trôi dạt khác nhau, tùy thuộc vào các yếu tố dữ liệu đang thay đổi. Các loại chính của sự trôi dạt khái niệm bao gồm~\cite{sciencedirect2024drift, hovakimyan2024evolving}.

Phân loại theo sự thay đổi phân phối:
\textbf{Sự trôi dạt ảo (Virtual Drift):} Còn được gọi là sự dịch chuyển biến phụ (covariate shift), đề cập đến tình huống mà sự thay đổi xảy ra trong phân phối các trường hợp đầu vào $P(X)$, trong khi xác suất hậu nghiệm của các giá trị mục tiêu $P(Y|X)$ vẫn không đổi~\cite{moreno2012unifying}.

\textbf{Sự trôi dạt thực (Real Drift):} Sự thay đổi trong xác suất hậu nghiệm của các giá trị mục tiêu (tức là các lớp) $P(Y|X)$ được gọi là sự trôi dạt thực. Sự trôi dạt thực có thể không ảnh hưởng đến sự phân phối các trường hợp đầu vào $P(X)$. Ví dụ, người ta có thể đề cập đến sự thay đổi trong sở thích của người dùng khi họ theo dõi các kênh tin tức phát trực tuyến, trong khi sự phân phối các mục tin tức nhận được thường không thay đổi~\cite{gama2014survey}.

Phân loại theo mô hình thay đổi theo thời gian:
\textbf{Sự trôi dạt đột ngột (Abrupt Drift):} Biểu thị trường hợp khi sự phân phối dữ liệu thay đổi đột ngột tại một thời điểm cụ thể. Drift đột ngột dễ nhận biết nhưng đòi hỏi cơ chế phát hiện và thích ứng nhanh để tránh suy giảm hiệu suất nghiêm trọng~\cite{basseville1993detection}.

\textbf{Sự trôi dạt dần dần (Gradual Drift):} Sự trôi dạt dần dần biểu thị trường hợp khi sự phân phối dữ liệu thay đổi dần dần theo thời gian qua một khoảng thời gian chuyển tiếp. Trong giai đoạn chuyển tiếp này, dữ liệu có thể đến từ cả phân phối cũ và phân phối mới với tỷ lệ thay đổi dần~\cite{gama2014survey}.

\textbf{Sự trôi dạt tăng dần (Incremental Drift):} Thể hiện sự tiến hóa dần dần của phân phối dữ liệu theo từng bước nhỏ liên tục. Ví dụ như sự tiến hóa dần dần của hệ thống đề xuất người dùng ngày càng tiến hóa và nhiều hơn dựa trên sự thay đổi sở thích của người dùng theo thời gian~\cite{hovakimyan2024evolving}.

\textbf{Sự trôi dạt lặp lại (Recurrent Drift):} Trôi dạt lặp lại là khi dữ liệu quay trở lại trạng thái cũ sau một thời gian, hoặc lặp lại theo chu kỳ. Những thay đổi trong dữ liệu không phải mới mà đã từng xảy ra trước đó. Ví dụ như xu hướng thời trang thay đổi theo mùa, tuần hoàn theo từng năm~\cite{hovakimyan2024evolving}.

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{image/distribution_based_concept_drift.png}
\caption{Phân loại dựa trên sự thay đổi phân phối}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{image/patern_based_concept_drift.png}
\caption{Phân loại dựa trên sự thay đổi theo thời gian}
\end{figure}

\subsection{Ảnh hưởng của concept drift}
Sự trôi dạt khái niệm có thể ảnh hưởng lớn đến hiệu suất của mô hình dự đoán, đặc biệt là khi mô hình học từ luồng dữ liệu. Một loạt các dịch vụ/ứng dụng trong bối cảnh hệ thống và mạng truyền thông có thể bị cản trở bởi sự trôi dạt khái niệm như~\cite{ramakrishnan2014enabling}:

\begin{itemize}
    \item \textbf{Hệ thống phát hiện xâm nhập (IDS):} Các mẫu tấn công mạng liên tục thay đổi, đòi hỏi IDS phải thích ứng với các mối đe dọa mới
    \item \textbf{Hệ thống phân loại và dự đoán lưu lượng:} Mẫu lưu lượng mạng thay đổi theo thời gian, ảnh hưởng đến độ chính xác dự đoán
    \item \textbf{Industrial IoT (IIoT):} Đặc biệt trong các kỹ thuật bảo trì dựa trên tình trạng (Condition-Based Maintenance - CBM) được sử dụng để dự đoán các điều kiện bất thường và thời gian bảo trì thông qua phân tích dữ liệu IIoT~\cite{jourdan2021machine}
    \item \textbf{Thành phố thông minh:} Dữ liệu được thu thập cho nhiều mục đích như đảm bảo an ninh mạng, dự đoán ô nhiễm không khí, dự đoán giao thông đường bộ và dự báo tải điện
\end{itemize}

Sự phân phối của dữ liệu có thể thay đổi theo thời gian do máy móc lão hóa và cần quy trình bảo trì, hoặc do các yếu tố môi trường thay đổi. Do đó, một kỹ thuật CBM không có khả năng xử lý sự trôi dạt khái niệm sẽ hoạt động kém~\cite{jourdan2021machine}. Do đó, sự trôi dạt khái niệm có thể ảnh hưởng đến hiệu quả và tính mạnh mẽ của phân tích luồng dữ liệu~\cite{tripathi2021ensuring}. Trong môi trường không cố định, có một số cân nhắc mà các mô hình dự đoán phải tính đến để phát hiện và tự thích ứng với sự trôi dạt khái niệm, nếu không, hiệu suất của các mô hình này sẽ giảm sút về độ chính xác và độ mạnh mẽ. Theo thời gian, một mô hình dự đoán có thể cần cập nhật lại dữ liệu mới, hoặc thay đổi các tham số và cấu trúc của nó bằng cách kết hợp các dữ liệu huấn luyện mới hoặc thay thế hoàn toàn mô hình cũ để xử lý sự trôi dạt khái niệm.

\section{Cách tiếp cận nghiên cứu}

Chương này trình bày khung phương pháp luận để điều tra phát hiện concept drift sử dụng phương pháp Shape Drift Detector (ShapeDD). Nghiên cứu này tập trung vào việc hiểu các nền tảng lý thuyết của ShapeDD, triển khai thuật toán cho các kịch bản drift khác nhau, và thực hiện đánh giá thực nghiệm toàn diện để đánh giá hiệu quả của nó trên các loại concept drift khác nhau.

Phương pháp luận nghiên cứu bao gồm ba thành phần chính: (1) phân tích lý thuyết của thuật toán ShapeDD và các nền tảng Maximum Mean Discrepancy (MMD) cơ bản, (2) triển khai và tối ưu hóa hệ thống phát hiện cho các bộ dữ liệu tổng hợp và thực tế, và (3) đánh giá thực nghiệm toàn diện trên các mẫu drift và cấu hình tham số khác nhau.

\section{Phương pháp ShapeDD: Phát hiện trôi dạt khái niệm dựa trên hình dạng}

\subsection{Giới thiệu và Động cơ}

Trong học máy cổ điển, dữ liệu thường được giả định là \textit{độc lập và phân phối đồng nhất} (i.i.d.) theo một phân phối tĩnh $P_X$. Tuy nhiên, trong các ứng dụng thực tế như luồng dữ liệu từ mạng xã hội, thiết bị IoT hay cảm biến, phân phối dữ liệu thường thay đổi theo thời gian — hiện tượng này được gọi là \textbf{trôi dạt khái niệm (concept drift)}. Khi đó, các mô hình học máy có xu hướng trở nên lỗi thời, đòi hỏi cơ chế phát hiện và điều chỉnh kịp thời.

Các phương pháp \textbf{không giám sát (unsupervised)} cho bài toán phát hiện drift thường dựa trên việc đo \textit{độ khác biệt} giữa hai phân phối dữ liệu trong hai cửa sổ thời gian liên tiếp. Tuy nhiên, do số lượng mẫu trong mỗi cửa sổ thường nhỏ, các phép đo này dễ bị \textbf{nhiễu}, khiến việc phân biệt giữa thay đổi thật và dao động ngẫu nhiên trở nên khó khăn.

\textbf{ShapeDD (Shape-Based Drift Detection)} được đề xuất nhằm khắc phục vấn đề này bằng cách khai thác \textit{đặc trưng hình dạng} mà tín hiệu drift thể hiện, đặc biệt trong các trường hợp \textbf{drift đột ngột (abrupt drift)}.

\subsection{Nền tảng lý thuyết}

\subsubsection{Đại lượng độ lớn trôi dạt (\texorpdfstring{$\sigma$}{σ})}

Xét luồng dữ liệu mà phân phối sinh dữ liệu tại thời điểm $t$ được ký hiệu là $D_t$. Khi xảy ra trôi dạt, ta có $D_t \neq D_s$ với một số $s < t$. ShapeDD định nghĩa đại lượng \textbf{độ lớn trôi dạt} $\sigma$ như là độ đo sự khác biệt giữa hai phân phối quan sát được trong hai cửa sổ thời gian lân cận.

Với hai cửa sổ $W_l(t) = [t - \frac{l}{2}, \, t + \frac{l}{2}]$ và $W_l(s) = [s - \frac{l}{2}, \, s + \frac{l}{2}]$, ta định nghĩa:
\begin{equation}
    \sigma_{d,l}(s,t) = d \big( P_{W_l(s)}, \, P_{W_l(t)} \big),
\end{equation}
trong đó $P_{W_l(t)}$ là phân phối trung bình trên cửa sổ $W_l(t)$ và $d(\cdot,\cdot)$ là độ đo khoảng cách (ví dụ: MMD, Wasserstein, KL, v.v.).

\subsubsection{Hình dạng đặc trưng của drift đột ngột (Định lý 1)}

Kết quả lý thuyết trung tâm của ShapeDD được phát biểu trong Định lý~1, mô tả \textit{hình dạng đặc trưng, không phụ thuộc vào phân phối} của tín hiệu $\sigma$ khi xảy ra một trôi dạt đột ngột.

Giả sử phân phối nền $p_t$ thay đổi \textbf{tức thời} tại $t=0$ từ $P$ sang $Q$, khi đó tín hiệu độ lớn trôi dạt có thể được phân tách thành hai phần:
\begin{equation}
    \sigma_{\parallel \cdot \parallel, l, p^\cdot}(t)
    = \underbrace{ \| P - Q \| }_{\text{Độ mạnh drift}} \cdot
      \underbrace{ h_l(t) }_{\text{Hình dạng drift}},
\end{equation}
trong đó $h_l(t)$ chỉ phụ thuộc vào độ dài cửa sổ $l$, được định nghĩa bởi:
\begin{equation}
    h_l(t) = \max\left( 0, \, 1 - \frac{|l - t|}{l} \right).
\end{equation}

Hàm $h_l(t)$ có dạng \textbf{tam giác cân}, đạt cực đại tại thời điểm xảy ra drift, và suy giảm tuyến tính về hai phía. Đặc tính này hoàn toàn không phụ thuộc vào dạng phân phối hay độ đo khoảng cách sử dụng, mà chỉ bị co giãn theo hệ số $\|P - Q\|$.

\subsubsection{Tổng quát hoá cho nhiều sự kiện drift (Hệ quả 1)}

Khi tồn tại nhiều điểm trôi dạt đột ngột tại các thời điểm $t_1 < t_2 < \dots < t_n$, và độ dài cửa sổ $l$ đủ nhỏ để các tam giác không chồng lên nhau, tổng tín hiệu trôi dạt được biểu diễn như:
\begin{equation}
    \sigma_{\parallel \cdot \parallel, l, p^\cdot}(t)
    = \sum_{i=1}^{n} \| P_{i-1} - P_i \| \, h_l(t - t_i).
\end{equation}

Như vậy, tín hiệu tổng thể $\sigma(t)$ có thể xem là tổng chập (linear superposition) của nhiều “hình tam giác” trôi dạt độc lập.

\subsection{Ứng dụng vào Lọc Nhiễu và Phát hiện Drift}

Nhận biết được dạng hình học của tín hiệu trôi dạt giúp ta thực hiện \textbf{ước lượng tham số (parametric estimation)} cho $\sigma$. Cụ thể, thay vì dùng giá trị ước lượng nhiễu $\hat{\sigma}$, ShapeDD tiến hành \textbf{khớp hàm tham số} $\tilde{\sigma}$ có dạng:
\begin{equation}
    \tilde{\sigma}(t) = \sum_i a_i \, h_l(t - t_i),
\end{equation}
trong đó $a_i$ biểu diễn biên độ (độ mạnh drift) và $t_i$ là vị trí thời gian của sự kiện drift.

Do hàm $h_l(t)$ có cấu trúc hình học cố định và chỉ phụ thuộc vào $l$, việc khớp mô hình $\tilde{\sigma}$ giúp:
\begin{itemize}
    \item Lọc bỏ nhiễu ngẫu nhiên trong $\hat{\sigma}$ (\textit{denoising});
    \item Xác định chính xác hơn thời điểm trôi dạt $t_i$;
    \item Giảm tỉ lệ báo động giả (false positive rate).
\end{itemize}

Trong thực nghiệm, quá trình khớp hàm này được thực hiện bằng \textbf{Fast Sequential Function Fitting}, áp dụng trên các tín hiệu thu được từ nhiều độ đo (như MMD) và các độ dài cửa sổ khác nhau, nhằm tạo ra ước lượng cuối cùng có độ chính xác cao.

\subsection{Tóm tắt}

Tóm lại, ShapeDD tiếp cận bài toán phát hiện trôi dạt khái niệm từ góc nhìn của \textbf{xử lý tín hiệu}. Phương pháp dựa vào việc chứng minh rằng độ lớn thay đổi của phân phối khi drift xảy ra luôn tạo ra một tín hiệu có \textit{hình tam giác đặc trưng}. Nhờ đó, ShapeDD có thể:
\begin{itemize}
    \item Lọc nhiễu trong tín hiệu trôi dạt,
    \item Ước lượng chính xác thời điểm xảy ra drift,
    \item Và đạt độ tin cậy cao trong phát hiện drift đột ngột.
\end{itemize}

\subsection{Maximum Mean Discrepancy (MMD)}

Như đã nhắc đến ở trên, ShapeDD dựa trên Maximum Mean Discrepancy (MMD)~\cite{gretton2012kernel}, một thước đo thống kê được sử dụng để so sánh hai phân phối xác suất $P$ và $Q$. Ý tưởng cốt lõi là ánh xạ dữ liệu từ không gian gốc vào không gian feature cao chiều nơi việc so sánh trở nên nhạy cảm hơn với sự khác biệt phân phối.

\subsubsection{Định nghĩa và intuition}

MMD đo lường khoảng cách giữa hai phân phối bằng cách tìm hàm $f$ có thể phân biệt tốt nhất giữa chúng. Nếu hai phân phối giống nhau, giá trị kỳ vọng của bất kỳ hàm nào áp dụng lên chúng sẽ giống nhau. Ngược lại, nếu khác nhau, sẽ tồn tại một hàm cho phép phân biệt rõ ràng.

MMD được định nghĩa chính thức như:
\begin{equation}
\text{MMD}(P, Q) = \sup_{f \in \mathcal{F}} \left| \mathbb{E}_{X \sim P}[f(X)] - \mathbb{E}_{Y \sim Q}[f(Y)] \right|
\end{equation}

trong đó:
\begin{itemize}
    \item $P$ và $Q$ là hai phân phối cần được so sánh
    \item $X \sim P$ đại diện cho biến ngẫu nhiên được lấy mẫu từ phân phối $P$
    \item $Y \sim Q$ đại diện cho biến ngẫu nhiên được lấy mẫu từ phân phối $Q$
    \item $\mathcal{F}$ là một lớp hàm $f$ sao cho $\|f\|_{\mathcal{H}} \leq 1$ trong Reproducing Kernel Hilbert Space (RKHS)~\cite{scholkopf2002learning}
    \item $\sup$ biểu thị supremum (cận trên nhỏ nhất)
\end{itemize}

\textbf{Intuition:} Trong không gian ban đầu, hai phân phối có thể khó phân biệt. Bằng cách ánh xạ vào RKHS thông qua hàm kernel~\cite{scholkopf2002learning}, các cấu trúc phức tạp của phân phối trở nên rõ ràng hơn. MMD đo lường khoảng cách giữa "trung bình" (mean embedding) của hai phân phối trong không gian này.

\subsubsection{Kernel trick và RKHS}

Trong thực tế, việc tìm supremum trên $\mathcal{F}$ là không khả thi về mặt tính toán. Do đó, MMD thường được triển khai trong RKHS~\cite{scholkopf2002learning} sử dụng kernel trick với hàm kernel $k(x, y)$:

\begin{equation}
k(x, y) = \langle \phi(x), \phi(y) \rangle_{\mathcal{H}}
\end{equation}

trong đó $\phi(x)$ ánh xạ điểm $x$ vào RKHS $\mathcal{H}$ và $\langle \cdot, \cdot \rangle_{\mathcal{H}}$ là tích vô hướng trong $\mathcal{H}$.

\textbf{Lựa chọn kernel phổ biến:} Gaussian RBF kernel được sử dụng rộng rãi nhất do tính chất universal (có thể xấp xỉ bất kỳ hàm liên tục nào):

\begin{equation}
k(x, y) = \exp\left(-\frac{\|x - y\|^2}{2\sigma^2}\right)
\end{equation}

Tham số $\sigma$ (bandwidth) điều khiển độ nhạy: giá trị nhỏ tập trung vào sự khác biệt cục bộ, giá trị lớn nắm bắt cấu trúc toàn cục.

\subsubsection{Công thức tính toán}

MMD bình phương trong RKHS trở thành:
\begin{equation}
\text{MMD}^2(P, Q) = \mathbb{E}_{X, X' \sim P}[k(X, X')] + \mathbb{E}_{Y, Y' \sim Q}[k(Y, Y')] - 2\mathbb{E}_{X \sim P, Y \sim Q}[k(X, Y)]
\end{equation}

\textbf{Giải thích ba thành phần:}
\begin{itemize}
    \item \textbf{Thành phần 1:} $\mathbb{E}_{X, X' \sim P}[k(X, X')]$ - độ tương đồng trung bình giữa các điểm trong phân phối $P$
    \item \textbf{Thành phần 2:} $\mathbb{E}_{Y, Y' \sim Q}[k(Y, Y')]$ - độ tương đồng trung bình giữa các điểm trong phân phối $Q$
    \item \textbf{Thành phần 3:} $-2\mathbb{E}_{X \sim P, Y \sim Q}[k(X, Y)]$ - độ tương đồng chéo giữa hai phân phối (có dấu âm)
\end{itemize}

Nếu $P = Q$, ba thành phần này cân bằng nhau và $\text{MMD}^2 = 0$. Nếu $P \neq Q$, sự khác biệt trong cấu trúc nội bộ và tương tác chéo dẫn đến $\text{MMD}^2 > 0$.

\subsubsection{Ước lượng thực nghiệm}

Để ước tính thực nghiệm với mẫu $\{x_i\}_{i=1}^n$ từ $P$ và $\{y_j\}_{j=1}^m$ từ $Q$, có hai ước lượng chính:

\textbf{1. Unbiased estimator ($\widehat{\text{MMD}}^2_u$):}
\begin{equation}
\widehat{\text{MMD}}^2_u = \frac{1}{n(n-1)} \sum_{i \neq j} k(x_i, x_j) + \frac{1}{m(m-1)} \sum_{i \neq j} k(y_i, y_j) - \frac{2}{nm} \sum_{i,j} k(x_i, y_j)
\end{equation}

Ước lượng này là unbiased ($\mathbb{E}[\widehat{\text{MMD}}^2_u] = \text{MMD}^2$) bằng cách loại trừ các cặp $(i,i)$ trong hai tổng đầu (tránh bias do tự tương quan).

\textbf{2. Biased but consistent estimator ($\widehat{\text{MMD}}^2_b$):}
\begin{equation}
\widehat{\text{MMD}}^2_b = \mathbf{w}^\top K_{XY} \mathbf{w}
\end{equation}

trong đó:
\begin{itemize}
    \item $K_{XY}$ là kernel matrix kích thước $(n+m) \times (n+m)$ trên tất cả samples $\{x_1, ..., x_n, y_1, ..., y_m\}$
    \item $\mathbf{w} = (n^{-1}, ..., n^{-1}, -m^{-1}, ..., -m^{-1})^\top$ với $n$ phần tử dương và $m$ phần tử âm
\end{itemize}

Ước lượng này biased nhưng consistent (hội tụ về $\text{MMD}^2$ khi $n, m \to \infty$).

\textbf{Tính chất thống kê:} Cả hai ước lượng đều hội tụ với tốc độ $O(\sqrt{\min(n,m)^{-1}})$ và bound này chỉ phụ thuộc vào tính chất của kernel, độc lập với số chiều dữ liệu~\cite{gretton2012kernel}.

\textbf{Ví dụ minh họa:} Xét hai phân phối 1D:
\begin{itemize}
    \item $P = \mathcal{N}(0, 1)$ - phân phối chuẩn tâm 0, phương sai 1
    \item $Q = \mathcal{N}(2, 1)$ - phân phối chuẩn tâm 2, phương sai 1
\end{itemize}

Với Gaussian kernel ($\sigma = 1$), MMD sẽ nắm bắt được sự dịch chuyển trung bình (mean shift) giữa hai phân phối. Khi $n, m \to \infty$, $\widehat{\text{MMD}}^2$ hội tụ về giá trị dương phản ánh khoảng cách thực giữa $P$ và $Q$.

\subsection{Các phương pháp phát hiện drift cơ bản}

Các phương pháp phát hiện drift cơ bản đã được trình bày chi tiết trong Chương 2. Để cung cấp ngữ cảnh cho ShapeDD, chúng ta tóm tắt ngắn gọn các đặc điểm chính:

\textbf{Phương pháp dựa trên hiệu suất mô hình:} DDM, EDDM, MDDM, FHDDMS theo dõi các thống kê lỗi của mô hình và phát hiện drift khi hiệu suất giảm đáng kể. Các phương pháp này phụ thuộc vào nhãn ground truth và có thể bị trễ trong việc phát hiện do cần thu thập đủ lỗi.

\textbf{Phương pháp dựa trên cửa sổ thích ứng:} ADWIN điều chỉnh động kích thước cửa sổ dựa trên sự thay đổi được quan sát, đạt được cân bằng giữa độ nhạy và ổn định với đảm bảo lý thuyết $O(\log W)$ về bộ nhớ.

\textbf{Phương pháp dựa trên độc lập thống kê:} DAWIDD phát hiện drift thông qua việc đo lường sự phụ thuộc giữa features và thời gian, cho phép phát hiện sớm mà không cần nhãn.

So với các phương pháp này, ShapeDD mang lại góc nhìn khác biệt bằng cách sử dụng Maximum Mean Discrepancy (MMD) để so sánh trực tiếp phân phối dữ liệu trong không gian kernel, kết hợp với kỹ thuật phát hiện hình dạng (shape detection) để giảm nhiễu và tăng độ chính xác định vị drift.

ShapeDD hoạt động theo bốn giai đoạn chính như sau~\cite{shapeDD2024}:

\subsubsection{Giai đoạn 1: Thu thập dữ liệu (Data Collection)}

Giai đoạn đầu tiên bao gồm thu thập dữ liệu sử dụng kỹ thuật cửa sổ trượt. ShapeDD sử dụng chiến lược cửa sổ đôi (double window) với kích thước $2l_1$ để so sánh hai đoạn dữ liệu liên tiếp:

\begin{itemize}
    \item \textbf{Cửa sổ tham chiếu}: $l_1$ điểm dữ liệu đầu tiên $[t-2l_1+1, t-l_1]$
    \item \textbf{Cửa sổ hiện tại}: $l_1$ điểm dữ liệu tiếp theo $[t-l_1+1, t]$
\end{itemize}

Đối với luồng dữ liệu $\mathcal{S} = \{x_1, x_2, \ldots, x_n\}$, chúng ta duy trì cửa sổ trượt $W_t$ có kích thước tổng cộng $2l_1$ tại thời điểm $t$:
\begin{equation}
W_t = \{x_{t-2l_1+1}, x_{t-2l_1+2}, \ldots, x_t\}
\end{equation}

\textbf{Lựa chọn kích thước cửa sổ $l_1$:} Đây là tham số quan trọng nhất của ShapeDD:
\begin{itemize}
    \item $l_1$ nhỏ (50-100): Nhạy với drift nhanh nhưng dễ bị nhiễu
    \item $l_1$ trung bình (200-500): Cân bằng giữa độ nhạy và ổn định
    \item $l_1$ lớn (>500): Ổn định nhưng trễ phát hiện cao
    \item \textbf{Adaptive sizing}: $l_1 = \alpha \times \text{stream\_length}$ với $\alpha \in [0.03, 0.10]$ điều chỉnh tự động theo độ dài luồng
\end{itemize}

\subsubsection{Giai đoạn 2: Xây dựng feature (Feature Construction)}

Trong giai đoạn này, chúng ta xây dựng ma trận tương đồng (similarity matrix) sử dụng hàm kernel để nắm bắt mối quan hệ giữa các điểm dữ liệu. Gaussian RBF kernel thường được sử dụng:

\begin{equation}
k(x_i, x_j) = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right)
\end{equation}

Điều này tạo ra ma trận kernel đối xứng $K \in \mathbb{R}^{2l_1 \times 2l_1}$ trong đó $K_{ij} = k(x_i, x_j)$ biểu thị sự tương đồng giữa các điểm dữ liệu $x_i$ và $x_j$.

\textbf{Lựa chọn bandwidth $\sigma$:} Có thể sử dụng median heuristic để tự động chọn $\sigma$:
\begin{equation}
\sigma = \text{median}\left(\{\|x_i - x_j\| : i, j \in W_t, i \neq j\}\right)
\end{equation}

Phương pháp này đảm bảo kernel thích nghi với scale của dữ liệu.

\textbf{Hiệu quả tính toán:} Ma trận kernel có thể được cập nhật tăng dần khi cửa sổ trượt:
\begin{itemize}
    \item Tính toán đầy đủ: $O(l_1^2)$ cho mỗi cửa sổ
    \item Cập nhật tăng dần: Chỉ cần tính $O(l_1)$ phần tử mới khi thêm điểm dữ liệu
\end{itemize}

\subsubsection{Giai đoạn 3: Tính toán sự khác biệt (Difference Computation)}

Cốt lõi của ShapeDD bao gồm tính toán sự khác biệt thống kê giữa hai nửa của cửa sổ trượt sử dụng MMD có trọng số. Chúng ta định nghĩa hàm trọng số $w(t)$ tạo ra trọng số tương phản (+1 và -1) cho hai nửa của cửa sổ:

\begin{equation}
w(t) = \begin{cases}
+\frac{1}{l_1} & \text{nếu } t \in [1, l_1] \quad \text{(cửa sổ tham chiếu)} \\
-\frac{1}{l_1} & \text{nếu } t \in [l_1+1, 2l_1] \quad \text{(cửa sổ hiện tại)}
\end{cases}
\end{equation}

Thống kê MMD có trọng số sau đó được tính như:
\begin{equation}
\text{MMD}^2_t = \sum_{i,j=1}^{2l_1} w_i w_j K_{ij}
\end{equation}

\textbf{Giải thích công thức:} Khai triển ra, ta có:
\begin{align}
\text{MMD}^2_t = &\frac{1}{l_1^2} \sum_{i,j=1}^{l_1} K_{ij} \quad \text{(tương đồng trong cửa sổ tham chiếu)} \nonumber \\
+ &\frac{1}{l_1^2} \sum_{i,j=l_1+1}^{2l_1} K_{ij} \quad \text{(tương đồng trong cửa sổ hiện tại)} \nonumber \\
- &\frac{2}{l_1^2} \sum_{i=1}^{l_1} \sum_{j=l_1+1}^{2l_1} K_{ij} \quad \text{(tương đồng chéo)}
\end{align}

Đây chính là công thức MMD giữa hai phân phối được định nghĩa bởi hai nửa cửa sổ.

Tính toán này được thực hiện trên toàn bộ luồng dữ liệu sử dụng phương pháp cửa sổ trượt, tạo ra chuỗi thời gian các giá trị MMD: $\{\text{MMD}^2_1, \text{MMD}^2_2, \ldots, \text{MMD}^2_T\}$.

\textbf{Ý nghĩa của chuỗi MMD:} Khi drift xảy ra tại thời điểm $t_d$:
\begin{itemize}
    \item Trước drift ($t < t_d - l_1$): Cả hai nửa cửa sổ đều từ phân phối cũ $\Rightarrow$ $\text{MMD}^2_t \approx 0$
    \item Tại drift ($t_d - l_1 \leq t \leq t_d$): Cửa sổ tham chiếu từ phân phối cũ, cửa sổ hiện tại từ phân phối mới $\Rightarrow$ $\text{MMD}^2_t$ tăng mạnh
    \item Sau drift ($t > t_d + l_1$): Cả hai nửa đều từ phân phối mới $\Rightarrow$ $\text{MMD}^2_t \approx 0$
\end{itemize}

Điều này tạo ra hình dạng tam giác (triangular shape) đặc trưng trong chuỗi MMD tại vị trí drift.

\subsubsection{Giai đoạn 4: Xác thực thống kê (Statistical Validation)}

Giai đoạn cuối cùng bao gồm hai bước: phát hiện hình dạng (shape detection) và xác thực thống kê.

\textbf{Bước 4.1: Shape Detection qua Convolution}

Để phát hiện hình dạng tam giác, ShapeDD sử dụng bộ lọc convolution $h'_l$ được thiết kế để nhạy với biên tăng-giảm:

\begin{equation}
h'_l(t) = \begin{cases}
+1 & \text{nếu } t \in [0, l] \\
-1 & \text{nếu } t \in (l, 2l]
\end{cases}
\end{equation}

Tín hiệu shape được tính bằng convolution:
\begin{equation}
\text{shape}_t = (h'_l * \text{MMD}^2)(t) = \sum_{i=0}^{2l} h'_l(i) \cdot \text{MMD}^2_{t-i}
\end{equation}

\textbf{Zero-crossing detection:} Drift candidate được xác định khi tín hiệu shape đổi dấu (từ dương sang âm hoặc ngược lại):
\begin{equation}
\text{Candidate}(t) = \text{sign}(\text{shape}_t) \neq \text{sign}(\text{shape}_{t-1})
\end{equation}

\textbf{Bước 4.2: Permutation Test}

Mỗi drift candidate được xác thực bằng permutation test~\cite{good2005permutation} để loại bỏ false positive:

\begin{enumerate}
    \item Tính $\text{MMD}^2_{\text{obs}}$ từ dữ liệu gốc tại vị trí candidate
    \item Lặp $N_{\text{perm}}$ lần (thường 1000-5000):
    \begin{enumerate}
        \item Hoán vị ngẫu nhiên nhãn của hai nửa cửa sổ
        \item Tính $\text{MMD}^2_{\text{perm}}$ với dữ liệu hoán vị
    \end{enumerate}
    \item Tính p-value:
    \begin{equation}
    p\text{-value} = \frac{\#\{\text{MMD}^2_{\text{perm}} \geq \text{MMD}^2_{\text{obs}}\}}{N_{\text{perm}}}
    \end{equation}
    \item Nếu $p\text{-value} < \alpha$ (thường $\alpha = 0.05$), chấp nhận drift
\end{enumerate}

\textbf{Tại sao permutation test hiệu quả?} Nếu không có drift thực sự, việc hoán vị nhãn không nên thay đổi nhiều $\text{MMD}^2$. Nếu có drift, $\text{MMD}^2_{\text{obs}}$ sẽ lớn hơn đáng kể so với các giá trị permutation.

\textbf{Độ phức tạp tính toán:} Permutation test là bước tốn thời gian nhất: $O(N_{\text{perm}} \cdot l_1^2)$. Tuy nhiên, vì chỉ áp dụng cho các candidate (không phải mọi thời điểm), chi phí trung bình vẫn chấp nhận được.

\subsubsection{Ưu điểm nổi bật của ShapeDD}

ShapeDD mang lại một số ưu điểm quan trọng so với các phương pháp phát hiện drift truyền thống:

\begin{enumerate}
    \item \textbf{Khử nhiễu và giảm báo động giả:} Nhờ cơ chế lọc shape, ShapeDD giảm đáng kể số lần báo động sai do nhiễu thống kê. Thay vì phản ứng với mọi dao động nhỏ trong tín hiệu, phương pháp chỉ tập trung vào các biến động có hình dạng phù hợp với drift thật. Việc yêu cầu tín hiệu phải match với triangle pattern giúp filter out các random fluctuations, đảm bảo tính ổn định vượt trội trong môi trường nhiều nhiễu so với phương pháp dùng trực tiếp MMD không lọc shape.

    \item \textbf{Độ chính xác định vị cao:} ShapeDD có khả năng xác định chính xác thời điểm xảy ra drift. Nhờ việc khớp dạng tam giác, phương pháp định vị điểm thay đổi gần như trùng khớp với vị trí drift thực (sai lệch chỉ khoảng $\pm l$ hoặc ít hơn, có thể hiệu chỉnh). Trong khi nhiều phương pháp cửa sổ đôi khác chỉ báo động đang có drift trong một khoảng nào đó, ShapeDD cung cấp trực tiếp thời điểm drift với độ trễ rất nhỏ.

    \item \textbf{Hiệu suất phát hiện cao:} Trên các bộ dữ liệu chuẩn (như SEA, STAGGER, Hyperplane) và dữ liệu thực tế, ShapeDD đạt hiệu năng phát hiện drift tương đương hoặc cao hơn các thuật toán đầu bảng. Chỉ số $\beta$-score (tỷ lệ TP/FP có trọng số) của ShapeDD thường vượt trội so với phương pháp so sánh. Đặc biệt, ShapeDD luôn vượt hơn phương pháp MMD thuần và phương pháp drift magnitude truyền thống về mọi mặt.

    \item \textbf{Thích ứng với nhiều kịch bản drift:} Mặc dù giả định lý thuyết ban đầu tập trung vào drift đột ngột, ShapeDD trong thực nghiệm tỏ ra linh hoạt trước nhiều kiểu drift khác nhau. Nhờ việc có thể kết hợp nhiều độ dài cửa sổ và nhiều độ đo, phương pháp có thể bắt được cả những thay đổi nhanh lẫn chậm. ShapeDD thừa hưởng tính chất phát hiện chắc chắn (surely detecting): nếu drift đủ rõ ràng và tách biệt, phương pháp đảm bảo sẽ phát hiện nhờ tính hợp lệ thống kê của kiểm định kernel two-sample.

    \item \textbf{Tính toán hiệu quả:} Thuật toán ShapeDD được triển khai tối ưu để chạy online với chi phí tuyến tính $O(l)$ theo kích thước cửa sổ trên mỗi mẫu mới. Việc tận dụng tích chập qua cumulative sum giúp tìm điểm drift trong một lượt quét mà không cần thuật toán tối ưu phức tạp lặp đi lặp lại. ShapeDD đủ nhẹ để áp dụng trong thời gian thực trên luồng dữ liệu tốc độ cao.
\end{enumerate}

\subsubsection{Hạn chế và điều kiện áp dụng hiệu quả}

Bên cạnh ưu điểm, ShapeDD cũng có một số hạn chế và điều kiện cần lưu ý:

\begin{itemize}
    \item \textbf{Giả định drift rời rạc và đột ngột:} Lý thuyết hình dạng của ShapeDD giả định mỗi khoảng thời gian chỉ có tối đa một sự kiện drift rõ ràng. Nếu các drift xảy ra liên tục hoặc quá gần nhau (khoảng cách giữa hai lần thay đổi nhỏ hơn độ dài $2l$ của cửa sổ), các mẫu hình tam giác có thể chồng lấn khiến bộ lọc shape không còn nhận dạng đúng được. ShapeDD phù hợp nhất khi các thay đổi lớn diễn ra cách nhau một khoảng đủ dài so với $l$.

    \item \textbf{Hạn chế với drift liên tục (gradual drift):} Trong trường hợp concept drift xảy ra một cách từ từ liên tục (ví dụ mô hình trôi nhẹ dần theo thời gian không có điểm cắt rạch ròi), hình dạng tam giác đặc trưng sẽ không còn rõ nét. Nếu phân phối thay đổi dần, tín hiệu $\sigma(t)$ sẽ không tạo thành mũi nhọn mà chỉ nhô lên rất thoải, khiến cách tiếp cận shape có thể kém nhạy hoặc phải đợi đến khi đủ lớn mới báo (dẫn tới trễ). ShapeDD phát huy tốt nhất với các drift kiểu đột ngột hoặc giai đoạn (sudden/step drift).

    \item \textbf{Lựa chọn độ dài cửa sổ $l$:} Hiệu quả của ShapeDD phụ thuộc vào tham số $l$. Nếu $l$ quá nhỏ, ước lượng $\hat{\sigma}(t)$ rất nhiễu, khiến khớp shape khó phân biệt tín hiệu; ngược lại nếu $l$ quá lớn, hiệu ứng drift bị làm mờ và còn gây tăng độ trễ phát hiện. Một giải pháp an toàn là kết hợp nhiều $l$ như ShapeDD đề xuất sẵn, nhằm đảm bảo không bỏ sót. Tuy nhiên, việc dùng nhiều cửa sổ cũng làm tăng chi phí tính toán và độ phức tạp triển khai.

    \item \textbf{Tham số kiểm định và ngưỡng:} ShapeDD yêu cầu đặt ngưỡng cho kiểm định (mức ý nghĩa $\alpha$) và ngưỡng cho biên độ $s$. Nếu đặt ngưỡng quá cao (nghiêm ngặt), phương pháp có thể bỏ lỡ những drift nhẹ; nếu đặt quá thấp, sẽ tăng nguy cơ báo động giả. Việc chọn các ngưỡng này cần hiệu chỉnh cẩn thận, thường thông qua cross-validation hoặc dựa vào chỉ số đánh giá tổng hợp như $\beta$-score.

    \item \textbf{Trường hợp dữ liệu nhiều chiều phức tạp:} Mặc dù MMD với kernel Gaussian có ưu điểm không phụ thuộc số chiều, nhưng trong thực tế khi phân phối thay đổi chỉ trên một phần không gian đặc trưng, hoặc drift chỉ ảnh hưởng một vài thuộc tính, thì việc phát hiện có thể khó khăn hơn (tín hiệu drift yếu vì khoảng cách toàn cục nhỏ). Khi đó, có thể cần kết hợp ShapeDD với phương pháp lựa chọn đặc trưng hoặc kiểm định theo từng chiều.
\end{itemize}

% \subsubsection{So sánh với các phương pháp phát hiện drift khác}

% \textbf{ShapeDD vs DDM:} DDM (Drift Detection Method) là phương pháp giám sát lỗi phân loại theo thời gian và đưa ra cảnh báo drift khi tỷ lệ lỗi tăng vượt ngưỡng dựa trên mô hình Bernoulli. So với DDM, ShapeDD có những khác biệt quan trọng:
% \begin{itemize}
%     \item ShapeDD hoạt động \textit{không cần nhãn} (unsupervised), trực tiếp phát hiện thay đổi phân phối dữ liệu thay vì chờ sai số mô hình tăng. DDM chỉ hữu dụng trong bối cảnh giám sát (supervised) và phụ thuộc vào chất lượng mô hình hiện tại.
%     \item Về độ chính xác thời gian, ShapeDD thường xác định điểm drift \textit{nhanh và chính xác hơn}. DDM có xu hướng phát hiện muộn – nó đợi đủ bằng chứng sai số tăng mới kích hoạt. ShapeDD phản ứng ngay khi phân phối bắt đầu lệch, chỉ lệch khoảng nửa độ dài cửa sổ $l$.
%     \item ShapeDD khắc phục được vấn đề nhiễu và không phụ thuộc trực tiếp vào hiệu năng mô hình, trong khi DDM có thể nhạy cảm với các dao động ngẫu nhiên trong lỗi.
% \end{itemize}

% \textbf{ShapeDD vs ADWIN:} ADWIN (Adaptive Windowing) là phương pháp dựa trên trượt cửa sổ với kích thước thay đổi thích ứng. ADWIN luôn duy trì một cửa sổ dữ liệu có thể mở rộng, và thu hẹp lại khi kiểm định thống kê phát hiện phân phối ở đầu và cuối cửa sổ khác nhau đáng kể.
% \begin{itemize}
%     \item Ưu điểm của ShapeDD so với ADWIN là \textit{giảm thiểu kiểm định nhiều lần}: ADWIN phải kiểm tra rất nhiều điểm cắt có thể trong cửa sổ lớn, dễ gặp vấn đề multiple testing làm tăng xác suất báo sai. ShapeDD chỉ xem xét vài điểm ứng viên do shape filter chọn lọc, giảm hẳn nguy cơ báo trùng lặp hoặc báo giả liên tục.
%     \item ShapeDD cho phép \textit{định vị chính xác} điểm drift (cung cấp trực tiếp $t_0$), còn ADWIN thường chỉ biết "một thay đổi đã xảy ra" và phải ước lượng điểm cắt – độ chính xác có thể kém hơn.
%     \item Về khả năng thích ứng, ADWIN nổi bật trong xử lý drift dần dần: nó có thể từ từ thu hẹp/gia tăng cửa sổ. Trong tình huống drift đột ngột, ADWIN thường phải chờ tích lũy đủ bằng chứng, nên có thể trễ hơn ShapeDD.
% \end{itemize}

% \textbf{ShapeDD vs HDDM:} HDDM (Hellinger Distance Drift Detection) sử dụng khoảng cách Hellinger tích lũy để phát hiện drift. Kết quả so sánh với HDDM cho thấy ShapeDD thường cho $\beta$-score cao hơn, đặc biệt trong trường hợp nhiễu lớn (HDDM có thể báo nhiều false positive hơn). Tuy nhiên, HDDM trong một số trường hợp phát hiện được drift nhỏ tốt hơn (vì tích lũy dần dần), dẫn đến xác suất phát hiện nhỉnh hơn khi cửa sổ rất nhỏ.

% \textbf{Đánh giá tổng quát:} Điểm độc đáo của ShapeDD là khai thác cấu trúc hình dạng lý thuyết của tín hiệu drift – một khía cạnh mà hầu hết phương pháp khác chưa tận dụng. Nhờ đó, ShapeDD đạt được cân bằng tốt giữa độ nhạy và độ đặc hiệu: nhạy vì dùng các độ đo mạnh như MMD, đặc hiệu vì yêu cầu khuôn dạng đặc trưng mới báo động. Trên tổng thể nhiều bộ dữ liệu, ShapeDD được đánh giá cao nhờ ổn định và chính xác, đặc biệt về phương diện giảm thiểu báo động sai và định vị đúng thời điểm thay đổi.

\section{Phương pháp cải tiến đề xuất}

\subsection{ShapeDD SNR-Adaptive: Phương pháp hybrid thích ứng với tỷ lệ tín hiệu-nhiễu}

Phần này trình bày phương pháp cải tiến ShapeDD SNR-Adaptive - một đóng góp nghiên cứu chính của luận văn này. Phương pháp này mở rộng ShapeDD gốc bằng cách tự động điều chỉnh chiến lược phát hiện dựa trên đặc trưng Signal-to-Noise Ratio (SNR) của môi trường dữ liệu.

\subsubsection{Phát hiện quan trọng: Ảnh hưởng của tỷ lệ tín hiệu-nhiễu (SNR)}

Phân tích lý thuyết cho thấy một kết quả quan trọng: \textbf{không có chiến lược phát hiện drift duy nhất là tối ưu cho mọi môi trường SNR}.

\textbf{Môi trường SNR cao} (tín hiệu drift mạnh, nhiễu thấp):
\begin{itemize}
    \item Ngưỡng tích cực (aggressive threshold) phù hợp hơn
    \item Có thể phát hiện sớm với recall cao mà không gây nhiều false positive
    \item Lý do: Tín hiệu drift vượt xa nhiễu, dễ phân biệt
\end{itemize}

\textbf{Môi trường SNR thấp} (tín hiệu drift yếu, nhiễu cao):
\begin{itemize}
    \item Ngưỡng bảo thủ (conservative threshold) hiệu quả hơn
    \item Đạt precision cao bằng cách chờ tín hiệu rõ ràng vượt ngưỡng nhiễu
    \item Lý do: Tín hiệu drift gần với nhiễu, cần threshold cao để tránh false alarm
\end{itemize}

\subsubsection{Nền tảng lý thuyết: Lý thuyết phát hiện tín hiệu}

Kết quả này phản ánh một nguyên lý cơ bản trong lý thuyết phát hiện tín hiệu (Signal Detection Theory) và tiêu chuẩn Neyman-Pearson~\cite{neyman1933problem}:

\begin{equation}
\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}
\end{equation}

trong đó:
\begin{itemize}
    \item $\sigma^2_{\text{signal}}$: phương sai của tín hiệu drift (độ biến thiên giữa các cửa sổ)
    \item $\sigma^2_{\text{noise}}$: phương sai nhiễu nội tại trong dữ liệu
\end{itemize}

\textbf{Đánh đổi Precision-Recall theo SNR:}

\begin{itemize}
    \item \textbf{Ngưỡng tích cực (thấp):}
    \begin{itemize}
        \item Recall cao (phát hiện nhiều drift)
        \item Nguy cơ báo động giả trên nhiễu (False Positive tăng)
        \item Phù hợp khi SNR cao
    \end{itemize}

    \item \textbf{Ngưỡng bảo thủ (cao):}
    \begin{itemize}
        \item Precision cao (ít báo động giả)
        \item Nguy cơ bỏ lỡ tín hiệu yếu (False Negative tăng)
        \item Phù hợp khi SNR thấp
    \end{itemize}
\end{itemize}

\subsubsection{Giải pháp: Phương pháp hybrid thích ứng SNR}

Để khắc phục hạn chế của các chiến lược đơn lẻ, Luận văn đề xuất phương pháp \textbf{ShapeDD SNR-Adaptive} - một thuật toán hybrid tự động chọn chiến lược phát hiện dựa trên SNR ước lượng của môi trường:

\textbf{Thuật toán ước lượng SNR:}

\begin{algorithm}[H]
\caption{Ước lượng SNR từ luồng dữ liệu}
\begin{algorithmic}[1]
\REQUIRE Dữ liệu $X$, kích thước cửa sổ $w$, số mẫu $k$
\ENSURE Ước lượng SNR
\STATE Chia $X$ thành $k$ cửa sổ kích thước $w$
\STATE Tính trung bình mỗi cửa sổ: $\mu_1, \mu_2, ..., \mu_k$
\STATE Tính phương sai giữa các cửa sổ: $\sigma^2_{\text{signal}} = \text{Var}(\mu_1, ..., \mu_k)$
\STATE Tính phương sai trung bình trong mỗi cửa sổ: $\sigma^2_{\text{noise}} = \frac{1}{k}\sum_{i=1}^{k}\text{Var}(X_i)$
\RETURN $\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}$
\end{algorithmic}
\end{algorithm}

\textbf{Logic lựa chọn chiến lược:}

\begin{algorithm}[H]
\caption{ShapeDD SNR-Adaptive}
\begin{algorithmic}[1]
\REQUIRE Dữ liệu $X$, ngưỡng SNR $\tau$, độ nhạy $s$
\ENSURE Kết quả phát hiện drift
\STATE $\text{SNR}_{\text{est}} \leftarrow$ \texttt{estimate\_snr}$(X)$
\IF{$\text{SNR}_{\text{est}} > \tau$}
    \STATE \textit{// Môi trường SNR cao - sử dụng chiến lược tích cực}
    \RETURN \texttt{shape\_adaptive\_v2}$(X, \text{sensitivity}=s)$
\ELSE
    \STATE \textit{// Môi trường SNR thấp - sử dụng chiến lược bảo thủ}
    \RETURN \texttt{shape}$(X)$ \textit{// ShapeDD gốc}
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/snr_adaptive_architecture.png}
\caption{Kiến trúc hệ thống ShapeDD SNR-Adaptive. Hệ thống ước lượng SNR từ luồng dữ liệu đầu vào, sau đó chọn chiến lược phát hiện thích ứng (aggressive hoặc conservative) dựa trên ngưỡng SNR. Chiến lược aggressive sử dụng threshold thấp hơn để phát hiện sớm (phù hợp với high SNR), trong khi chiến lược conservative sử dụng threshold cao hơn để giảm false positive (phù hợp với low SNR). Việc lựa chọn strategy dựa trên tiêu chuẩn Neyman-Pearson nhằm cân bằng Type I và Type II errors.}
\label{fig:snr_adaptive_architecture}
\end{figure}

\subsubsection{Ưu điểm của phương pháp SNR-Adaptive}

Phương pháp hybrid này mang lại các lợi ích sau:

\begin{enumerate}
    \item \textbf{Robust trên nhiều môi trường:} Tự động thích ứng với đặc điểm SNR của dữ liệu
    \item \textbf{Tối ưu F1-score:} Kết hợp điểm mạnh của cả hai chiến lược
    \item \textbf{Không cần điều chỉnh thủ công:} Tự động ước lượng và lựa chọn chiến lược
    \item \textbf{Nền tảng lý thuyết vững chắc:} Dựa trên lý thuyết phát hiện tín hiệu
\end{enumerate}

\subsubsection{Đánh giá thực nghiệm}

Đánh giá toàn diện phương pháp SNR-Adaptive, bao gồm:
\begin{itemize}
    \item Phân tích hiệu ứng pha loãng SNR trong môi trường buffer
    \item Tối ưu hóa tham số (ngưỡng $\tau$ và độ nhạy $s$) dựa trên tiêu chuẩn Neyman-Pearson
    \item So sánh hiệu suất với 17 phương pháp baseline khác trên 8 datasets
    \item Phân tích phân bố chiến lược (aggressive vs conservative) và ảnh hưởng đến F1-score
    \item Sensitivity analysis với các giá trị threshold khác nhau
\end{itemize}

\textbf{Kết quả chi tiết được trình bày trong Chapter~\ref{chap:experiments}, Section 4.6 "Đánh giá SNR-Adaptive".}

\subsection{Khung chiến lược thích ứng}

\subsection{Phương pháp Meta-Learning}

Luận văn phát triển khung meta-learning tự động lựa chọn chiến lược thích ứng dựa trên đặc trưng drift được phát hiện:

\textbf{Trích xuất feature:} Đối với mỗi episode drift được phát hiện, nghiên cứu trích xuất feature mô tả:
\begin{itemize}
    \item Mức độ drift: $|\Delta(t_1, t_2)|$
    \item Tốc độ drift: $\frac{|\Delta(t_1, t_2)|}{t_2 - t_1}$
    \item Chiều bị ảnh hưởng: Số lượng feature cho thấy thay đổi đáng kể
    \item Ngữ cảnh lịch sử: Các mẫu drift trước đây và kết quả thích ứng
\end{itemize}

\textbf{Lựa chọn chiến lược:} Meta-classifier được huấn luyện trên các episode drift lịch sử dự đoán chiến lược thích ứng phù hợp nhất:

\begin{equation}
s^* = \arg\max_{s \in \mathcal{S}} P(s|\mathbf{f}_{\text{drift}})
\end{equation}

trong đó $\mathbf{f}_{\text{drift}}$ biểu thị các feature drift được trích xuất và $\mathcal{S}$ là tập hợp các chiến lược thích ứng có sẵn.

\subsection{Quản lý cửa sổ thích ứng}

Luận văn đề xuất chiến lược quản lý cửa sổ thích ứng điều chỉnh kích thước cửa sổ dựa trên đặc trưng drift:

\begin{equation}
w_{\text{size}}(t) = w_{\text{base}} \cdot \exp(-\lambda \cdot \Delta(t))
\end{equation}

trong đó $w_{\text{base}}$ là kích thước cửa sổ cơ sở, $\lambda$ là tham số suy giảm, và $\Delta(t)$ là mức độ drift được phát hiện.

\subsection{Chi tiết triển khai ShapeDD}

\subsubsection{Thuật toán ShapeDD đầy đủ}

Để hiểu rõ hơn về cách ShapeDD hoạt động trong thực tế, chúng ta trình bày thuật toán đầy đủ kết hợp cả 4 giai đoạn đã mô tả:

\begin{algorithm}[H]
\caption{ShapeDD - Shape-Based Drift Detector}
\label{alg:shapedd-full}
\begin{algorithmic}[1]
\REQUIRE Luồng dữ liệu $\mathcal{S} = \{x_1, x_2, ..., x_n\}$
\REQUIRE Kích thước cửa sổ $l_1$, $l_2$ (với $l_2 > l_1$)
\REQUIRE Số lần permutation $n_{\text{perm}}$
\REQUIRE Mức ý nghĩa $\alpha$ (thường 0.05)
\ENSURE Tập hợp các drift point $\mathcal{D}$

\STATE \textit{// Giai đoạn 1: Khởi tạo}
\STATE Tính ma trận kernel $K \in \mathbb{R}^{n \times n}$: $K_{ij} = k(x_i, x_j)$
\STATE Khởi tạo $\mathcal{D} \leftarrow \emptyset$ (tập drift points rỗng)

\STATE \textit{// Giai đoạn 2: Tính toán MMD statistic sequence}
\STATE Tạo weight vector $\mathbf{w} = [\frac{1}{l_1}, ..., \frac{1}{l_1}, -\frac{1}{l_1}, ..., -\frac{1}{l_1}]^\top$ (kích thước $2l_1$)
\STATE Khởi tạo ma trận trọng số $W \in \mathbb{R}^{(n-2l_1) \times n}$
\FOR{$i = 1$ to $n - 2l_1$}
    \STATE $W[i, i:i+2l_1] \leftarrow \mathbf{w}$
\ENDFOR
\STATE Tính MMD sequence: $\text{stat}[i] = W[i, :] \cdot K \cdot W[i, :]^\top$

\STATE \textit{// Giai đoạn 3: Shape detection via convolution}
\STATE Tạo shape filter $h'_l = [+1, ..., +1, -1, ..., -1]$ (length $2l_1$)
\STATE $\text{shape} \leftarrow \text{convolve}(\text{stat}, h'_l)$
\STATE Tính $\text{shape\_prime}[i] = \text{shape}[i] \times \text{shape}[i+1]$ \textit{// Detect sign changes}

\STATE \textit{// Giai đoạn 4: Statistical validation}
\FOR{mỗi zero-crossing tại vị trí $t$ trong shape\_prime}
    \STATE Extract window $W_t = \{x_{t-l_2+1}, ..., x_t\}$
    \STATE Chia $W_t$ thành hai nửa: $W_{\text{ref}} = W_t[1:l_2/2]$, $W_{\text{test}} = W_t[l_2/2+1:l_2]$
    \STATE Tính $\text{MMD}^2_{\text{obs}}$ giữa $W_{\text{ref}}$ và $W_{\text{test}}$

    \STATE \textit{// Permutation test}
    \STATE $p\text{-value} \leftarrow 0$
    \FOR{$j = 1$ to $n_{\text{perm}}$}
        \STATE Hoán vị ngẫu nhiên nhãn của $W_t$
        \STATE Tính $\text{MMD}^2_{\text{perm}}$
        \IF{$\text{MMD}^2_{\text{perm}} \geq \text{MMD}^2_{\text{obs}}$}
            \STATE $p\text{-value} \leftarrow p\text{-value} + 1$
        \ENDIF
    \ENDFOR
    \STATE $p\text{-value} \leftarrow p\text{-value} / n_{\text{perm}}$

    \IF{$p\text{-value} < \alpha$}
        \STATE $\mathcal{D} \leftarrow \mathcal{D} \cup \{t\}$ \textit{// Accept drift}
    \ENDIF
\ENDFOR

\RETURN $\mathcal{D}$
\end{algorithmic}
\end{algorithm}

\textbf{Độ phức tạp tính toán:}
\begin{itemize}
    \item \textbf{Khởi tạo kernel matrix:} $O(n^2 \cdot d)$ với $d$ là số chiều dữ liệu
    \item \textbf{MMD sequence computation:} $O(n \cdot l_1^2)$
    \item \textbf{Convolution:} $O(n \cdot l_1)$
    \item \textbf{Permutation test:} $O(|\mathcal{D}| \cdot n_{\text{perm}} \cdot l_2^2)$
    \item \textbf{Tổng thể:} $O(n^2 \cdot d + n \cdot l_1^2 + |\mathcal{D}| \cdot n_{\text{perm}} \cdot l_2^2)$
\end{itemize}

\subsubsection{Các biến thể của ShapeDD}

Ngoài phiên bản gốc, nghiên cứu này triển khai và đánh giá nhiều biến thể của ShapeDD để xử lý các thách thức khác nhau trong phát hiện drift. Mỗi biến thể có những cải tiến và trade-offs riêng.

\textbf{1. ShapeDD Adaptive:} Phiên bản adaptive đầu tiên giới thiệu khái niệm sensitivity levels để điều chỉnh độ nhạy của detector:

\begin{itemize}
    \item \textbf{Gamma selection:} Sử dụng Scott's rule để tự động chọn bandwidth kernel:
    \begin{equation}
    \gamma = \frac{1}{2\sigma^2}, \quad \sigma = \sigma_{\text{data}} \cdot n^{-1/(d+4)}
    \end{equation}

    \item \textbf{Sensitivity levels:} Năm mức độ nhạy với các threshold multipliers khác nhau:
    \begin{itemize}
        \item \texttt{low}: $\text{threshold} = \text{baseline} \times 1.5$ (bảo thủ nhất)
        \item \texttt{medium}: $\text{threshold} = \text{baseline} \times 1.2$
        \item \texttt{high}: $\text{threshold} = \text{baseline} \times 0.8$
        \item \texttt{ultrahigh}: $\text{threshold} = \text{baseline} \times 0.5$ (tích cực nhất)
        \item \texttt{none}: Không có threshold, chấp nhận mọi candidate
    \end{itemize}

    \item \textbf{FDR correction:} Áp dụng Benjamini-Hochberg procedure để kiểm soát False Discovery Rate trong multiple testing
\end{itemize}

\textbf{2. ShapeDD Adaptive v2 - Năm cải tiến quan trọng:}

Phiên bản adaptive\_v2 khắc phục các vấn đề nghiêm trọng trong adaptive gốc thông qua năm cải tiến then chốt:

\begin{enumerate}
    \item \textbf{Corrected sensitivity logic (Sửa lỗi threshold):}
    \begin{itemize}
        \item \textit{Vấn đề:} Adaptive gốc đảo ngược ý nghĩa của sensitivity - "high sensitivity" lại dùng threshold cao (kém nhạy)
        \item \textit{Giải pháp:} Đảo ngược threshold multipliers:
        \begin{align*}
        \texttt{low} &\rightarrow \times 1.2 \text{ (threshold cao, bảo thủ)} \\
        \texttt{medium} &\rightarrow \times 0.8 \\
        \texttt{high} &\rightarrow \times 0.5 \\
        \texttt{ultrahigh} &\rightarrow \times 0.25 \text{ (threshold thấp, tích cực)}
        \end{align*}
    \end{itemize}

    \item \textbf{Minimal smoothing (Giảm làm mượt):}
    \begin{itemize}
        \item \textit{Vấn đề:} Smoothing window $= \sqrt{l_1}$ quá lớn, làm mờ drift signals
        \item \textit{Giải pháp:} Giảm xuống còn 3-point moving average:
        \begin{equation}
        \text{smooth\_window} = 3 \quad (\text{thay vì } \max(3, \lceil\sqrt{l_1}\rceil))
        \end{equation}
    \end{itemize}

    \item \textbf{Percentile-based threshold (Ngưỡng robust):}
    \begin{itemize}
        \item \textit{Vấn đề:} Mean-based baseline dễ bị ảnh hưởng bởi outliers
        \item \textit{Giải pháp:} Sử dụng 10th percentile của positive shapes:
        \begin{equation}
        \text{baseline} = \text{percentile}(\text{positive\_shapes}, 10)
        \end{equation}
        \item Robust hơn với extreme values và noise spikes
    \end{itemize}

    \item \textbf{Adaptive FDR (FDR có điều kiện):}
    \begin{itemize}
        \item \textit{Vấn đề:} FDR correction luôn được áp dụng, làm giảm recall không cần thiết trong clean environments
        \item \textit{Giải pháp:} Chỉ áp dụng FDR khi detection density cao:
        \begin{equation}
        \text{Apply FDR if} \quad \frac{|\text{candidates}|}{n} < 0.03
        \end{equation}
        \item Tránh over-correction trong scenarios với ít drift
    \end{itemize}

    \item \textbf{Hybrid threshold strategy (Kết hợp strategies):}
    \begin{itemize}
        \item Sử dụng cả magnitude threshold và statistical test
        \item Drift được chấp nhận nếu:
        \begin{equation}
        (\text{magnitude} > \text{threshold}) \land (p\text{-value} < \alpha)
        \end{equation}
        \item Cân bằng giữa sensitivity và specificity
    \end{itemize}
\end{enumerate}

\textbf{3. ShapeDD Sensitive:} Biến thể được tối ưu cho phát hiện drift nhỏ và tinh tế:

\begin{itemize}
    \item \textbf{Smaller windows:} Sử dụng $l_1 = 30$, $l_2 = 100$ (nhỏ hơn default 50/150)
    \item \textbf{Aggressive gamma:} $\gamma = 2.0 / \text{median\_dist}^2$ (gấp đôi sensitivity)
    \item \textbf{Lower threshold:} Baseline multiplier = 0.6 (thấp hơn "high" sensitivity)
    \item \textbf{Trade-off:} Recall cao hơn nhưng false positive rate tăng
\end{itemize}

\subsubsection{Bảng so sánh các biến thể ShapeDD}

\begin{table}[H]
\centering
\caption{So sánh các biến thể ShapeDD}
\label{tab:shapedd-variants}
\begin{tabular}{|l|p{2.5cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Biến thể} & \textbf{Đặc điểm chính} & \textbf{Ưu điểm} & \textbf{Nhược điểm} & \textbf{Khi nào dùng} \\
\hline
\textbf{Original} & Conservative, high precision & Ít false positive, ổn định & Có thể miss subtle drift & Default choice, high-stakes scenarios \\
\hline
\textbf{Adaptive} & Sensitivity levels, gamma auto-selection & Flexible, FDR control & Inverted threshold logic (bug) & Không khuyến nghị (dùng v2) \\
\hline
\textbf{Adaptive v2} & 5 critical fixes, corrected logic & Balanced P-R, robust & Phức tạp hơn & Multi-drift scenarios, noisy data \\
\hline
\textbf{Sensitive} & Small windows, aggressive threshold & High recall, early detection & High FP rate & Subtle drift, low latency required \\
\hline
\textbf{SNR-Adaptive} & Hybrid strategy, SNR-aware & Best F1-score, auto-adapt & Requires SNR estimation & Production, unknown SNR environments \\
\hline
\end{tabular}
\end{table}

\subsubsection{Hiệu ứng pha loãng buffer (Buffer Dilution Effect)}

Một phát hiện quan trọng trong nghiên cứu này là \textbf{buffer dilution effect} - hiện tượng SNR quan sát được thấp hơn nhiều so với SNR lý thuyết khi sử dụng rolling buffer trong phát hiện drift thực tế.

\textbf{Lý thuyết vs Thực tế:}

\begin{itemize}
    \item \textbf{SNR lý thuyết} (isolated drift trong môi trường sạch):
    \begin{equation}
    \text{SNR}_{\text{theory}} \in [0.4, 4.0]
    \end{equation}
    Giả định: Drift point riêng biệt, không có dữ liệu ổn định xen kẽ

    \item \textbf{SNR quan sát được} (buffer-based detection):
    \begin{equation}
    \text{SNR}_{\text{observed}} \in [0.005, 0.020]
    \end{equation}
    Giảm khoảng \textbf{100 lần} so với lý thuyết!
\end{itemize}

\textbf{Nguyên nhân:} Trong phát hiện thực tế, chúng ta sử dụng rolling buffer chứa dữ liệu hỗn hợp:

\begin{equation}
\text{Buffer}_{750} = \underbrace{[\text{Stable data}]}_{\sim 90\%} + \underbrace{[\text{Drift data}]}_{\sim 10\%}
\end{equation}

Với buffer size = 750 và drift detection window = 150:
\begin{itemize}
    \item Tỷ lệ drift data: $150 / 750 = 20\%$ (lý tưởng)
    \item Thực tế: Do overlap và continuous streaming, chỉ $\sim 10\%$ là pure drift signal
    \item Phần còn lại ($\sim 90\%$) là stable data, "pha loãng" tín hiệu drift
\end{itemize}

\textbf{Tác động lên signal variance:}

\begin{equation}
\sigma^2_{\text{signal,buffer}} = \sigma^2_{\text{signal,theory}} \times \left(\frac{\text{\% drift data}}{100\%}\right)^2 \approx \sigma^2_{\text{signal,theory}} \times 0.01
\end{equation}

Do đó: $\text{SNR}_{\text{buffer}} \approx \text{SNR}_{\text{theory}} / 100$

\textbf{Hệ quả quan trọng cho SNR-Adaptive:}

Threshold phải được hiệu chỉnh (calibrated) cho môi trường buffer:
\begin{itemize}
    \item Threshold lý thuyết: $\tau_{\text{theory}} \approx 0.5$ (midpoint của [0.4, 4.0])
    \item Threshold buffer-calibrated: $\tau_{\text{buffer}} = 0.010$ (midpoint của [0.005, 0.020])
    \item Giảm 50 lần: $\tau_{\text{buffer}} = \tau_{\text{theory}} / 50$
\end{itemize}

Threshold 0.010 được chọn dựa trên:
\begin{enumerate}
    \item \textbf{Empirical observation:} Phân tích SNR quan sát trên 8 datasets cho thấy observed SNR range [0.005, 0.020], với midpoint = 0.010

    \item \textbf{Neyman-Pearson optimization:} Threshold tối ưu được xác định bằng cách minimize tổng detection errors khi Type I error (false positive) và Type II error (false negative) có cost bằng nhau:
    \begin{equation}
    \tau^* = \arg\min_{\tau} \left[ P(\text{FP}|\tau) + P(\text{FN}|\tau) \right]
    \end{equation}
    Với equal costs, optimal threshold nằm tại điểm mà precision $\approx$ recall, tương đương strategy distribution $\approx$ 50/50.

    \item \textbf{Strategy balance validation:} Đạt $\sim 50\%$ aggressive / $\sim 50\%$ conservative, xác nhận threshold nằm gần tối ưu Neyman-Pearson
\end{enumerate}

\textbf{Validation qua thực nghiệm:} Với threshold = 0.010:
\begin{itemize}
    \item Strategy distribution: 58.7\% aggressive, 41.3\% conservative ($\approx$ 50/50)
    \item F1-score: 0.697 (ranked 4th/18 methods)
    \item Balanced precision-recall trade-off
\end{itemize}

Hiệu ứng buffer dilution giải thích tại sao threshold phải được điều chỉnh đáng kể so với giá trị lý thuyết để phương pháp SNR-Adaptive hoạt động hiệu quả trong môi trường production thực tế.
