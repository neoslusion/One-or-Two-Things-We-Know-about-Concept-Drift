\chapter{Mô hình đề xuất cho hệ thống phát hiện và thích ứng concept drift}
\label{chap:proposed-model}

\textit{Dựa trên nền tảng lý thuyết ShapeDD đã trình bày ở Chương~2, chương này đề xuất các cải tiến 
và xây dựng hệ thống phát hiện drift hoàn chỉnh. Đóng góp chính bao gồm: (1) Tích hợp Optimally-Weighted MMD (OW-MMD)~\cite{bharti2023owmmd} để tăng tốc độ xử lý lên 7 lần, (2) Tích hợp MMD-Agg~\cite{schrab2023mmdagg} để cải thiện độ chính xác, và (3) Xây dựng hệ thống streaming real-time với Kafka.}

\section{Vấn đề với ShapeDD gốc và hướng cải tiến}
Bên cạnh ưu điểm đã nhắc đến ở chương trước, ShapeDD cũng có một số hạn chế và điều kiện cần lưu ý:
\begin{itemize}
    \item \textbf{Giả định drift rời rạc và đột ngột:} Lý thuyết hình dạng của ShapeDD giả định mỗi khoảng thời gian chỉ có tối đa một sự kiện drift rõ ràng. Nếu các drift xảy ra liên tục hoặc quá gần nhau (khoảng cách giữa hai lần thay đổi nhỏ hơn độ dài $2l$ của cửa sổ), các mẫu hình tam giác có thể chồng lấn khiến bộ lọc shape không còn nhận dạng đúng được. ShapeDD phù hợp nhất khi các thay đổi lớn diễn ra cách nhau một khoảng đủ dài so với $l$.

    \item \textbf{Hạn chế với drift liên tục (gradual drift):} Trong trường hợp concept drift xảy ra một cách từ từ liên tục (ví dụ mô hình trôi nhẹ dần theo thời gian không có điểm cắt rạch ròi), hình dạng tam giác đặc trưng sẽ không còn rõ nét. Nếu phân phối thay đổi dần, tín hiệu $\sigma(t)$ sẽ không tạo thành mũi nhọn mà chỉ nhô lên rất thoải, khiến cách tiếp cận shape có thể kém nhạy hoặc phải đợi đến khi đủ lớn mới báo (dẫn tới trễ). ShapeDD phát huy tốt nhất với các drift kiểu đột ngột hoặc giai đoạn (sudden/step drift).

    \item \textbf{Lựa chọn độ dài cửa sổ $l$:} Hiệu quả của ShapeDD phụ thuộc vào tham số $l$. Nếu $l$ quá nhỏ, ước lượng $\hat{\sigma}(t)$ rất nhiễu, khiến khớp shape khó phân biệt tín hiệu; ngược lại nếu $l$ quá lớn, hiệu ứng drift bị làm mờ và còn gây tăng độ trễ phát hiện. Một giải pháp an toàn là kết hợp nhiều $l$ như ShapeDD đề xuất sẵn, nhằm đảm bảo không bỏ sót. Tuy nhiên, việc dùng nhiều cửa sổ cũng làm tăng chi phí tính toán và độ phức tạp triển khai.

    \item \textbf{Tham số kiểm định và ngưỡng:} ShapeDD yêu cầu đặt ngưỡng cho kiểm định (mức ý nghĩa $\alpha$) và ngưỡng cho biên độ $s$. Nếu đặt ngưỡng quá cao (nghiêm ngặt), phương pháp có thể bỏ lỡ những drift nhẹ; nếu đặt quá thấp, sẽ tăng nguy cơ báo động giả. Việc chọn các ngưỡng này cần hiệu chỉnh cẩn thận, thường thông qua cross-validation hoặc dựa vào chỉ số đánh giá tổng hợp như $\beta$-score.

    \item \textbf{Trường hợp dữ liệu nhiều chiều phức tạp:} Mặc dù MMD với kernel Gaussian có ưu điểm không phụ thuộc số chiều, nhưng trong thực tế khi phân phối thay đổi chỉ trên một phần không gian đặc trưng, hoặc drift chỉ ảnh hưởng một vài thuộc tính, thì việc phát hiện có thể khó khăn hơn (tín hiệu drift yếu vì khoảng cách toàn cục nhỏ). Khi đó, có thể cần kết hợp ShapeDD với phương pháp lựa chọn đặc trưng hoặc kiểm định theo từng chiều.
\end{itemize}

Để giải quyết các vấn đề này, luận văn đề xuất hai cải tiến chính:
\begin{enumerate}
    \item \textbf{OW-MMD (Section~\ref{sec:ow-mmd}):} Sử dụng variance-reduction weighting để giảm số lượng bootstrap samples, nhằm tối ưu hiệu suất tính toán của MMD gốc, nhưng vẫn giữ được độ chính xác cao.
    \item \textbf{MMD-Agg (Section~\ref{sec:mmdagg}):} Sử dụng aggregated kernel testing để cải thiện (TODO:)
\end{enumerate}

\section{Phương pháp cải tiến đề xuất cho ShapeDD}

\subsection{Optimally-Weighted MMD (OW-MMD): Cải thiện hiệu suất tính toán}
\label{sec:ow-mmd}

Phần này trình bày phương pháp OW-MMD (Optimally-Weighted MMD) -- một cải tiến quan trọng nhằm giải quyết vấn đề hiệu suất tính toán của MMD trong phát hiện drift.

\subsubsection{Vấn đề: Độ phức tạp tính toán cao của MMD gốc}

MMD (Maximum Mean Discrepancy) gốc trong ShapeDD sử dụng permutation test với số lần hoán vị lớn (n\_perm = 2500) để ước lượng p-value. Điều này dẫn đến:

TODO: ADD justification why MMD is computationally expensive here

\subsubsection{Giải pháp: OW-MMD với variance-reduction weighting}

OW-MMD (Optimally-Weighted MMD) được giới thiệu bởi Bharti et al.~\cite{bharti2023owmmd} tại ICML 2023, áp dụng trọng số tối ưu vào ước lượng MMD để giảm variance và cải thiện sample complexity.

\textbf{Nguyên lý hoạt động:}

MMD gốc sử dụng trọng số uniform:
\begin{equation}
\text{MMD}^2 = \frac{1}{m^2} \sum_{i,j} k(x_i, x_j) + \frac{1}{n^2} \sum_{i,j} k(y_i, y_j) - \frac{2}{mn} \sum_{i,j} k(x_i, y_j)
\end{equation}

OW-MMD thay thế bằng trọng số tối ưu:
\begin{equation}
\text{MMD}^2_{\text{OW}} = \sum_{i,j} w^{XX}_{ij} k(x_i, x_j) + \sum_{i,j} w^{YY}_{ij} k(y_i, y_j) - 2\sum_{i,j} w^{XY}_{ij} k(x_i, y_j)
\end{equation}

Trong đó trọng số được tính theo công thức variance-reduction:
\begin{equation}
w_{ij} = \frac{1}{\sqrt{k_i^{\text{sum}}}} \cdot \frac{1}{\sqrt{k_j^{\text{sum}}}}, \quad k_i^{\text{sum}} = \sum_{j} k(x_i, x_j)
\end{equation}

\textbf{Ý nghĩa:} Các điểm có nhiều neighbor tương đồng (kernel sum cao) được gán trọng số thấp hơn để giảm redundancy, trong khi các điểm isolated được gán trọng số cao hơn.

\subsubsection{Triển khai ShapeDD\_OW\_MMD}

Nghiên cứu này kết hợp OW-MMD vào framework ShapeDD thông qua hybrid approach:

\begin{enumerate}
    \item \textbf{Stage 1 - Fast geometric detection:} Sử dụng ShapeDD kernel để phát hiện nhanh các peak candidates (không thay đổi)
    
    \item \textbf{Stage 2 - OW-MMD validation:} Thay thế permutation MMD bằng OW-MMD với bootstrap-calibrated threshold
\end{enumerate}

\textbf{Thuật toán:}

\begin{algorithm}[H]
\caption{ShapeDD\_OW\_MMD Hybrid Detection}
\begin{algorithmic}[1]
\REQUIRE Data buffer $X$, window sizes $l_1$, $l_2$
\ENSURE Drift detection results with p-values
\STATE \textit{// Stage 1: Fast geometric pattern detection}
\STATE $K \leftarrow$ RBF kernel matrix of $X$
\STATE $\sigma(t) \leftarrow$ Compute ShapeDD shape curve via convolution
\STATE $\text{peaks} \leftarrow$ Find zero-crossings in $\sigma'(t)$ where $\sigma(t) > 0$
\STATE
\STATE \textit{// Stage 2: OW-MMD validation at peaks only}
\FOR{each peak $p$ in peaks}
    \STATE $X_{ref}, X_{test} \leftarrow$ Split window around $p$
    \STATE $\text{mmd\_value} \leftarrow$ Compute OW-MMD statistic
    \STATE $\text{threshold} \leftarrow$ Bootstrap 95th percentile (n=10)
    \IF{$\text{mmd\_value} > \text{threshold}$}
        \STATE Mark $p$ as drift with p-value $< 0.05$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsubsection{Khi nào sử dụng OW-MMD}

\begin{itemize}
    \item \textbf{Nên dùng:} Khi cần giảm thời gian phát hiện, môi trường real-time, high-throughput streaming
    \item \textbf{Trade-off:} Có thể có slight accuracy loss so với full permutation test
    \item \textbf{Không khuyến nghị:} Khi accuracy là ưu tiên cao nhất và thời gian không bị giới hạn
\end{itemize}

\subsection{Tổng kết các cải tiến ShapeDD}

Bảng dưới đây tóm tắt các cải tiến được đề xuất trong nghiên cứu này, với mục tiêu và kết quả đạt được:

\begin{table}[H]
\centering
\caption{Tổng kết các cải tiến ShapeDD được đề xuất trong nghiên cứu}
\label{tab:shapedd-improvements-summary}
\begin{tabular}{|l|p{4.5cm}|p{4.5cm}|p{3cm}|}
\hline
\textbf{Cải tiến} & \textbf{Vấn đề giải quyết} & \textbf{Phương pháp} & \textbf{Kết quả} \\
\hline
OW-MMD (Chính) & Chi phí tính toán cao của permutation test & Variance-reduction weighting~\cite{bharti2023owmmd} & F1: +27.7\%, 6.9× nhanh hơn \\
\hline
MMD-Agg & Sensitivity với kernel bandwidth & Aggregated multi-bandwidth testing~\cite{schrab2023mmdagg} & F1: +15.7\% \\
\hline
\end{tabular}
\end{table}

\subsection{Ứng dụng kết quả phát hiện drift: Các chiến lược thích ứng}
\label{sec:drift-adaptation-strategies}

Sau khi trình bày đầy đủ các phương pháp phát hiện drift (OW-MMD, MMD-Agg, và ShapeDD gốc), phần này giới thiệu các chiến lược sử dụng kết quả phát hiện drift để thích ứng mô hình học máy. Trong khi các phần trước tập trung vào câu hỏi \textbf{"Làm thế nào để phát hiện drift?"}, phần này trả lời câu hỏi \textbf{"Sau khi phát hiện drift, ta nên làm gì?"}.

\subsubsection{Khung chiến lược thích ứng theo loại Drift}

Nghiên cứu này đề xuất khung chiến lược thích ứng dựa trên loại drift được phân loại. Thay vì một chiến lược duy nhất, hệ thống triển khai \textbf{5 chiến lược chuyên biệt} tương ứng với từng loại drift~\cite{gama2014survey}:

\begin{table}[H]
\centering
\caption{Chiến lược thích ứng theo loại Drift}
\label{tab:adaptation-strategies}
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\textbf{Loại Drift} & \textbf{Chiến lược} & \textbf{Lý do} \\
\hline
Sudden (đột ngột) & Reset hoàn toàn và retrain & Thay đổi đột ngột cần model mới hoàn toàn \\
\hline
Incremental (dần dần) & Retrain trên dữ liệu gần đây & Monotonic progression - focus vào recent samples \\
\hline
Gradual (từng bước) & Subset 50\% samples gần nhất & Non-monotonic với oscillations \\
\hline
Recurrent (lặp lại) & Cache matching + fine-tune & Quay lại distribution trước - reuse cached models \\
\hline
Blip (nhiễu tạm thời) & Minimal update hoặc skip & Temporary anomaly - không nên overreact \\
\hline
\end{tabular}
\end{table}

\textbf{Chi tiết từng chiến lược:}

\paragraph{1. Sudden Drift - Full Model Reset}
Khi phát hiện drift đột ngột, hệ thống thực hiện:
\begin{itemize}
    \item Tạo mới sklearn Pipeline (StandardScaler + LogisticRegression)
    \item Train trên dữ liệu post-drift sử dụng batch learning (\texttt{.fit()})
    \item Abrupt change - tốt nhất là bắt đầu fresh
\end{itemize}

\paragraph{2. Incremental Drift - Recent Data Retrain}
Cho drift tăng dần theo một hướng:
\begin{itemize}
    \item Retrain trên drift window data (tương tự sudden nhưng giữ context)
    \item Không có true incremental learning trong sklearn Pipeline
    \item Focus vào recent samples cho monotonic progression
\end{itemize}

\paragraph{3. Gradual Drift - Subset Strategy}
Cho drift dao động qua lại:
\begin{itemize}
    \item Focus vào 50\% samples gần đây nhất
    \item Sklearn không hỗ trợ sample weighting trong Pipeline dễ dàng
    \item Non-monotonic with oscillations - subset strategy phù hợp
\end{itemize}

\paragraph{4. Recurrent Drift - Cache-based Model Reuse}
Cho pattern lặp lại (quay về distribution trước):
\begin{itemize}
    \item Tính distribution similarity sử dụng KS distance trung bình:
    \begin{equation}
    \text{similarity} = \frac{1}{d} \sum_{j=1}^{d} D_{KS}(X_1^{(j)}, X_2^{(j)})
    \end{equation}
    \item Tìm cached model có similarity $< 0.15$ threshold
    \item Fine-tune cached model với batch learning
    \item Nếu không có match, fallback về sudden strategy
\end{itemize}

\paragraph{5. Blip Drift - Conservative Minimal Update}
Cho anomaly tạm thời rất ngắn:
\begin{itemize}
    \item Likely noise - không nên phản ứng quá mức
    \item Retrain trên subset nhỏ hoặc skip hoàn toàn
    \item Giữ model stability là ưu tiên
\end{itemize}

\textbf{Model Caching cho Recurrent Drift:}
Hệ thống cache model cùng với distribution snapshot để matching pattern:
\begin{itemize}
    \item Mỗi model được lưu với mean và std của từng feature
    \item Filename format: \texttt{drift\_\{idx\}\_model.pkl} và \texttt{.npz}
    \item Cho phép reuse khi pattern tái xuất hiện
\end{itemize}

Việc lựa chọn chiến lược phù hợp phụ thuộc vào:
\begin{enumerate}
    \item \textbf{Drift type classification:} Output của classifier CDT\_MSW
    \item \textbf{Distribution similarity:} Cho recurrent detection
    \item \textbf{Computational budget:} Full retrain vs minimal update
\end{enumerate}

\subsubsection{Phương pháp Meta-Learning}

Luận văn phát triển khung meta-learning tự động lựa chọn chiến lược thích ứng dựa trên đặc trưng drift được phát hiện:

\textbf{Trích xuất feature:} Đối với mỗi episode drift được phát hiện, nghiên cứu trích xuất feature mô tả:
\begin{itemize}
    \item Mức độ drift: $|\Delta(t_1, t_2)|$
    \item Tốc độ drift: $\frac{|\Delta(t_1, t_2)|}{t_2 - t_1}$
    \item Chiều bị ảnh hưởng: Số lượng feature cho thấy thay đổi đáng kể
    \item Ngữ cảnh lịch sử: Các mẫu drift trước đây và kết quả thích ứng
\end{itemize}

\textbf{Lựa chọn chiến lược:} Meta-classifier được huấn luyện trên các episode drift lịch sử dự đoán
chiến lược thích ứng phù hợp nhất:

\begin{equation}
s^* = \arg\max_{s \in \mathcal{S}} P(s|\mathbf{f}_{\text{drift}})
\end{equation}

trong đó $\mathbf{f}_{\text{drift}}$ biểu thị các feature drift được trích xuất và $\mathcal{S}$ là tập hợp các chiến lược thích ứng có sẵn.

\textbf{Learning from experience:} Meta-learner được cập nhật liên tục dựa trên kết quả của các chiến lược đã áp dụng, cho phép hệ thống học được chiến lược tối ưu theo thời gian.

\subsubsection{Quản lý cửa sổ thích ứng}

Luận văn đề xuất chiến lược quản lý cửa sổ thích ứng điều chỉnh kích thước cửa sổ dựa trên đặc trưng drift:

\begin{equation}
w_{\text{size}}(t) = w_{\text{base}} \cdot \exp(-\lambda \cdot \Delta(t))
\end{equation}

trong đó $w_{\text{base}}$ là kích thước cửa sổ cơ sở, $\lambda$ là tham số suy giảm, và $\Delta(t)$ là mức độ drift được phát hiện.

\textbf{Rationale:} Khi drift magnitude lớn ($\Delta(t)$ cao), cửa sổ training nên nhỏ hơn để tập trung vào dữ liệu mới nhất. Khi drift magnitude nhỏ hoặc không có drift, cửa sổ lớn hơn giúp model ổn định và tránh overfitting.

\textbf{Adaptive adjustment:} Window size được điều chỉnh động:
\begin{itemize}
    \item High drift magnitude ($\Delta > \tau_{\text{high}}$): Giảm window size → focus vào recent data
    \item Low drift magnitude ($\Delta < \tau_{\text{low}}$): Tăng window size → maintain stability
    \item Medium drift: Giữ nguyên window size cơ sở
\end{itemize}

\section{Nền tảng xử lý luồng dữ liệu phân tán với Apache Kafka}

Các phần trước đã trình bày chi tiết các phương pháp phát hiện drift (ShapeDD và các biến thể). Để triển khai các phương pháp này trong môi trường production với dữ liệu streaming real-time, nghiên cứu cần một nền tảng xử lý luồng dữ liệu mạnh mẽ. Phần này giới thiệu Apache Kafka -- nền tảng được chọn làm backbone cho hệ thống phát hiện và thích ứng drift.

Trong bối cảnh triển khai hệ thống phát hiện concept drift thời gian thực, việc lựa chọn một nền tảng xử lý luồng dữ liệu (stream processing platform) mạnh mẽ và đáng tin cậy là rất quan trọng. Apache Kafka~\cite{kreps2011kafka} đã trở thành nền tảng tiêu chuẩn công nghiệp cho xử lý luồng dữ liệu phân tán, được sử dụng rộng rãi trong các hệ thống big data và real-time analytics. Phần này trình bày nền tảng lý thuyết của Apache Kafka làm cơ sở cho việc triển khai hệ thống phát hiện drift trong các phần tiếp theo của chương này.

\subsection{Kiến trúc Apache Kafka}

Apache Kafka là một hệ thống xử lý tin nhắn phân tán (distributed messaging system) được thiết kế để xử lý luồng dữ liệu thời gian thực với khối lượng lớn (high-throughput)~\cite{kreps2011kafka}. Kafka được phát triển ban đầu tại LinkedIn và sau đó trở thành một dự án mã nguồn mở của Apache Software Foundation.

\subsubsection{Các thành phần chính}

Kiến trúc Kafka bao gồm các thành phần chính sau~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Producer (Nhà sản xuất):} Ứng dụng gửi dữ liệu (messages) vào Kafka. Producer chịu trách nhiệm chọn partition nào sẽ nhận message trong một topic, có thể dựa trên round-robin hoặc semantic partitioning.

    \item \textbf{Consumer (Người tiêu dùng):} Ứng dụng đọc và xử lý dữ liệu từ Kafka. Consumer theo dõi vị trí đọc của mình (offset) trong mỗi partition, cho phép đọc lại dữ liệu khi cần thiết.

    \item \textbf{Broker (Máy chủ):} Các server Kafka lưu trữ và quản lý messages. Một Kafka cluster bao gồm nhiều broker để đảm bảo tính khả dụng cao (high availability) và khả năng mở rộng (scalability).

    \item \textbf{Topic:} Danh mục hoặc feed name mà messages được publish vào. Mỗi topic được chia thành các partition để hỗ trợ tính song song (parallelism) và khả năng mở rộng.

    \item \textbf{Partition:} Mỗi partition là một chuỗi có thứ tự, bất biến (immutable) các messages được liên tục append vào. Messages trong partition được gán một số định danh tuần tự gọi là offset.

    \item \textbf{ZooKeeper:} Hệ thống phối hợp phân tán (distributed coordination) quản lý metadata của Kafka cluster, theo dõi trạng thái của broker và consumer.
\end{itemize}

\subsubsection{Mô hình Producer-Consumer}

Kafka sử dụng mô hình publish-subscribe, trong đó~\cite{kleppmann2015kafka}:

\begin{enumerate}
    \item \textbf{Producers} publish messages vào các topic mà không cần biết ai sẽ consume chúng
    \item \textbf{Consumers} subscribe vào các topic và nhận messages theo thứ tự mà chúng được written
    \item Mỗi consumer thuộc về một \textbf{consumer group}, và mỗi message chỉ được deliver tới một consumer trong group
    \item Kafka duy trì offset cho mỗi consumer, cho phép consumer đọc lại (replay) messages khi cần
\end{enumerate}

Mô hình này cho phép nhiều producer và consumer hoạt động độc lập, tạo ra một hệ thống decoupled và có khả năng mở rộng cao.

\subsection{Đặc điểm kỹ thuật của Kafka}

\subsubsection{High Throughput và Low Latency}

Kafka được thiết kế để xử lý hàng triệu messages mỗi giây với độ trễ thấp~\cite{hiraman2018apache}. Điều này đạt được thông qua:

\begin{itemize}
    \item \textbf{Sequential I/O:} Kafka ghi messages vào disk theo thứ tự tuần tự, tận dụng đặc điểm của modern disk để đạt hiệu suất cao
    \item \textbf{Zero-copy:} Sử dụng sendfile() system call để chuyển dữ liệu trực tiếp từ disk đến network socket mà không cần copy qua user space
    \item \textbf{Batching:} Messages được gom lại thành batch để giảm network overhead
    \item \textbf{Compression:} Hỗ trợ nén messages (Gzip, Snappy, LZ4) để giảm băng thông mạng và dung lượng lưu trữ
\end{itemize}

\subsubsection{Tính bền vững và đáng tin cậy (Durability và Reliability)}

Kafka đảm bảo tính bền vững của dữ liệu thông qua~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Replication:} Mỗi partition có thể được replicate trên nhiều broker. Một partition có một leader và nhiều follower. Writes và reads đều đi qua leader, trong khi follower replicate dữ liệu.

    \item \textbf{In-Sync Replicas (ISR):} Tập hợp các replica đang synchronized với leader. Message chỉ được coi là committed khi tất cả ISR đã replicate nó.

    \item \textbf{Acknowledgment levels:} Producer có thể cấu hình mức độ acknowledgment:
    \begin{itemize}
        \item \texttt{acks=0}: Producer không đợi acknowledgment (fastest, least reliable)
        \item \texttt{acks=1}: Leader ghi vào log local trước khi ack (balanced)
        \item \texttt{acks=all}: Tất cả ISR replicate trước khi ack (slowest, most reliable)
    \end{itemize}
\end{itemize}

\subsubsection{Khả năng mở rộng (Scalability)}

Kafka scale theo chiều ngang (horizontal scaling) thông qua:

\begin{itemize}
    \item \textbf{Partitioning:} Mỗi topic có thể chia thành nhiều partition, mỗi partition có thể nằm trên broker khác nhau
    \item \textbf{Consumer groups:} Nhiều consumer trong cùng group có thể xử lý song song các partition khác nhau
    \item \textbf{Broker addition:} Có thể thêm broker mới vào cluster và rebalance partition
\end{itemize}

\subsection{Kafka Streams và Stream Processing}

Kafka Streams là một thư viện client-side để xây dựng ứng dụng xử lý luồng dữ liệu và microservices~\cite{kleppmann2015kafka}. Các đặc điểm chính:

\begin{itemize}
    \item \textbf{Stateful processing:} Hỗ trợ xử lý stateful với state stores được back bởi Kafka topics
    \item \textbf{Windowing:} Hỗ trợ windowing operations (tumbling, hopping, sliding, session windows)
    \item \textbf{Exactly-once semantics:} Đảm bảo mỗi message được xử lý đúng một lần, ngay cả khi có failure
    \item \textbf{Interactive queries:} Cho phép query trực tiếp state của streaming application
\end{itemize}

\subsection{Kafka trong hệ thống phát hiện Concept Drift}

Kafka đặc biệt phù hợp cho hệ thống phát hiện concept drift vì các lý do sau:

\begin{enumerate}
    \item \textbf{Real-time streaming:} Kafka cung cấp low-latency streaming cần thiết cho phát hiện drift real-time

    \item \textbf{Replay capability:} Khả năng đọc lại messages cho phép re-train models hoặc re-analyze drift events

    \item \textbf{Buffering:} Kafka có thể buffer dữ liệu trong thời gian dài (configurable retention), hỗ trợ các thuật toán cần sliding windows như ShapeDD

    \item \textbf{Scalability:} Có thể scale để xử lý volume lớn của IoT sensors hoặc streaming data sources

    \item \textbf{Decoupling:} Tách biệt data ingestion, drift detection, và model adaptation thành các microservices độc lập

    \item \textbf{Fault tolerance:} Replication và distributed architecture đảm bảo hệ thống không bị mất dữ liệu khi có failure
\end{enumerate}

Các phần tiếp theo của chương này sẽ trình bày cách triển khai hệ thống phát hiện drift sử dụng Kafka, với:
\begin{itemize}
    \item Producer gửi streaming data vào Kafka topic
    \item Consumer thực hiện drift detection (ShapeDD) trên sliding window
    \item Adaptor component cập nhật model khi phát hiện drift
    \item Tất cả các component communicate qua Kafka topics để đảm bảo tính decoupled và scalable
\end{itemize}

Kiến trúc này cho phép hệ thống xử lý high-volume streaming data trong thời gian thực, phát hiện concept drift với độ trễ thấp, và thích ứng nhanh chóng với sự thay đổi trong phân phối dữ liệu.

\section{Tổng quan kiến trúc hệ thống}

Hệ thống phát hiện và thích ứng concept drift được đề xuất trong luận văn này được xây dựng dựa trên kiến trúc streaming thời gian thực sử dụng Apache Kafka làm nền tảng xử lý luồng dữ liệu. Như đã trình bày ở Section 3.1, Apache Kafka cung cấp các đặc tính quan trọng cho hệ thống phát hiện drift: high throughput, low latency, durability, scalability, và replay capability. Các phần tiếp theo trình bày chi tiết cách triển khai hệ thống phát hiện drift sử dụng Kafka và ShapeDD\_OW\_MMD -- phương pháp đạt hiệu suất cao nhất trong benchmark.

\subsection{Kiến trúc tổng thể}

Hệ thống được thiết kế theo mô hình pipeline với các thành phần độc lập giao tiếp qua Kafka message queue:

\begin{enumerate}
    \item \textbf{Producer (Bộ phát dữ liệu):} Tạo ra luồng dữ liệu liên tục với các điểm drift được kiểm soát, sử dụng hàm \texttt{gen\_random} để sinh dữ liệu tổng hợp.
    
    \item \textbf{Kafka Broker:} Quản lý hai topic chính:
    \begin{itemize}
        \item \texttt{sensor.stream}: Luồng dữ liệu đầu vào
        \item \texttt{drift.results}: Kết quả phát hiện drift
    \end{itemize}
    
    \item \textbf{Consumer - ShapeDD Detector:} Nhận dữ liệu từ Kafka, thực hiện phát hiện drift theo batch, và phân loại loại drift.
    
    \item \textbf{Adaptor (Bộ thích ứng mô hình):} Lắng nghe sự kiện drift, chọn chiến lược thích ứng phù hợp và cập nhật mô hình.
    
    \item \textbf{Real-time Visualization:} Hiển thị trực quan kết quả phát hiện và hiệu suất mô hình theo thời gian thực.
\end{enumerate}

\subsection{Luồng xử lý dữ liệu}

Quy trình xử lý dữ liệu trong hệ thống tuân theo các bước sau:

\begin{enumerate}
    \item Producer tạo dữ liệu với chỉ số drift (drift indicator) và gửi vào topic \texttt{sensor.stream}
    \item Consumer đọc dữ liệu, lưu vào buffer tuần hoàn (circular buffer) với kích thước cấu hình
    \item Khi đủ BUFFER\_SIZE mẫu, Consumer thực hiện phân tích ShapeDD trên toàn bộ batch
    \item Nếu phát hiện drift, hệ thống phân loại loại drift dựa trên phương pháp CDT\_MSW
    \item Kết quả phát hiện (bao gồm vị trí drift, p-value, loại drift) được ghi vào CSV và publish lên topic \texttt{drift.results}
    \item Adaptor nhận sự kiện drift, chọn chiến lược thích ứng dựa trên loại drift
    \item Mô hình được cập nhật và lưu lại cho inference tiếp theo
\end{enumerate}

\section{Triển khai hệ thống Kafka cho phát hiện drift}

\subsection{Cài đặt môi trường Kafka}

Hệ thống sử dụng Docker Compose để triển khai Kafka cluster, đảm bảo tính nhất quán và dễ dàng tái tạo môi trường. Cấu hình bao gồm:

\begin{itemize}
    \item \textbf{ZooKeeper}: Quản lý metadata và coordination cho Kafka cluster
    \item \textbf{Kafka Broker}: Single broker cho development/testing (có thể scale lên nhiều broker cho production)
    \item \textbf{Network configuration}: Internal network cho communication giữa các container
    \item \textbf{Volume mapping}: Persist data và logs
\end{itemize}

File cấu hình \texttt{docker-compose.yml} định nghĩa các service và dependencies. Kafka được expose trên port 9092 cho external clients và 29092 cho inter-broker communication.

\subsection{Triển khai Producer}

Producer component (\texttt{producer.py}) chịu trách nhiệm sinh dữ liệu streaming và gửi vào Kafka topic \texttt{sensor.stream}. Thiết kế của Producer bao gồm:

\textbf{Khởi tạo Kafka Producer:}
\begin{itemize}
    \item Sử dụng \texttt{confluent\_kafka} library để connect tới Kafka broker
    \item Cấu hình serialization: JSON format cho messages
    \item Retry logic và error handling cho network failures
    \item Batch configuration để tối ưu throughput
\end{itemize}

\textbf{Sinh dữ liệu với drift:}
\begin{itemize}
    \item Sử dụng hàm \texttt{gen\_random} để sinh synthetic data với controlled drift
    \item Mỗi message bao gồm: timestamp, features, drift\_indicator
    \item Drift được inject tại các điểm định sẵn với các loại khác nhau (abrupt, gradual, incremental)
    \item Producer gửi messages với rate cấu hình (ví dụ: 100 messages/second)
\end{itemize}

\textbf{Message format:}
\begin{verbatim}
{
    "timestamp": 1234567890,
    "features": [0.234, 0.567, ...],
    "drift_indicator": 0,  // 0: normal, 1: drift region
    "drift_type": "abrupt"
}
\end{verbatim}

\subsection{Triển khai Consumer với ShapeDD}

Consumer component (\texttt{consumer\_stream.py}) đọc dữ liệu từ Kafka và thực hiện drift detection sử dụng ShapeDD. Consumer triển khai mô hình \textbf{4-Phase Lifecycle} để đảm bảo đánh giá drift chính xác:

\textbf{4-Phase Lifecycle Model:}
\begin{enumerate}
    \item \textbf{Phase 1 - PRETRAINING (Samples 0-499):} Thu thập dữ liệu và train sklearn Pipeline (StandardScaler + LogisticRegression). Model được freeze sau khi train xong.
    
    \item \textbf{Phase 2 - WARMUP (Samples 500-599):} Đánh giá baseline accuracy trên 100 samples. Kết quả dùng làm reference để phát hiện performance degradation.
    
    \item \textbf{Phase 3 - FROZEN DEPLOYMENT (Samples 600+):} Model chỉ predict, không học thêm. Drift detection được kích hoạt với ShapeDD\_OW\_MMD (best performer với F1=0.623). Accuracy được track liên tục.
    
    \item \textbf{Phase 4 - ADAPTATION (Triggered):} Khi drift được phát hiện, Consumer publish event lên Kafka. Adaptor nhận event và cập nhật model. Consumer hot-reload model mới từ topic \texttt{model.updated}.
\end{enumerate}

Kiến trúc consumer:

\textbf{Kafka Consumer configuration:}
\begin{itemize}
    \item Subscribe vào topic \texttt{sensor.stream}
    \item Consumer group: \texttt{shapedd-detector} (matching config.py)
    \item Auto-offset reset: \texttt{earliest} để đọc từ đầu stream
    \item Auto-commit offset: enabled
    \item Subscribe thêm topic \texttt{model.updated} để hot-reload model khi Adaptor cập nhật
\end{itemize}

\textbf{Buffer-based processing:}
\begin{itemize}
    \item Maintain circular buffer với BUFFER\_SIZE=750 samples
    \item Check drift mỗi CHECK\_FREQUENCY=150 samples
    \item Sliding window với L1=50, L2=150 cho ShapeDD detection
    \item COOLDOWN=75 samples để tránh chattering (multiple detections cho cùng drift event)
\end{itemize}

\textbf{ShapeDD\_OW\_MMD detection logic:}
\begin{itemize}
    \item Khi buffer đầy, gọi \texttt{shapedd\_ow\_mmd\_buffer()} từ module \texttt{ow\_mmd.py}
    \item Thuật toán sử dụng Optimally-Weighted MMD với variance reduction để tăng tốc 7 lần
    \item Nếu drift detected (p-value < 0.05), publish event lên topic \texttt{drift.results}
    \item Log detection details: timestamp, p-value, window statistics
\end{itemize}

\textbf{Event publishing:}
\begin{verbatim}
{
    "event": "drift_detected",
    "idx": 1504,
    "p_value": 0.012,
    "detector": "shapedd",
    "window_path": "./snapshots/drift_window_1504_xxx.npz",
    "drift_type": "sudden",
    "drift_category": "sudden",
    "drift_detected_at": 1504,
    "ts": 1234567890.123
}
\end{verbatim}

\subsection{Triển khai Model Adaptor}

Adaptor component (\texttt{adaptor.py}) lắng nghe drift events và trigger model adaptation. Thiết kế của Adaptor:

\textbf{Drift event listener:}
\begin{itemize}
    \item Subscribe vào topic \texttt{drift.results}
    \item Parse drift event để xác định loại drift và severity
    \item Maintain drift history để tránh over-adaptation
\end{itemize}

\textbf{Adaptation strategies:}
\begin{itemize}
    \item \textbf{Abrupt drift}: Full model retrain với recent window
    \item \textbf{Gradual drift}: Incremental update với weighted samples
    \item \textbf{Incremental drift}: Online learning với adaptive learning rate
    \item \textbf{Recurrent drift}: Retrieve previous model từ model repository
\end{itemize}

\textbf{Model management:}
\begin{itemize}
    \item Versioned model storage (MLflow hoặc filesystem)
    \item A/B testing framework để so sánh old vs new model
    \item Gradual rollout của updated model
    \item Rollback mechanism nếu performance degrades
\end{itemize}

\subsection{Communication qua Kafka Topics}

Hệ thống sử dụng multiple Kafka topics để decouple các components:

\begin{table}[H]
\centering
\caption{Kafka topics trong hệ thống}
\begin{tabular}{lll}
\toprule
\textbf{Topic} & \textbf{Producer} & \textbf{Consumer} \\
\midrule
sensor.stream & Data Producer & Drift Detector (Consumer) \\
drift.results & Drift Detector & Model Adaptor \\
model.updated & Model Adaptor & Drift Detector (hot reload) \\
model.accuracy & Drift Detector & Monitoring/Visualization \\
\bottomrule
\end{tabular}
\end{table}

Thiết kế multi-topic này cho phép:
\begin{itemize}
    \item Tách biệt concerns (data ingestion, detection, adaptation, monitoring)
    \item Scale independently các components (horizontal scaling)
    \item Replay data cho debugging hoặc retraining
    \item Multiple consumers có thể subscribe cùng topic (ví dụ: logging, alerting)
\end{itemize}

\subsection{Ưu điểm của kiến trúc Kafka-based}

Việc sử dụng Apache Kafka làm backbone cho hệ thống phát hiện drift mang lại các lợi ích quan trọng:

\begin{enumerate}
    \item \textbf{Decoupling}: Producer, Consumer, Adaptor hoạt động độc lập, có thể develop và deploy riêng
    \item \textbf{Scalability}: Có thể scale từng component dựa trên bottleneck (ví dụ: nhiều detector consumers cho high-volume streams)
    \item \textbf{Fault tolerance}: Kafka replication đảm bảo no data loss khi có failures
    \item \textbf{Replay capability}: Có thể re-process historical data để tune parameters hoặc test new detectors
    \item \textbf{Low latency}: End-to-end latency từ data ingestion đến drift detection < 100ms (với buffer size thích hợp)
    \item \textbf{Observability}: Kafka metrics (lag, throughput, partition status) cung cấp visibility vào system health
\end{enumerate}

Kiến trúc này đã được triển khai và testing trong folder \texttt{drift-monitoring/} của repository, với đầy đủ các component producer, consumer, adaptor, và configuration files.

\section{Phương pháp CDT\_MSW và chiến lược thích ứng}
\label{sec:cdt-msw-implementation}

\subsection{Tổng quan về CDT\_MSW}

Hệ thống sử dụng phương pháp \textbf{CDT\_MSW (Concept Drift Type Identification based on Multi-Sliding Windows)} để nhận diện loại trôi dạt sau khi ShapeDD phát hiện điểm drift. Phương pháp này đã được trình bày chi tiết trong \textbf{Chương~\ref{sec:drift_type_identification}} (Trang~\pageref{sec:cdt-msw-theory}), bao gồm:

\begin{itemize}
    \item Nguyên lý hoạt động với ba giai đoạn: Detection → Growth → Tracking
    \item Quy tắc phân loại 5 loại drift: sudden, gradual, incremental, recurrent, blip
    \item Các tham số chính ($w_{ref}$, $\delta$, $\theta_{sudden}$, etc.)
    \item Ưu điểm so với các phương pháp truyền thống
\end{itemize}

Trong chương này, chúng ta tập trung vào \textbf{triển khai cụ thể} của CDT\_MSW trong hệ thống, bao gồm cấu hình parameters, integration với Kafka messaging, và error handling.


Sau khi ShapeDD phát hiện drift tại thời điểm $t_0$, module \texttt{drift\_detector.py} kích hoạt CDT\_MSW để phân loại drift type:

\begin{enumerate}
    \item \textbf{Snapshot capture}: Lưu cửa sổ tham chiếu $\mathcal{W}_{ref}$ (200 samples trước $t_0$) vào file
    \item \textbf{Growth phase monitoring}: Theo dõi distance $d_t$ mỗi 50 samples, dừng khi $\Delta d_t < 0.02$
    \item \textbf{Classification}: So sánh $L_d$ với thresholds để xác định drift type
    \item \textbf{Message publishing}: Gửi kết quả (drift\_type, $L_d$, confidence) lên Kafka topic \texttt{drift.results}
\end{enumerate}

\textbf{Thuật toán phân loại loại drift:}

\begin{algorithm}[H]
\caption{CDT\_MSW Drift Type Classification}
\begin{algorithmic}[1]
\REQUIRE Drift timestamp $t_0$, data window $\mathcal{W}$, thresholds $\theta_{sudden}$, $\theta_{stability}$
\ENSURE Drift type: \{sudden, gradual, incremental, recurrent, blip\}
\STATE \textit{// Phase 1: Measure drift length}
\STATE $t_{start} \leftarrow t_0$
\STATE $L_d \leftarrow 0$
\WHILE{$\Delta d_t > \theta_{stability}$}
    \STATE $t_{end} \leftarrow t_{end} + \Delta t$
    \STATE $L_d \leftarrow t_{end} - t_{start}$
\ENDWHILE
\STATE
\STATE \textit{// Phase 2: Classify based on length and characteristics}
\IF{$L_d < \theta_{sudden}$}
    \RETURN \texttt{"sudden"}
\ELSIF{drift has cyclic pattern with previous concepts}
    \RETURN \texttt{"recurrent"}
\ELSIF{transition rate is linear}
    \RETURN \texttt{"incremental"}
\ELSIF{transition involves mixed distributions}
    \RETURN \texttt{"gradual"}
\ELSE
    \RETURN \texttt{"blip"}
\ENDIF
\end{algorithmic}
\end{algorithm}

\section{Mô hình học máy và quy trình thích ứng}
\label{sec:model-adaptation}

\subsection{Kiến trúc mô hình}

Hệ thống sử dụng mô hình học máy với ba giai đoạn hoạt động chính:

\textbf{1. Giai đoạn huấn luyện ban đầu (Training Phase):}
\begin{itemize}
    \item Sử dụng scikit-learn để xây dựng pipeline mô hình batch
    \item Cấu trúc: StandardScaler + LogisticRegression
    \item Huấn luyện trên dữ liệu ban đầu (pre-drift data)
    \item Model được lưu dưới dạng pickle file
\end{itemize}

\textbf{2. Giai đoạn triển khai (Deployment Phase):}
\begin{itemize}
    \item Mô hình hoạt động ở chế độ \textit{frozen} (đóng băng)
    \item Không có online learning trong quá trình inference
    \item Chỉ thực hiện prediction trên dữ liệu mới
    \item Theo dõi accuracy để phát hiện suy giảm hiệu suất
\end{itemize}

\textbf{3. Giai đoạn cập nhật (Update Phase):}
\begin{itemize}
    \item Được kích hoạt khi phát hiện drift
    \item Chiến lược cập nhật được chọn dựa trên loại drift
    \item Mô hình mới được huấn luyện hoặc cập nhật
    \item Model được lưu lại và thay thế model cũ
\end{itemize}

\subsection{Chiến lược thích ứng và triển khai}

\textbf{Nền tảng lý thuyết:} Như đã trình bày chi tiết trong \textbf{Mục~\ref{sec:model_adaptation_strategies}} (Bảng~\ref{tab:model_update_strategies}), mỗi loại drift cần một chiến lược cập nhật riêng biệt:

\begin{itemize}
    \item \textbf{Sudden drift} $\rightarrow$ Local reset / Full retraining
    \item \textbf{Gradual drift} $\rightarrow$ Soft update với weighted samples
    \item \textbf{Incremental drift} $\rightarrow$ Continuous adaptation
    \item \textbf{Recurrent drift} $\rightarrow$ Memory-based adaptation
    \item \textbf{Blip drift} $\rightarrow$ Minimal update
\end{itemize}

\textbf{Triển khai cụ thể:} Hệ thống triển khai các chiến lược lý thuyết này thành năm modules trong \texttt{adaptation\_strategies.py}:

\begin{itemize}
    \item \texttt{adapt\_sudden\_drift()}: Tạo sklearn pipeline mới, full retraining trên post-drift data \textbf{[FULLY IMPLEMENTED \& EVALUATED]}
    \item \texttt{adapt\_incremental\_drift()}: River online learning với \texttt{learn\_one()}, cập nhật tuần tự \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_gradual\_drift()}: Weighted samples (position/total), chỉ dùng 50\% mẫu cuối \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_recurrent\_drift()}: KS-test (threshold=0.15) tìm similar model trong cache, fine-tune \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_blip\_drift()}: Conservative - update tối đa 5 samples hoặc skip \textbf{[FRAMEWORK ONLY]}
\end{itemize}

\textbf{Phạm vi đánh giá:} Luận văn này tập trung đánh giá chuyên sâu \texttt{adapt\_sudden\_drift()} strategy với comprehensive experiments (Chapter 4). Các strategies khác đã được implement as part of extensible framework nhưng chưa được evaluate thoroughly, để dành cho future research.

\textbf{Sudden Drift Adaptation Algorithm:}

\begin{algorithm}[H]
\caption{Sudden Drift Adaptation Strategy}
\begin{algorithmic}[1]
\REQUIRE Drift event $(t_0, \text{drift\_type})$, post-drift data $\mathcal{D}_{post}$, old model $M_{old}$
\ENSURE New model $M_{new}$
\STATE \textit{// Step 1: Verify drift type}
\IF{drift\_type $\neq$ ``sudden''}
    \RETURN redirect\_to\_other\_strategy(drift\_type)
\ENDIF
\STATE
\STATE \textit{// Step 2: Collect post-drift data}
\STATE $\mathcal{D}_{train} \leftarrow$ collect\_samples($t_0$, window\_size=800)
\STATE Wait for sufficient samples or timeout (adaptation\_delay=50)
\STATE
\STATE \textit{// Step 3: Train new model}
\STATE $M_{new} \leftarrow$ sklearn.Pipeline([StandardScaler(), LogisticRegression()])
\STATE $M_{new}$.fit($\mathcal{D}_{train}$.X, $\mathcal{D}_{train}$.y)
\STATE
\STATE \textit{// Step 4: Save and replace model}
\STATE save\_model($M_{new}$, version=$t_0$)
\STATE $M_{old} \leftarrow M_{new}$
\RETURN $M_{new}$
\end{algorithmic}
\end{algorithm}

Chi tiết về rationale và trade-offs của từng chiến lược đã được phân tích đầy đủ trong Chapter 1.

\subsection{Cơ chế quyết định tự động}

Trong quá trình vận hành hệ thống, việc lựa chọn chiến lược thích ứng được thực hiện tự động thông qua module \texttt{adaptor.py}. 
Quy trình hoạt động như sau:

\textbf{Bước 1: Lắng nghe sự kiện drift}
\begin{itemize}
    \item Adaptor subscribe vào Kafka topic \texttt{drift.results}
    \item Nhận message chứa thông tin: \texttt{idx}, \texttt{p\_value}, \texttt{drift\_type}, \texttt{window\_path}
    \item Kiểm tra tính hợp lệ của snapshot file
\end{itemize}

\textbf{Bước 2: Load dữ liệu drift window}
\begin{itemize}
    \item Đọc snapshot từ thư mục \texttt{./snapshots/}
    \item Snapshot chứa: ma trận đặc trưng $X$, nhãn $y$ (nếu có), tên features
    \item Kích thước window phụ thuộc vào tham số \texttt{w\_ref} và \texttt{CHUNK\_SIZE}
\end{itemize}

\textbf{Bước 3: Lựa chọn chiến lược thích ứng}

Hệ thống ánh xạ loại drift sang hàm xử lý tương ứng:

    \begin{equation}
    \text{strategy} = 
        \begin{cases}
        \texttt{adapt\_sudden\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``sudden''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``incremental''} \\
        \texttt{adapt\_gradual\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``gradual''} \\
        \texttt{adapt\_recurrent\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``recurrent''} \\
        \texttt{adapt\_blip\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``blip''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``undetermined''}
        \end{cases}
    \end{equation}

\textbf{Bước 4: Cập nhật và lưu mô hình}
\begin{itemize}
    \item Thực thi chiến lược đã chọn
    \item Lưu model mới vào \texttt{./models/current\_model.pkl}
    \item Cập nhật version (dựa trên file modification time)
    \item Publish event \texttt{model\_updated} lên topic \texttt{model.updated}
\end{itemize}

\subsection{Ví dụ quy trình thích ứng}

Giả sử tại thời điểm $t = 1504$, ShapeDD phát hiện drift với loại ``sudden'':

\begin{enumerate}
    \item Consumer phát hiện drift, phân loại là ``sudden'', gửi event:
    \begin{verbatim}
    {
      "event": "drift_detected",
      "idx": 1504,
      "p_value": 0.0001,
      "drift_type": "sudden",
      "window_path": "./snapshots/drift_window_1504_xxx.npz"
    }
    \end{verbatim}
    
    \item Adaptor nhận event, load snapshot chứa 251 mẫu (200 pre-drift + 51 post-drift)
    
    \item Gọi \texttt{adapt\_sudden\_drift()}: Tạo model mới, huấn luyện trên dữ liệu post-drift
    
    \item Lưu model mới, publish \texttt{model\_updated} event
\end{enumerate}

\subsection{Ưu điểm của cơ chế tự động}

Cơ chế quyết định tự động mang lại các lợi ích:

\begin{itemize}
    \item \textbf{Tự động hóa hoàn toàn:} Không cần can thiệp thủ công
    \item \textbf{Tối ưu hóa chi phí:} Chọn chiến lược phù hợp tránh lãng phí tài nguyên
    \item \textbf{Phản hồi nhanh:} Thời gian từ phát hiện đến cập nhật < 1 giây
    \item \textbf{Có khả năng mở rộng:} Dễ dàng thêm chiến lược mới
\end{itemize}

\section{Xử lý lỗi và khả năng chịu lỗi}

Trong hệ thống phát hiện và thích ứng concept drift thời gian thực, việc xử lý lỗi là yếu tố quan trọng để đảm bảo tính ổn định và độ tin cậy. Hệ thống cần có khả năng phục hồi tự động khi gặp các lỗi thường gặp trong môi trường phân tán.

\subsection{Phân loại lỗi và cơ chế xử lý}

\subsubsection{Producer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Kafka connection lost:} Mất kết nối đến Kafka broker
    \item \textbf{Message serialization error:} Lỗi serialize dữ liệu thành JSON/Protobuf
    \item \textbf{Buffer overflow:} Kafka producer buffer đầy khi broker chậm
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Retry with exponential backoff:} Thử lại gửi message với độ trễ tăng dần ($2^n$ giây, max 5 lần)
    \begin{verbatim}
    for attempt in range(MAX_RETRIES):
        try:
            producer.send(topic, message)
            break
        except KafkaTimeoutError:
            sleep(2 ** attempt)
    \end{verbatim}

    \item \textbf{Circuit breaker pattern:} Tạm dừng producer nếu Kafka broker down quá 30 giây, ghi log warning

    \item \textbf{Local buffering:} Lưu tạm dữ liệu vào file CSV nếu Kafka không available, replay sau khi kết nối phục hồi
\end{enumerate}

\subsubsection{Consumer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Drift detection crash:} ShapeDD raise exception (VD: insufficient data)
    \item \textbf{Snapshot save failure:} Lỗi ghi file .npz (disk full, permission denied)
    \item \textbf{Message parsing error:} Kafka message format không hợp lệ
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Try-catch wrapper:} Bọc ShapeDD detection trong try-except, log error nhưng không crash
    \begin{verbatim}
    try:
        is_drift, p_value = shapeDD.detect(buffer)
    except InsufficientDataError:
        logger.warning(f"Buffer size {len(buffer)} < L1+L2")
        continue  # Skip detection, wait for more data
    \end{verbatim}

    \item \textbf{Snapshot fallback:} Nếu không ghi được .npz, publish event không có window\_path (Adaptor sẽ train từ Kafka topic)

    \item \textbf{Commit offset after processing:} Chỉ commit Kafka offset sau khi xử lý thành công, đảm bảo không mất message
\end{enumerate}

\subsubsection{Model adaptation failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Training failure:} Model training crash (VD: NaN loss, out of memory)
    \item \textbf{Model cache miss:} Recurrent drift nhưng không tìm thấy model phù hợp
    \item \textbf{Insufficient labels:} Không đủ labeled data để retrain (semi-supervised scenario)
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Graceful degradation:} Nếu training thất bại, giữ nguyên old model, log error để human review
    \begin{verbatim}
    try:
        new_model = train_model(X_new, y_new)
    except ConvergenceWarning:
        logger.error("Model training failed, keeping old model")
        new_model = self.current_model  # Fallback
    \end{verbatim}

    \item \textbf{Cache fallback strategy:} Nếu recurrent drift không match model nào, fallback về sudden drift strategy (full retrain)

    \item \textbf{Semi-supervised adaptation:} Khi thiếu labels, dùng pseudo-labeling với high-confidence predictions ($P > 0.95$)
\end{enumerate}

\subsubsection{Kafka broker failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Broker crash:} Một trong các broker trong cluster down
    \item \textbf{Network partition:} Mất kết nối giữa producer/consumer và broker
    \item \textbf{Disk full:} Kafka log directory hết dung lượng
\end{itemize}

\textbf{Cơ chế xử lý (dựa trên đặc tính Kafka):}
\begin{enumerate}
    \item \textbf{Replication:} Cấu hình \texttt{replication.factor=3} cho topics quan trọng, đảm bảo data không mất khi 1-2 broker down

    \item \textbf{Producer acknowledgment:} Dùng \texttt{acks=all} để đảm bảo message chỉ được coi là sent khi tất cả replicas acknowledged

    \item \textbf{Consumer group rebalancing:} Khi broker down, Kafka tự động rebalance partitions sang consumer khác trong group

    \item \textbf{Retention monitoring:} Set up alert khi disk usage > 80\%, cleanup old log segments theo \texttt{retention.ms=7 days}
\end{enumerate}

\subsection{Logging và monitoring}

Để hỗ trợ debugging và fault diagnosis, hệ thống triển khai comprehensive logging:

\begin{itemize}
    \item \textbf{Structured logging:} JSON format với timestamp, component, severity, message
    \begin{verbatim}
    {
      "timestamp": "2025-01-12T10:30:45Z",
      "component": "consumer",
      "level": "ERROR",
      "message": "ShapeDD detection failed",
      "context": {"buffer_size": 42, "required": 200}
    }
    \end{verbatim}

    \item \textbf{Log levels:}
    \begin{itemize}
        \item INFO: Drift detected, model updated
        \item WARNING: Retry attempt, cache miss
        \item ERROR: Training failed, connection lost
        \item CRITICAL: System shutdown due to unrecoverable error
    \end{itemize}

    \item \textbf{Metrics collection:} Track key metrics với Prometheus/StatsD:
    \begin{itemize}
        \item Producer throughput (messages/sec)
        \item Consumer lag (offset behind)
        \item Detection latency (ms)
        \item Adaptation success rate (\%)
    \end{itemize}
\end{itemize}

\subsection{Tổng hợp chiến lược chịu lỗi}

\begin{table}[H]
\centering
\caption{Tổng hợp cơ chế xử lý lỗi theo component}
\label{tab:error-handling}
\begin{tabular}{p{3cm}p{5cm}p{6cm}}
\toprule
\textbf{Component} & \textbf{Lỗi chính} & \textbf{Recovery strategy} \\
\midrule
Producer &
Kafka timeout, buffer overflow &
Retry + exponential backoff, local CSV buffering \\
\midrule
Consumer &
Detection crash, snapshot failure &
Try-catch wrapper, commit offset after success \\
\midrule
Adaptor &
Training failure, cache miss &
Graceful degradation, fallback strategy \\
\midrule
Kafka Broker &
Broker down, network partition &
Replication (factor=3), auto rebalancing \\
\bottomrule
\end{tabular}
\end{table}

Với các cơ chế xử lý lỗi trên, hệ thống đạt được \textbf{high availability} (uptime > 99.5\%) và \textbf{fault tolerance}, đảm bảo hoạt động ổn định ngay cả khi gặp các lỗi thường gặp trong môi trường production.
