\chapter{Mô hình đề xuất cho hệ thống phát hiện và thích ứng concept drift}
\label{chap:proposed-model}

\section{Nền tảng xử lý luồng dữ liệu phân tán với Apache Kafka}

Trong bối cảnh triển khai hệ thống phát hiện concept drift thời gian thực, việc lựa chọn một nền tảng xử lý luồng dữ liệu (stream processing platform) mạnh mẽ và đáng tin cậy là rất quan trọng. Apache Kafka~\cite{kreps2011kafka} đã trở thành nền tảng tiêu chuẩn công nghiệp cho xử lý luồng dữ liệu phân tán, được sử dụng rộng rãi trong các hệ thống big data và real-time analytics. Phần này trình bày nền tảng lý thuyết của Apache Kafka làm cơ sở cho việc triển khai hệ thống phát hiện drift trong các phần tiếp theo của chương này.

\subsection{Kiến trúc Apache Kafka}

Apache Kafka là một hệ thống xử lý tin nhắn phân tán (distributed messaging system) được thiết kế để xử lý luồng dữ liệu thời gian thực với khối lượng lớn (high-throughput)~\cite{kreps2011kafka}. Kafka được phát triển ban đầu tại LinkedIn và sau đó trở thành một dự án mã nguồn mở của Apache Software Foundation.

\subsubsection{Các thành phần chính}

Kiến trúc Kafka bao gồm các thành phần chính sau~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Producer (Nhà sản xuất):} Ứng dụng gửi dữ liệu (messages) vào Kafka. Producer chịu trách nhiệm chọn partition nào sẽ nhận message trong một topic, có thể dựa trên round-robin hoặc semantic partitioning.

    \item \textbf{Consumer (Người tiêu dùng):} Ứng dụng đọc và xử lý dữ liệu từ Kafka. Consumer theo dõi vị trí đọc của mình (offset) trong mỗi partition, cho phép đọc lại dữ liệu khi cần thiết.

    \item \textbf{Broker (Máy chủ):} Các server Kafka lưu trữ và quản lý messages. Một Kafka cluster bao gồm nhiều broker để đảm bảo tính khả dụng cao (high availability) và khả năng mở rộng (scalability).

    \item \textbf{Topic:} Danh mục hoặc feed name mà messages được publish vào. Mỗi topic được chia thành các partition để hỗ trợ tính song song (parallelism) và khả năng mở rộng.

    \item \textbf{Partition:} Mỗi partition là một chuỗi có thứ tự, bất biến (immutable) các messages được liên tục append vào. Messages trong partition được gán một số định danh tuần tự gọi là offset.

    \item \textbf{ZooKeeper:} Hệ thống phối hợp phân tán (distributed coordination) quản lý metadata của Kafka cluster, theo dõi trạng thái của broker và consumer.
\end{itemize}

\subsubsection{Mô hình Producer-Consumer}

Kafka sử dụng mô hình publish-subscribe, trong đó~\cite{kleppmann2015kafka}:

\begin{enumerate}
    \item \textbf{Producers} publish messages vào các topic mà không cần biết ai sẽ consume chúng
    \item \textbf{Consumers} subscribe vào các topic và nhận messages theo thứ tự mà chúng được written
    \item Mỗi consumer thuộc về một \textbf{consumer group}, và mỗi message chỉ được deliver tới một consumer trong group
    \item Kafka duy trì offset cho mỗi consumer, cho phép consumer đọc lại (replay) messages khi cần
\end{enumerate}

Mô hình này cho phép nhiều producer và consumer hoạt động độc lập, tạo ra một hệ thống decoupled và có khả năng mở rộng cao.

\subsection{Đặc điểm kỹ thuật của Kafka}

\subsubsection{High Throughput và Low Latency}

Kafka được thiết kế để xử lý hàng triệu messages mỗi giây với độ trễ thấp~\cite{hiraman2018apache}. Điều này đạt được thông qua:

\begin{itemize}
    \item \textbf{Sequential I/O:} Kafka ghi messages vào disk theo thứ tự tuần tự, tận dụng đặc điểm của modern disk để đạt hiệu suất cao
    \item \textbf{Zero-copy:} Sử dụng sendfile() system call để chuyển dữ liệu trực tiếp từ disk đến network socket mà không cần copy qua user space
    \item \textbf{Batching:} Messages được gom lại thành batch để giảm network overhead
    \item \textbf{Compression:} Hỗ trợ nén messages (Gzip, Snappy, LZ4) để giảm băng thông mạng và dung lượng lưu trữ
\end{itemize}

\subsubsection{Tính bền vững và đáng tin cậy (Durability và Reliability)}

Kafka đảm bảo tính bền vững của dữ liệu thông qua~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Replication:} Mỗi partition có thể được replicate trên nhiều broker. Một partition có một leader và nhiều follower. Writes và reads đều đi qua leader, trong khi follower replicate dữ liệu.

    \item \textbf{In-Sync Replicas (ISR):} Tập hợp các replica đang synchronized với leader. Message chỉ được coi là committed khi tất cả ISR đã replicate nó.

    \item \textbf{Acknowledgment levels:} Producer có thể cấu hình mức độ acknowledgment:
    \begin{itemize}
        \item \texttt{acks=0}: Producer không đợi acknowledgment (fastest, least reliable)
        \item \texttt{acks=1}: Leader ghi vào log local trước khi ack (balanced)
        \item \texttt{acks=all}: Tất cả ISR replicate trước khi ack (slowest, most reliable)
    \end{itemize}
\end{itemize}

\subsubsection{Khả năng mở rộng (Scalability)}

Kafka scale theo chiều ngang (horizontal scaling) thông qua:

\begin{itemize}
    \item \textbf{Partitioning:} Mỗi topic có thể chia thành nhiều partition, mỗi partition có thể nằm trên broker khác nhau
    \item \textbf{Consumer groups:} Nhiều consumer trong cùng group có thể xử lý song song các partition khác nhau
    \item \textbf{Broker addition:} Có thể thêm broker mới vào cluster và rebalance partition
\end{itemize}

\subsection{Kafka Streams và Stream Processing}

Kafka Streams là một thư viện client-side để xây dựng ứng dụng xử lý luồng dữ liệu và microservices~\cite{kleppmann2015kafka}. Các đặc điểm chính:

\begin{itemize}
    \item \textbf{Stateful processing:} Hỗ trợ xử lý stateful với state stores được back bởi Kafka topics
    \item \textbf{Windowing:} Hỗ trợ windowing operations (tumbling, hopping, sliding, session windows)
    \item \textbf{Exactly-once semantics:} Đảm bảo mỗi message được xử lý đúng một lần, ngay cả khi có failure
    \item \textbf{Interactive queries:} Cho phép query trực tiếp state của streaming application
\end{itemize}

\subsection{Kafka trong hệ thống phát hiện Concept Drift}

Kafka đặc biệt phù hợp cho hệ thống phát hiện concept drift vì các lý do sau:

\begin{enumerate}
    \item \textbf{Real-time streaming:} Kafka cung cấp low-latency streaming cần thiết cho phát hiện drift real-time

    \item \textbf{Replay capability:} Khả năng đọc lại messages cho phép re-train models hoặc re-analyze drift events

    \item \textbf{Buffering:} Kafka có thể buffer dữ liệu trong thời gian dài (configurable retention), hỗ trợ các thuật toán cần sliding windows như ShapeDD

    \item \textbf{Scalability:} Có thể scale để xử lý volume lớn của IoT sensors hoặc streaming data sources

    \item \textbf{Decoupling:} Tách biệt data ingestion, drift detection, và model adaptation thành các microservices độc lập

    \item \textbf{Fault tolerance:} Replication và distributed architecture đảm bảo hệ thống không bị mất dữ liệu khi có failure
\end{enumerate}

Các phần tiếp theo của chương này sẽ trình bày cách triển khai hệ thống phát hiện drift sử dụng Kafka, với:
\begin{itemize}
    \item Producer gửi streaming data vào Kafka topic
    \item Consumer thực hiện drift detection (ShapeDD) trên sliding window
    \item Adaptor component cập nhật model khi phát hiện drift
    \item Tất cả các component communicate qua Kafka topics để đảm bảo tính decoupled và scalable
\end{itemize}

Kiến trúc này cho phép hệ thống xử lý high-volume streaming data trong thời gian thực, phát hiện concept drift với độ trễ thấp, và thích ứng nhanh chóng với sự thay đổi trong phân phối dữ liệu.

\section{Tổng quan kiến trúc hệ thống}

Hệ thống phát hiện và thích ứng concept drift được đề xuất trong luận văn này được xây dựng dựa trên kiến trúc streaming thời gian thực sử dụng Apache Kafka làm nền tảng xử lý luồng dữ liệu. Như đã trình bày ở Section 3.1, Apache Kafka cung cấp các đặc tính quan trọng cho hệ thống phát hiện drift: high throughput, low latency, durability, scalability, và replay capability. Các phần tiếp theo trình bày chi tiết cách triển khai hệ thống phát hiện drift sử dụng Kafka và ShapeDD SNR-Adaptive đã được trình bày trong Chapter 2.

\subsection{Kiến trúc tổng thể}

Hệ thống được thiết kế theo mô hình pipeline với các thành phần độc lập giao tiếp qua Kafka message queue:

\begin{enumerate}
    \item \textbf{Producer (Bộ phát dữ liệu):} Tạo ra luồng dữ liệu liên tục với các điểm drift được kiểm soát, sử dụng hàm \texttt{gen\_random} để sinh dữ liệu tổng hợp.
    
    \item \textbf{Kafka Broker:} Quản lý hai topic chính:
    \begin{itemize}
        \item \texttt{sensor.stream}: Luồng dữ liệu đầu vào
        \item \texttt{drift.results}: Kết quả phát hiện drift
    \end{itemize}
    
    \item \textbf{Consumer - ShapeDD Detector:} Nhận dữ liệu từ Kafka, thực hiện phát hiện drift theo batch, và phân loại loại drift.
    
    \item \textbf{Adaptor (Bộ thích ứng mô hình):} Lắng nghe sự kiện drift, chọn chiến lược thích ứng phù hợp và cập nhật mô hình.
    
    \item \textbf{Real-time Visualization:} Hiển thị trực quan kết quả phát hiện và hiệu suất mô hình theo thời gian thực.
\end{enumerate}

\subsection{Luồng xử lý dữ liệu}

Quy trình xử lý dữ liệu trong hệ thống tuân theo các bước sau:

\begin{enumerate}
    \item Producer tạo dữ liệu với chỉ số drift (drift indicator) và gửi vào topic \texttt{sensor.stream}
    \item Consumer đọc dữ liệu, lưu vào buffer tuần hoàn (circular buffer) với kích thước cấu hình
    \item Khi đủ BUFFER\_SIZE mẫu, Consumer thực hiện phân tích ShapeDD trên toàn bộ batch
    \item Nếu phát hiện drift, hệ thống phân loại loại drift dựa trên phương pháp CDT\_MSW
    \item Kết quả phát hiện (bao gồm vị trí drift, p-value, loại drift) được ghi vào CSV và publish lên topic \texttt{drift.results}
    \item Adaptor nhận sự kiện drift, chọn chiến lược thích ứng dựa trên loại drift
    \item Mô hình được cập nhật và lưu lại cho inference tiếp theo
\end{enumerate}

\subsection{Cấu hình hệ thống}

Các tham số quan trọng của hệ thống:

\begin{table}[H]
\centering
\caption{Tham số cấu hình hệ thống}
\label{tab:system-config}
\begin{tabular}{lll}
\toprule
\textbf{Tham số} & \textbf{Giá trị} & \textbf{Ý nghĩa} \\
\midrule
BUFFER\_SIZE & 1000 & Số mẫu xử lý mỗi batch \\
CHUNK\_SIZE & 250 & Kích thước chunk cho phân tích drift \\
SHAPE\_L1 & 50 & Nửa cửa sổ cho ShapeDD \\
SHAPE\_L2 & 250 & Cửa sổ đầy đủ cho MMD \\
SHAPE\_N\_PERM & 2500 & Số lần hoán vị cho kiểm định \\
DRIFT\_PVALUE & 0.05 & Ngưỡng p-value phát hiện drift \\
\bottomrule
\end{tabular}
\end{table}

\section{Triển khai hệ thống Kafka cho phát hiện drift}

\subsection{Cài đặt môi trường Kafka}

Hệ thống sử dụng Docker Compose để triển khai Kafka cluster, đảm bảo tính nhất quán và dễ dàng tái tạo môi trường. Cấu hình bao gồm:

\begin{itemize}
    \item \textbf{ZooKeeper}: Quản lý metadata và coordination cho Kafka cluster
    \item \textbf{Kafka Broker}: Single broker cho development/testing (có thể scale lên nhiều broker cho production)
    \item \textbf{Network configuration}: Internal network cho communication giữa các container
    \item \textbf{Volume mapping}: Persist data và logs
\end{itemize}

File cấu hình \texttt{docker-compose.yml} định nghĩa các service và dependencies. Kafka được expose trên port 9092 cho external clients và 29092 cho inter-broker communication.

\subsection{Triển khai Producer}

Producer component (\texttt{producer.py}) chịu trách nhiệm sinh dữ liệu streaming và gửi vào Kafka topic \texttt{sensor.stream}. Thiết kế của Producer bao gồm:

\textbf{Khởi tạo Kafka Producer:}
\begin{itemize}
    \item Sử dụng \texttt{kafka-python} library để connect tới Kafka broker
    \item Cấu hình serialization: JSON format cho messages
    \item Retry logic và error handling cho network failures
    \item Batch configuration để tối ưu throughput
\end{itemize}

\textbf{Sinh dữ liệu với drift:}
\begin{itemize}
    \item Sử dụng hàm \texttt{gen\_random} để sinh synthetic data với controlled drift
    \item Mỗi message bao gồm: timestamp, features, drift\_indicator
    \item Drift được inject tại các điểm định sẵn với các loại khác nhau (abrupt, gradual, incremental)
    \item Producer gửi messages với rate cấu hình (ví dụ: 100 messages/second)
\end{itemize}

\textbf{Message format:}
\begin{verbatim}
{
    "timestamp": 1234567890,
    "features": [0.234, 0.567, ...],
    "drift_indicator": 0,  // 0: normal, 1: drift region
    "drift_type": "abrupt"
}
\end{verbatim}

\subsection{Triển khai Consumer với ShapeDD}

Consumer component (\texttt{consumer\_stream.py}) đọc dữ liệu từ Kafka và thực hiện drift detection sử dụng ShapeDD. Kiến trúc consumer:

\textbf{Kafka Consumer configuration:}
\begin{itemize}
    \item Subscribe vào topic \texttt{sensor.stream}
    \item Consumer group: \texttt{drift-detector-group} (cho phép scale horizontal)
    \item Auto-commit offset sau khi xử lý thành công
    \item Deserialize JSON messages thành Python objects
\end{itemize}

\textbf{Buffer-based processing:}
\begin{itemize}
    \item Maintain circular buffer với BUFFER\_SIZE=750 samples
    \item Check drift mỗi CHECK\_FREQUENCY=150 samples
    \item Sliding window với L1=50, L2=150 cho ShapeDD detection
    \item COOLDOWN=75 samples để tránh chattering (multiple detections cho cùng drift event)
\end{itemize}

\textbf{ShapeDD detection logic:}
\begin{itemize}
    \item Khi buffer đầy, gọi \texttt{shape\_snr\_adaptive()} từ module \texttt{shape\_dd.py}
    \item Thuật toán tự động ước lượng SNR và chọn strategy (aggressive/conservative)
    \item Nếu drift detected (p-value < 0.05), publish event lên topic \texttt{drift.results}
    \item Log detection details: timestamp, p-value, strategy used, window statistics
\end{itemize}

\textbf{Event publishing:}
\begin{verbatim}
{
    "detection_time": 1234567890,
    "p_value": 0.012,
    "strategy": "aggressive",
    "snr_estimate": 0.015,
    "drift_location": 5432
}
\end{verbatim}

\subsection{Triển khai Model Adaptor}

Adaptor component (\texttt{adaptor.py}) lắng nghe drift events và trigger model adaptation. Thiết kế của Adaptor:

\textbf{Drift event listener:}
\begin{itemize}
    \item Subscribe vào topic \texttt{drift.results}
    \item Parse drift event để xác định loại drift và severity
    \item Maintain drift history để tránh over-adaptation
\end{itemize}

\textbf{Adaptation strategies:}
\begin{itemize}
    \item \textbf{Abrupt drift}: Full model retrain với recent window
    \item \textbf{Gradual drift}: Incremental update với weighted samples
    \item \textbf{Incremental drift}: Online learning với adaptive learning rate
    \item \textbf{Recurrent drift}: Retrieve previous model từ model repository
\end{itemize}

\textbf{Model management:}
\begin{itemize}
    \item Versioned model storage (MLflow hoặc filesystem)
    \item A/B testing framework để so sánh old vs new model
    \item Gradual rollout của updated model
    \item Rollback mechanism nếu performance degrades
\end{itemize}

\subsection{Communication qua Kafka Topics}

Hệ thống sử dụng multiple Kafka topics để decouple các components:

\begin{table}[H]
\centering
\caption{Kafka topics trong hệ thống}
\begin{tabular}{lll}
\toprule
\textbf{Topic} & \textbf{Producer} & \textbf{Consumer} \\
\midrule
sensor.stream & Data Producer & Drift Detector \\
drift.results & Drift Detector & Model Adaptor \\
model.updates & Model Adaptor & Inference Service \\
metrics.monitoring & All components & Monitoring Dashboard \\
\bottomrule
\end{tabular}
\end{table}

Thiết kế multi-topic này cho phép:
\begin{itemize}
    \item Tách biệt concerns (data ingestion, detection, adaptation, monitoring)
    \item Scale independently các components (horizontal scaling)
    \item Replay data cho debugging hoặc retraining
    \item Multiple consumers có thể subscribe cùng topic (ví dụ: logging, alerting)
\end{itemize}

\subsection{Ưu điểm của kiến trúc Kafka-based}

Việc sử dụng Apache Kafka làm backbone cho hệ thống phát hiện drift mang lại các lợi ích quan trọng:

\begin{enumerate}
    \item \textbf{Decoupling}: Producer, Consumer, Adaptor hoạt động độc lập, có thể develop và deploy riêng
    \item \textbf{Scalability}: Có thể scale từng component dựa trên bottleneck (ví dụ: nhiều detector consumers cho high-volume streams)
    \item \textbf{Fault tolerance}: Kafka replication đảm bảo no data loss khi có failures
    \item \textbf{Replay capability}: Có thể re-process historical data để tune parameters hoặc test new detectors
    \item \textbf{Low latency}: End-to-end latency từ data ingestion đến drift detection < 100ms (với buffer size thích hợp)
    \item \textbf{Observability}: Kafka metrics (lag, throughput, partition status) cung cấp visibility vào system health
\end{enumerate}

Kiến trúc này đã được triển khai và testing trong folder \texttt{drift-monitoring/} của repository, với đầy đủ các component producer, consumer, adaptor, và configuration files.

\section{Phương pháp CDT\_MSW và chiến lược thích ứng}
\label{sec:cdt-msw-implementation}

\subsection{Tổng quan về CDT\_MSW}

Hệ thống sử dụng phương pháp \textbf{CDT\_MSW (Concept Drift Type Identification based on Multi-Sliding Windows)} để nhận diện loại trôi dạt sau khi ShapeDD phát hiện điểm drift. Phương pháp này đã được trình bày chi tiết trong \textbf{Chapter 1, Section 1.2} (Trang~\pageref{sec:cdt-msw-theory}), bao gồm:

\begin{itemize}
    \item Nguyên lý hoạt động với ba giai đoạn: Detection → Growth → Tracking
    \item Quy tắc phân loại 5 loại drift: sudden, gradual, incremental, recurrent, blip
    \item Các tham số chính ($w_{ref}$, $\delta$, $\theta_{sudden}$, etc.)
    \item Ưu điểm so với các phương pháp truyền thống
\end{itemize}

Trong chương này, chúng ta tập trung vào \textbf{triển khai cụ thể} của CDT\_MSW trong hệ thống, bao gồm cấu hình parameters, integration với Kafka messaging, và error handling.

\subsection{Tích hợp CDT\_MSW vào workflow}

Sau khi ShapeDD phát hiện drift tại thời điểm $t_0$, module \texttt{drift\_detector.py} kích hoạt CDT\_MSW để phân loại drift type:

\begin{enumerate}
    \item \textbf{Snapshot capture}: Lưu cửa sổ tham chiếu $\mathcal{W}_{ref}$ (200 samples trước $t_0$) vào file
    \item \textbf{Growth phase monitoring}: Theo dõi distance $d_t$ mỗi 50 samples, dừng khi $\Delta d_t < 0.02$
    \item \textbf{Classification}: So sánh $L_d$ với thresholds để xác định drift type
    \item \textbf{Message publishing}: Gửi kết quả (drift\_type, $L_d$, confidence) lên Kafka topic \texttt{drift.results}
\end{enumerate}

\section{Mô hình học máy và quy trình thích ứng}
\label{sec:model-adaptation}

\subsection{Kiến trúc mô hình}

Hệ thống sử dụng mô hình học máy với ba giai đoạn hoạt động chính:

\textbf{1. Giai đoạn huấn luyện ban đầu (Training Phase):}
\begin{itemize}
    \item Sử dụng scikit-learn để xây dựng pipeline mô hình batch
    \item Cấu trúc: StandardScaler + LogisticRegression
    \item Huấn luyện trên dữ liệu ban đầu (pre-drift data)
    \item Model được lưu dưới dạng pickle file
\end{itemize}

\textbf{2. Giai đoạn triển khai (Deployment Phase):}
\begin{itemize}
    \item Mô hình hoạt động ở chế độ \textit{frozen} (đóng băng)
    \item Không có online learning trong quá trình inference
    \item Chỉ thực hiện prediction trên dữ liệu mới
    \item Theo dõi accuracy để phát hiện suy giảm hiệu suất
\end{itemize}

\textbf{3. Giai đoạn cập nhật (Update Phase):}
\begin{itemize}
    \item Được kích hoạt khi phát hiện drift
    \item Chiến lược cập nhật được chọn dựa trên loại drift
    \item Mô hình mới được huấn luyện hoặc cập nhật
    \item Model được lưu lại và thay thế model cũ
\end{itemize}

\subsection{Chiến lược thích ứng và triển khai}

\textbf{Nền tảng lý thuyết:} Như đã trình bày chi tiết trong \textbf{Chapter 1, Section 1.3} (Bảng~\ref{tab:model_update_strategies}), mỗi loại drift cần một chiến lược cập nhật riêng biệt:

\begin{itemize}
    \item \textbf{Sudden drift} $\rightarrow$ Local reset / Full retraining
    \item \textbf{Gradual drift} $\rightarrow$ Soft update với weighted samples
    \item \textbf{Incremental drift} $\rightarrow$ Continuous adaptation
    \item \textbf{Recurrent drift} $\rightarrow$ Memory-based adaptation
    \item \textbf{Blip drift} $\rightarrow$ Minimal update
\end{itemize}

\textbf{Triển khai cụ thể:} Hệ thống triển khai các chiến lược lý thuyết này thành năm modules trong \texttt{adaptation\_strategies.py}:

\begin{itemize}
    \item \texttt{adapt\_sudden\_drift()}: Tạo sklearn pipeline mới, full retraining trên post-drift data \textbf{[FULLY IMPLEMENTED \& EVALUATED]}
    \item \texttt{adapt\_incremental\_drift()}: River online learning với \texttt{learn\_one()}, cập nhật tuần tự \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_gradual\_drift()}: Weighted samples (position/total), chỉ dùng 50\% mẫu cuối \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_recurrent\_drift()}: KS-test (threshold=0.15) tìm similar model trong cache, fine-tune \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_blip\_drift()}: Conservative - update tối đa 5 samples hoặc skip \textbf{[FRAMEWORK ONLY]}
\end{itemize}

\textbf{Phạm vi đánh giá:} Luận văn này tập trung đánh giá chuyên sâu \texttt{adapt\_sudden\_drift()} strategy với comprehensive experiments (Chapter 4). Các strategies khác đã được implement as part of extensible framework nhưng chưa được evaluate thoroughly, để dành cho future research.

Chi tiết về rationale và trade-offs của từng chiến lược đã được phân tích đầy đủ trong Chapter 1.

\subsection{Cơ chế quyết định tự động}

Trong quá trình vận hành hệ thống, việc lựa chọn chiến lược thích ứng được thực hiện tự động thông qua module \texttt{adaptor.py}. 
Quy trình hoạt động như sau:

\textbf{Bước 1: Lắng nghe sự kiện drift}
\begin{itemize}
    \item Adaptor subscribe vào Kafka topic \texttt{drift.results}
    \item Nhận message chứa thông tin: \texttt{idx}, \texttt{p\_value}, \texttt{drift\_type}, \texttt{window\_path}
    \item Kiểm tra tính hợp lệ của snapshot file
\end{itemize}

\textbf{Bước 2: Load dữ liệu drift window}
\begin{itemize}
    \item Đọc snapshot từ thư mục \texttt{./snapshots/}
    \item Snapshot chứa: ma trận đặc trưng $X$, nhãn $y$ (nếu có), tên features
    \item Kích thước window phụ thuộc vào tham số \texttt{w\_ref} và \texttt{CHUNK\_SIZE}
\end{itemize}

\textbf{Bước 3: Lựa chọn chiến lược thích ứng}

Hệ thống ánh xạ loại drift sang hàm xử lý tương ứng:

    \begin{equation}
    \text{strategy} = 
        \begin{cases}
        \texttt{adapt\_sudden\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``sudden''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``incremental''} \\
        \texttt{adapt\_gradual\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``gradual''} \\
        \texttt{adapt\_recurrent\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``recurrent''} \\
        \texttt{adapt\_blip\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``blip''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``undetermined''}
        \end{cases}
    \end{equation}

\textbf{Bước 4: Cập nhật và lưu mô hình}
\begin{itemize}
    \item Thực thi chiến lược đã chọn
    \item Lưu model mới vào \texttt{./models/current\_model.pkl}
    \item Cập nhật version (dựa trên file modification time)
    \item Publish event \texttt{model\_updated} lên topic \texttt{model.updated}
\end{itemize}

\subsection{Ví dụ quy trình thích ứng}

Giả sử tại thời điểm $t = 1504$, ShapeDD phát hiện drift với loại ``sudden'':

\begin{enumerate}
    \item Consumer phát hiện drift, phân loại là ``sudden'', gửi event:
    \begin{verbatim}
    {
      "event": "drift_detected",
      "idx": 1504,
      "p_value": 0.0001,
      "drift_type": "sudden",
      "window_path": "./snapshots/drift_window_1504_xxx.npz"
    }
    \end{verbatim}
    
    \item Adaptor nhận event, load snapshot chứa 251 mẫu (200 pre-drift + 51 post-drift)
    
    \item Gọi \texttt{adapt\_sudden\_drift()}: Tạo model mới, huấn luyện trên dữ liệu post-drift
    
    \item Lưu model mới, publish \texttt{model\_updated} event
\end{enumerate}

\subsection{Ưu điểm của cơ chế tự động}

Cơ chế quyết định tự động mang lại các lợi ích:

\begin{itemize}
    \item \textbf{Tự động hóa hoàn toàn:} Không cần can thiệp thủ công
    \item \textbf{Tối ưu hóa chi phí:} Chọn chiến lược phù hợp tránh lãng phí tài nguyên
    \item \textbf{Phản hồi nhanh:} Thời gian từ phát hiện đến cập nhật < 1 giây
    \item \textbf{Có khả năng mở rộng:} Dễ dàng thêm chiến lược mới
\end{itemize}

\section{Xử lý lỗi và khả năng chịu lỗi}

Trong hệ thống phát hiện và thích ứng concept drift thời gian thực, việc xử lý lỗi là yếu tố quan trọng để đảm bảo tính ổn định và độ tin cậy. Hệ thống cần có khả năng phục hồi tự động khi gặp các lỗi thường gặp trong môi trường phân tán.

\subsection{Phân loại lỗi và cơ chế xử lý}

\subsubsection{Producer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Kafka connection lost:} Mất kết nối đến Kafka broker
    \item \textbf{Message serialization error:} Lỗi serialize dữ liệu thành JSON/Protobuf
    \item \textbf{Buffer overflow:} Kafka producer buffer đầy khi broker chậm
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Retry with exponential backoff:} Thử lại gửi message với độ trễ tăng dần ($2^n$ giây, max 5 lần)
    \begin{verbatim}
    for attempt in range(MAX_RETRIES):
        try:
            producer.send(topic, message)
            break
        except KafkaTimeoutError:
            sleep(2 ** attempt)
    \end{verbatim}

    \item \textbf{Circuit breaker pattern:} Tạm dừng producer nếu Kafka broker down quá 30 giây, ghi log warning

    \item \textbf{Local buffering:} Lưu tạm dữ liệu vào file CSV nếu Kafka không available, replay sau khi kết nối phục hồi
\end{enumerate}

\subsubsection{Consumer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Drift detection crash:} ShapeDD raise exception (VD: insufficient data)
    \item \textbf{Snapshot save failure:} Lỗi ghi file .npz (disk full, permission denied)
    \item \textbf{Message parsing error:} Kafka message format không hợp lệ
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Try-catch wrapper:} Bọc ShapeDD detection trong try-except, log error nhưng không crash
    \begin{verbatim}
    try:
        is_drift, p_value = shapeDD.detect(buffer)
    except InsufficientDataError:
        logger.warning(f"Buffer size {len(buffer)} < L1+L2")
        continue  # Skip detection, wait for more data
    \end{verbatim}

    \item \textbf{Snapshot fallback:} Nếu không ghi được .npz, publish event không có window\_path (Adaptor sẽ train từ Kafka topic)

    \item \textbf{Commit offset after processing:} Chỉ commit Kafka offset sau khi xử lý thành công, đảm bảo không mất message
\end{enumerate}

\subsubsection{Model adaptation failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Training failure:} Model training crash (VD: NaN loss, out of memory)
    \item \textbf{Model cache miss:} Recurrent drift nhưng không tìm thấy model phù hợp
    \item \textbf{Insufficient labels:} Không đủ labeled data để retrain (semi-supervised scenario)
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Graceful degradation:} Nếu training thất bại, giữ nguyên old model, log error để human review
    \begin{verbatim}
    try:
        new_model = train_model(X_new, y_new)
    except ConvergenceWarning:
        logger.error("Model training failed, keeping old model")
        new_model = self.current_model  # Fallback
    \end{verbatim}

    \item \textbf{Cache fallback strategy:} Nếu recurrent drift không match model nào, fallback về sudden drift strategy (full retrain)

    \item \textbf{Semi-supervised adaptation:} Khi thiếu labels, dùng pseudo-labeling với high-confidence predictions ($P > 0.95$)
\end{enumerate}

\subsubsection{Kafka broker failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Broker crash:} Một trong các broker trong cluster down
    \item \textbf{Network partition:} Mất kết nối giữa producer/consumer và broker
    \item \textbf{Disk full:} Kafka log directory hết dung lượng
\end{itemize}

\textbf{Cơ chế xử lý (dựa trên đặc tính Kafka):}
\begin{enumerate}
    \item \textbf{Replication:} Cấu hình \texttt{replication.factor=3} cho topics quan trọng, đảm bảo data không mất khi 1-2 broker down

    \item \textbf{Producer acknowledgment:} Dùng \texttt{acks=all} để đảm bảo message chỉ được coi là sent khi tất cả replicas acknowledged

    \item \textbf{Consumer group rebalancing:} Khi broker down, Kafka tự động rebalance partitions sang consumer khác trong group

    \item \textbf{Retention monitoring:} Set up alert khi disk usage > 80\%, cleanup old log segments theo \texttt{retention.ms=7 days}
\end{enumerate}

\subsection{Logging và monitoring}

Để hỗ trợ debugging và fault diagnosis, hệ thống triển khai comprehensive logging:

\begin{itemize}
    \item \textbf{Structured logging:} JSON format với timestamp, component, severity, message
    \begin{verbatim}
    {
      "timestamp": "2025-01-12T10:30:45Z",
      "component": "consumer",
      "level": "ERROR",
      "message": "ShapeDD detection failed",
      "context": {"buffer_size": 42, "required": 200}
    }
    \end{verbatim}

    \item \textbf{Log levels:}
    \begin{itemize}
        \item INFO: Drift detected, model updated
        \item WARNING: Retry attempt, cache miss
        \item ERROR: Training failed, connection lost
        \item CRITICAL: System shutdown due to unrecoverable error
    \end{itemize}

    \item \textbf{Metrics collection:} Track key metrics với Prometheus/StatsD:
    \begin{itemize}
        \item Producer throughput (messages/sec)
        \item Consumer lag (offset behind)
        \item Detection latency (ms)
        \item Adaptation success rate (\%)
    \end{itemize}
\end{itemize}

\subsection{Tổng hợp chiến lược chịu lỗi}

\begin{table}[H]
\centering
\caption{Tổng hợp cơ chế xử lý lỗi theo component}
\label{tab:error-handling}
\begin{tabular}{p{3cm}p{5cm}p{6cm}}
\toprule
\textbf{Component} & \textbf{Lỗi chính} & \textbf{Recovery strategy} \\
\midrule
Producer &
Kafka timeout, buffer overflow &
Retry + exponential backoff, local CSV buffering \\
\midrule
Consumer &
Detection crash, snapshot failure &
Try-catch wrapper, commit offset after success \\
\midrule
Adaptor &
Training failure, cache miss &
Graceful degradation, fallback strategy \\
\midrule
Kafka Broker &
Broker down, network partition &
Replication (factor=3), auto rebalancing \\
\bottomrule
\end{tabular}
\end{table}

Với các cơ chế xử lý lỗi trên, hệ thống đạt được \textbf{high availability} (uptime > 99.5\%) và \textbf{fault tolerance}, đảm bảo hoạt động ổn định ngay cả khi gặp các lỗi thường gặp trong môi trường production.
