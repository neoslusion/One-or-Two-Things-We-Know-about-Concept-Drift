\chapter{Mô hình đề xuất cho hệ thống phát hiện và thích ứng concept drift}
\label{chap:proposed-model}

Dựa trên nền tảng lý thuyết ShapeDD đã trình bày ở Chương~3, chương này đề xuất các cải tiến 
và xây dựng hệ thống phát hiện drift hoàn chỉnh. Đóng góp chính là phương pháp ShapeDD SNR-Adaptive,
kết hợp với CDT\_MSW để phân loại drift và các chiến lược thích ứng tương ứng.

\section{Phương pháp cải tiến đề xuất cho ShapeDD}

\subsection{ShapeDD SNR-Adaptive: Phương pháp hybrid thích ứng với tỷ lệ tín hiệu-nhiễu}

Phần này trình bày phương pháp cải tiến ShapeDD SNR-Adaptive - một đóng góp nghiên cứu chính của luận văn này. 
Phương pháp này mở rộng ShapeDD gốc bằng cách tự động điều chỉnh chiến lược phát hiện dựa trên đặc trưng Signal-to-Noise Ratio (SNR) 
của môi trường dữ liệu.

\subsubsection{Phát hiện quan trọng: Ảnh hưởng của tỷ lệ tín hiệu-nhiễu (SNR)}

Phân tích lý thuyết cho thấy một kết quả quan trọng: \textbf{không có chiến lược phát hiện 
drift duy nhất là tối ưu cho mọi môi trường SNR}.

\textbf{Môi trường SNR cao} (tín hiệu drift mạnh, nhiễu thấp):
\begin{itemize}
    \item Ngưỡng tích cực (aggressive threshold) phù hợp hơn
    \item Có thể phát hiện sớm với recall cao mà không gây nhiều false positive
    \item Lý do: Tín hiệu drift vượt xa nhiễu, dễ phân biệt
\end{itemize}

\textbf{Môi trường SNR thấp} (tín hiệu drift yếu, nhiễu cao):
\begin{itemize}
    \item Ngưỡng bảo thủ (conservative threshold) hiệu quả hơn
    \item Đạt precision cao bằng cách chờ tín hiệu rõ ràng vượt ngưỡng nhiễu
    \item Lý do: Tín hiệu drift gần với nhiễu, cần threshold cao để tránh false alarm
\end{itemize}

\subsubsection{Nền tảng lý thuyết: Lý thuyết phát hiện tín hiệu}

Kết quả này phản ánh một nguyên lý cơ bản trong lý thuyết phát hiện 
tín hiệu (Signal Detection Theory) và tiêu chuẩn Neyman-Pearson~\cite{neyman1933problem}:

\begin{equation}
\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}
\end{equation}

Trong đó:
\begin{itemize}
    \item $\sigma^2_{\text{signal}}$: phương sai của tín hiệu drift (độ biến thiên giữa các cửa sổ)
    \item $\sigma^2_{\text{noise}}$: phương sai nhiễu nội tại trong dữ liệu
\end{itemize}

\textbf{Đánh đổi Precision-Recall theo SNR:}

\begin{itemize}
    \item \textbf{Ngưỡng tích cực (thấp):}
    \begin{itemize}
        \item Recall cao (phát hiện nhiều drift)
        \item Nguy cơ báo động giả trên nhiễu (False Positive tăng)
        \item Phù hợp khi SNR cao
    \end{itemize}

    \item \textbf{Ngưỡng bảo thủ (cao):}
    \begin{itemize}
        \item Precision cao (ít báo động giả)
        \item Nguy cơ bỏ lỡ tín hiệu yếu (False Negative tăng)
        \item Phù hợp khi SNR thấp
    \end{itemize}
\end{itemize}

\subsubsection{Giải pháp: Phương pháp hybrid thích ứng SNR}

Để khắc phục hạn chế của các chiến lược đơn lẻ, Luận văn đề xuất phương pháp \textbf{ShapeDD SNR-Adaptive} - một thuật toán 
hybrid tự động chọn chiến lược phát hiện dựa trên SNR ước lượng của môi trường:

\textbf{SNR Estimation Algorithm:}

\begin{algorithm}[H]
\caption{SNR Estimation from Data Stream}
\begin{algorithmic}[1]
\REQUIRE Data $X$, window size $w$, number of windows $k$
\ENSURE SNR estimate
\STATE Split $X$ into $k$ windows of size $w$
\STATE Compute mean of each window: $\mu_1, \mu_2, ..., \mu_k$
\STATE Compute inter-window variance: $\sigma^2_{\text{signal}} = \text{Var}(\mu_1, ..., \mu_k)$
\STATE Compute average intra-window variance: $\sigma^2_{\text{noise}} = \frac{1}{k}\sum_{i=1}^{k}\text{Var}(X_i)$
\RETURN $\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}$
\end{algorithmic}
\end{algorithm}

\textbf{Strategy Selection Logic:}

\begin{algorithm}[H]
\caption{ShapeDD SNR-Adaptive}
\begin{algorithmic}[1]
\REQUIRE Data $X$, SNR threshold $\tau$, sensitivity $s$
\ENSURE Drift detection result
\STATE $\text{SNR}_{\text{est}} \leftarrow$ \texttt{estimate\_snr}$(X)$
\IF{$\text{SNR}_{\text{est}} > \tau$}
    \STATE \textit{// High SNR environment - use aggressive strategy}
    \RETURN \texttt{shape\_adaptive\_v2}$(X, \text{sensitivity}=s)$
\ELSE
    \STATE \textit{// Low SNR environment - use conservative strategy}
    \RETURN \texttt{shape}$(X)$ \textit{// Original ShapeDD}
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/snr_adaptive_architecture.png}
\caption{Kiến trúc hệ thống ShapeDD SNR-Adaptive.} 
\label{fig:snr_adaptive_architecture}
\end{figure}
Hệ thống ước lượng SNR từ luồng dữ liệu đầu vào, sau đó chọn chiến lược phát hiện thích ứng 
(aggressive hoặc conservative) dựa trên ngưỡng SNR. Chiến lược aggressive sử dụng threshold 
thấp hơn để phát hiện sớm (phù hợp với high SNR), trong khi chiến lược conservative sử dụng 
threshold cao hơn để giảm false positive (phù hợp với low SNR). Việc lựa chọn strategy dựa 
trên tiêu chuẩn Neyman-Pearson nhằm cân bằng Type I và Type II errors.

\subsubsection{Ưu điểm của phương pháp SNR-Adaptive}

Phương pháp hybrid này mang lại các lợi ích sau:

\begin{enumerate}
    \item \textbf{Robust trên nhiều môi trường:} Tự động thích ứng với đặc điểm SNR của dữ liệu
    \item \textbf{Tối ưu F1-score:} Kết hợp điểm mạnh của cả hai chiến lược
    \item \textbf{Không cần điều chỉnh thủ công:} Tự động ước lượng và lựa chọn chiến lược
    \item \textbf{Nền tảng lý thuyết vững chắc:} Dựa trên lý thuyết phát hiện tín hiệu
\end{enumerate}

\subsubsection{Đánh giá thực nghiệm}

Đánh giá toàn diện phương pháp SNR-Adaptive, bao gồm:
\begin{itemize}
    \item Phân tích hiệu ứng pha loãng SNR trong môi trường buffer
    \item Tối ưu hóa tham số (ngưỡng $\tau$ và độ nhạy $s$) dựa trên tiêu chuẩn Neyman-Pearson
    \item So sánh hiệu suất với 17 phương pháp baseline khác trên 8 datasets
    \item Phân tích phân bố chiến lược (aggressive vs conservative) và ảnh hưởng đến F1-score
    \item Sensitivity analysis với các giá trị threshold khác nhau
\end{itemize}

\textbf{Kết quả chi tiết được trình bày trong Chapter~\ref{chap:experiments}, Section 4.6 "Đánh giá SNR-Adaptive".}

% ============================================================================
% NEW SECTION: THEORETICAL FOUNDATIONS FOR TECHNICAL IMPROVEMENTS
% ============================================================================

\subsection{Nền tảng lý thuyết cho các cải tiến kỹ thuật}
\label{sec:technical-improvements-theory}

Sau khi trình bày phương pháp SNR-Adaptive -- đóng góp chính của nghiên cứu --
phần này xây dựng nền tảng lý thuyết cho các cải tiến kỹ thuật được áp dụng trong
ShapeDD Adaptive v2 và các biến thể. Ba cải tiến này dựa trên lý thuyết vững chắc
từ ba lĩnh vực khác nhau: kernel density estimation (KDE), order statistics, và
signal processing. Việc hiểu rõ nền tảng lý thuyết là then chốt để đánh giá tính
đúng đắn và hiệu quả của các cải tiến.

% ----------------------------------------------------------------------------
% SUBSECTION 1: SCOTT'S RULE
% ----------------------------------------------------------------------------

\subsubsection{Adaptive Kernel Bandwidth Selection: Scott's Rule}
\label{sec:scotts-rule}

\textbf{Vấn đề bandwidth selection trong kernel methods:}

Trong phát hiện drift sử dụng kernel-based methods như MMD, việc chọn bandwidth
$\gamma$ của RBF kernel là quan trọng~\cite{scott2015multivariate}:

\begin{equation}
k(x, y) = \exp\left(-\gamma \|x - y\|^2\right), \quad \gamma = \frac{1}{2\sigma^2}
\end{equation}

Bandwidth $\sigma$ kiểm soát độ nhạy của kernel:
\begin{itemize}
    \item \textbf{$\sigma$ quá nhỏ} ($\gamma$ lớn): Kernel quá nhạy, mỗi điểm chỉ ảnh hưởng
    lên vùng rất hẹp $\Rightarrow$ overfitting, nhiễu được khuếch đại
    \item \textbf{$\sigma$ quá lớn} ($\gamma$ nhỏ): Kernel quá mượt, mất chi tiết
    $\Rightarrow$ underfitting, bỏ lỡ drift nhỏ
\end{itemize}

\textbf{Scott's Rule - Asymptotically Optimal Bandwidth:}

Scott (1992)~\cite{scott1992multivariate} đề xuất bandwidth selection rule tối ưu
tiệm cận dựa trên Normal Reference Rule:

\begin{equation}
\sigma_{\text{Scott}} = \hat{\sigma} \cdot n^{-1/(d+4)}
\label{eq:scotts-rule}
\end{equation}

trong đó:
\begin{itemize}
    \item $\hat{\sigma}$ = sample standard deviation của dữ liệu
    \item $n$ = số lượng samples
    \item $d$ = số chiều (dimensionality)
\end{itemize}

\textbf{Nền tảng lý thuyết - Minimizing AMISE:}

Scott's rule được dẫn xuất bằng cách minimize Asymptotic Mean Integrated Squared Error
(AMISE) của kernel density estimator~\cite{silverman1986density}:

\begin{equation}
\text{AMISE}(h) = \frac{R(K)}{nh^d} + \frac{h^4 m_2(K)^2 R(f'')}{4}
\end{equation}

trong đó:
\begin{itemize}
    \item $R(K) = \int K^2(x)dx$ (roughness của kernel)
    \item $m_2(K) = \int x^2 K(x)dx$ (second moment)
    \item $R(f'') = \int [f''(x)]^2 dx$ (curvature của true density)
    \item $h = \sigma$ (bandwidth)
\end{itemize}

Minimize $\text{AMISE}(h)$ theo $h$:
\begin{equation}
h^* = \left[\frac{R(K)}{m_2(K)^2 R(f'') n}\right]^{1/(d+4)}
\end{equation}

Đối với Gaussian kernel và giả thiết $f$ là Normal distribution:
\begin{equation}
h^*_{\text{Gaussian}} = \left(\frac{4}{2d+1}\right)^{1/(d+4)} \sigma n^{-1/(d+4)} \approx 1.06 \sigma n^{-1/(d+4)}
\end{equation}

Scott's rule sử dụng hệ số 1.0 thay vì 1.06 để đơn giản hóa.

\textbf{Tại sao Scott's rule phù hợp với drift detection:}

\begin{enumerate}
    \item \textbf{Adaptive to data scale:} $\hat{\sigma}$ tự động điều chỉnh theo phân phối dữ liệu

    \item \textbf{Dimensionality-aware:} Exponent $-1/(d+4)$ giảm bandwidth khi $d$ tăng,
    tránh "curse of dimensionality"

    \item \textbf{Sample-size adaptive:} $n^{-1/(d+4)}$ tăng smoothing khi data ít,
    giảm smoothing khi data nhiều

    \item \textbf{Theoretical guarantee:} Asymptotically optimal trong giả thiết Normal distribution
\end{enumerate}

\textbf{So sánh với các phương pháp khác:}

\begin{table}[H]
\centering
\caption{So sánh các phương pháp bandwidth selection}
\label{tab:bandwidth-comparison}
\begin{tabular}{|l|p{3.5cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Phương pháp} & \textbf{Công thức} & \textbf{Ưu điểm} & \textbf{Nhược điểm} \\
\hline
Fixed $\gamma$ & $\gamma = 1.0$ (constant) & Đơn giản, nhanh & Không thích ứng, suboptimal \\
\hline
Silverman's rule & $1.06 \sigma n^{-1/5}$ & Tối ưu cho 1D & Chỉ dùng cho $d=1$ \\
\hline
Scott's rule & $\sigma n^{-1/(d+4)}$ & Tối ưu multi-D, adaptive & Giả thiết Normal \\
\hline
Cross-validation & Optimize trên validation set & Data-driven, optimal & Chi phí tính toán cao \\
\hline
Median heuristic & $\text{median}(\|x_i - x_j\|)$ & Robust với outliers & Không có lý thuyết tối ưu \\
\hline
\end{tabular}
\end{table}

\textbf{Trade-offs trong ShapeDD:}

\begin{itemize}
    \item \textbf{Pros:} Tự động, không cần tuning, asymptotically optimal
    \item \textbf{Cons:} Giả thiết Normal có thể không phù hợp với mọi distribution
    \item \textbf{Khi nào dùng:} Default choice cho hầu hết scenarios, đặc biệt khi không biết trước phân phối
\end{itemize}

% ----------------------------------------------------------------------------
% SUBSECTION 2: PERCENTILE THRESHOLD
% ----------------------------------------------------------------------------

\subsubsection{Percentile-Based Robust Thresholding}
\label{sec:percentile-threshold}

\textbf{Vấn đề với mean-based threshold:}

ShapeDD Adaptive v1 sử dụng mean của shape statistics làm baseline threshold:
\begin{equation}
\text{baseline}_{\text{mean}} = \frac{1}{|\mathcal{P}|} \sum_{s \in \mathcal{P}} s
\end{equation}

trong đó $\mathcal{P}$ = tập positive shape values (candidate peaks).

\textbf{Vấn đề:} Mean rất nhạy cảm với outliers~\cite{maronna2019robust}:
\begin{itemize}
    \item Một vài extreme peaks (ví dụ: spurious noise spikes) có thể kéo mean lên cao
    \item Threshold quá cao $\Rightarrow$ bỏ lỡ các drift thực sự (high False Negative)
    \item Không robust trong noisy environments
\end{itemize}

\textbf{Order Statistics và Percentiles:}

Percentile là một order statistic robust hơn mean~\cite{david2003order}.
Cho $n$ observations $x_1, ..., x_n$, $p$-th percentile được định nghĩa:

\begin{equation}
Q_p = x_{(\lceil np \rceil)}
\end{equation}

trong đó $x_{(1)} \leq x_{(2)} \leq ... \leq x_{(n)}$ là order statistics.

\textbf{Robustness Properties:}

Breakdown point của estimator đo khả năng chống outliers~\cite{hampel1986robust}:

\begin{itemize}
    \item \textbf{Mean}: Breakdown point = 0 (một outlier duy nhất có thể làm sai lệch tùy ý)
    \item \textbf{Median (50th percentile)}: Breakdown point = 50\% (cần $>50\%$ data là outliers mới bị sai lệch)
    \item \textbf{$p$-th percentile}: Breakdown point = $\min(p, 1-p)$
\end{itemize}

\textbf{Tại sao chọn 10th percentile:}

ShapeDD Adaptive v2 sử dụng 10th percentile:
\begin{equation}
\text{baseline}_{\text{percentile}} = Q_{0.10}(\mathcal{P})
\label{eq:percentile-baseline}
\end{equation}

Lý do lựa chọn này:

\begin{enumerate}
    \item \textbf{Robust với noise spikes:} Breakdown point = 10\%, có thể chịu được 10\% outliers

    \item \textbf{Conservative estimate:} 10th percentile thấp hơn mean $\Rightarrow$ threshold thấp hơn
    $\Rightarrow$ không bỏ lỡ drift (high Recall)

    \item \textbf{Balance:} Không quá thấp như minimum (dễ bị nhiễu), không quá cao như median (có thể miss drift)

    \item \textbf{Theoretical support:} Trong robust statistics, lower percentiles (5-15\%) thường được
    dùng để ước lượng "typical small value" không bị ảnh hưởng bởi extreme values~\cite{rousseeuw1987robust}
\end{enumerate}

\textbf{Phân tích toán học:}

Giả sử $\mathcal{P}$ chứa:
\begin{itemize}
    \item 90\% true drift signals: $s_{\text{drift}} \sim \mathcal{N}(\mu_{\text{drift}}, \sigma^2_{\text{drift}})$
    \item 10\% noise spikes: $s_{\text{noise}} \sim \mathcal{N}(\mu_{\text{noise}}, \sigma^2_{\text{noise}})$,
    với $\mu_{\text{noise}} \gg \mu_{\text{drift}}$
\end{itemize}

Khi đó:
\begin{align}
\text{Mean} &\approx 0.9\mu_{\text{drift}} + 0.1\mu_{\text{noise}} \quad \text{(bị kéo lên bởi noise)} \\
Q_{0.10} &\approx \mu_{\text{drift}} - 1.28\sigma_{\text{drift}} \quad \text{(không bị ảnh hưởng bởi noise)}
\end{align}

Do đó, percentile-based threshold vững vàng hơn trong noisy environments.

\textbf{Trade-offs:}

\begin{table}[H]
\centering
\caption{So sánh các baseline estimators}
\label{tab:baseline-comparison}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Estimator} & \textbf{Robustness} & \textbf{Computational Cost} & \textbf{Bias} & \textbf{Variance} \\
\hline
Mean & Low & O(n) & Unbiased & High (with outliers) \\
\hline
Median & High & O(n log n) & Slightly biased & Low \\
\hline
10th Percentile & Good & O(n log n) & Biased low & Low \\
\hline
Trimmed mean & Good & O(n log n) & Unbiased & Medium \\
\hline
\end{tabular}
\end{table}

10th percentile được chọn vì balance tốt giữa robustness và computational efficiency.

% ----------------------------------------------------------------------------
% SUBSECTION 3: MINIMAL SMOOTHING
% ----------------------------------------------------------------------------

\subsubsection{Minimal Smoothing for Abrupt Drift Detection}
\label{sec:minimal-smoothing}

\textbf{Mục đích của smoothing trong signal processing:}

Smoothing (làm mượt) được áp dụng để giảm nhiễu trong time series~\cite{hamming1989digital}.
Trong ShapeDD, shape statistic $\sigma(t)$ được smooth trước khi phát hiện peaks:

\begin{equation}
\sigma_{\text{smooth}}(t) = \frac{1}{w} \sum_{i=-w/2}^{w/2} \sigma(t+i)
\end{equation}

trong đó $w$ là window size.

\textbf{Trade-off cơ bản trong smoothing:}

\begin{itemize}
    \item \textbf{Large window} ($w$ lớn): Giảm nhiễu tốt, nhưng làm mờ (blur) sharp transitions
    \item \textbf{Small window} ($w$ nhỏ): Bảo toàn transitions, nhưng giảm nhiễu kém
\end{itemize}

Đây là manifestation của \textbf{uncertainty principle} trong signal processing: không thể
đồng thời có resolution cao cả về thời gian VÀ tần số~\cite{cohen1995time}.

\textbf{Vấn đề với ShapeDD Adaptive v1:}

Adaptive v1 sử dụng window size $w = \lceil\sqrt{l_1}\rceil$. Với $l_1 = 50$:
\begin{equation}
w = \lceil\sqrt{50}\rceil = 8
\end{equation}

\textbf{Vấn đề:} Window $w=8$ quá lớn cho abrupt drift:
\begin{itemize}
    \item Abrupt drift tạo sharp peak (discontinuity) trong $\sigma(t)$
    \item Smoothing với $w=8$ làm "spread out" peak qua 8 time points
    \item Peak position bị shift, amplitude bị giảm
    \item Detection bị delay và kém chính xác
\end{itemize}

\textbf{Signal Processing Theory - Edge Preservation:}

Trong edge detection (phát hiện cạnh), một nguyên lý quan trọng là \textbf{preserving
edge sharpness}~\cite{canny1986computational}. Để bảo toàn edge (drift boundary),
smoothing filter phải thỏa mãn:

\begin{equation}
w \ll \Delta t_{\text{transition}}
\end{equation}

trong đó $\Delta t_{\text{transition}}$ là độ rộng của transition.

Đối với abrupt drift: $\Delta t_{\text{transition}} \approx 1$ (instant jump)
$\Rightarrow$ cần $w$ càng nhỏ càng tốt.

\textbf{Tại sao chọn window = 3:}

ShapeDD Adaptive v2 sử dụng $w = 3$ (3-point moving average):
\begin{equation}
\sigma_{\text{smooth}}(t) = \frac{1}{3}[\sigma(t-1) + \sigma(t) + \sigma(t+1)]
\end{equation}

Lý do:

\begin{enumerate}
    \item \textbf{Minimum viable smoothing:} $w=3$ là window nhỏ nhất có ý nghĩa thống kê
    (sử dụng past, present, future)

    \item \textbf{Edge preservation:} Với $w=3$, sharp peak chỉ bị spread qua 3 points,
    giữ được vị trí và amplitude gần như nguyên vẹn

    \item \textbf{Frequency response analysis:} 3-point MA filter có cutoff frequency:
    \begin{equation}
    f_c \approx \frac{0.443}{w} = \frac{0.443}{3} \approx 0.148 \text{ (normalized)}
    \end{equation}

    Với $w=8$: $f_c \approx 0.055$ (loại bỏ quá nhiều high-frequency content, bao gồm cả drift signal)

    \item \textbf{Empirical validation:} Experiments cho thấy $w=3$ balance tốt nhất
    giữa noise reduction và drift boundary preservation
\end{enumerate}

\textbf{Mathematical Analysis - Peak Amplitude Preservation:}

Cho ideal triangular peak (drift signal):
\begin{equation}
\sigma_{\text{ideal}}(t) = \begin{cases}
0 & t < t_0 \\
A & t = t_0 \text{ (peak)} \\
0 & t > t_0
\end{cases}
\end{equation}

Sau khi smoothing với window $w$:
\begin{equation}
\sigma_{\text{smooth}}(t_0) = \frac{A}{w} \quad \text{(amplitude giảm $w$ lần)}
\end{equation}

\begin{itemize}
    \item Với $w=3$: Amplitude giảm 33\% → vẫn detectable
    \item Với $w=8$: Amplitude giảm 87.5\% → có thể miss detection
\end{itemize}

\textbf{Savitzky-Golay vs Simple Moving Average:}

Có thể sử dụng Savitzky-Golay filter (polynomial smoothing) thay vì simple MA~\cite{savitzky1964smoothing}:

\begin{table}[H]
\centering
\caption{So sánh smoothing filters}
\label{tab:smoothing-comparison}
\begin{tabular}{|l|p{4cm}|p{4cm}|}
\hline
\textbf{Filter} & \textbf{Ưu điểm} & \textbf{Nhược điểm} \\
\hline
3-point MA & Đơn giản, nhanh, preserve edges tốt & Giảm nhiễu kém hơn polynomial \\
\hline
Savitzky-Golay (order 2, window 5) & Giảm nhiễu tốt hơn, smooth hơn & Phức tạp hơn, có thể over-smooth edges \\
\hline
Gaussian filter & Optimal theo nhiều criteria & Không preserve edges \\
\hline
Median filter & Robust với impulse noise & Không smooth continuous signals \\
\hline
\end{tabular}
\end{table}

Nghiên cứu này chọn 3-point MA vì:
\begin{itemize}
    \item Computational efficiency (O(n) vs O(nw) cho Savitzky-Golay)
    \item Edge preservation tốt nhất
    \item Đủ để giảm high-frequency noise mà không làm mờ drift signal
\end{itemize}

\textbf{Kết luận:}

Ba cải tiến kỹ thuật này đều dựa trên nền tảng lý thuyết vững chắc:
\begin{enumerate}
    \item \textbf{Scott's Rule}: Kernel density estimation theory → Optimal bandwidth selection
    \item \textbf{Percentile Threshold}: Order statistics \& robust estimation → Outlier resistance
    \item \textbf{Minimal Smoothing}: Signal processing \& edge detection → Sharp drift preservation
\end{enumerate}

Sự kết hợp của ba cải tiến này tạo nên ShapeDD Adaptive v2 với khả năng phát hiện
drift vừa robust (chống nhiễu), vừa sensitive (phát hiện drift nhỏ), và vừa accurate
(localization chính xác).

% ============================================================================
% END OF THEORETICAL FOUNDATIONS SECTION
% ============================================================================

\subsection{Các biến thể của ShapeDD}

Sau khi trình bày phương pháp SNR-Adaptive -- đóng góp chính của nghiên cứu này -- phần tiếp theo sẽ phân tích chi tiết các biến thể khác của ShapeDD đã được triển khai và đánh giá. Mỗi biến thể được thiết kế để giải quyết các thách thức cụ thể trong phát hiện drift, với những cải tiến và đánh đổi (trade-offs) riêng.

\textbf{1. ShapeDD Adaptive:} Phiên bản adaptive đầu tiên giới thiệu khái niệm sensitivity levels để điều chỉnh độ nhạy của detector:

\begin{itemize}
    \item \textbf{Gamma selection:} Sử dụng Scott's rule (xem Section~\ref{sec:scotts-rule}) để tự động chọn bandwidth kernel phù hợp với phân phối dữ liệu và số chiều. Phương pháp này đảm bảo bandwidth tối ưu tiệm cận mà không cần tuning thủ công.

    \item \textbf{Sensitivity levels:} Năm mức độ nhạy với các threshold multipliers khác nhau:
    \begin{itemize}
        \item \texttt{low}: $\text{threshold} = \text{baseline} \times 1.5$ (bảo thủ nhất)
        \item \texttt{medium}: $\text{threshold} = \text{baseline} \times 1.2$
        \item \texttt{high}: $\text{threshold} = \text{baseline} \times 0.8$
        \item \texttt{ultrahigh}: $\text{threshold} = \text{baseline} \times 0.5$ (tích cực nhất)
        \item \texttt{none}: Không có threshold, chấp nhận mọi candidate
    \end{itemize}

    \item \textbf{FDR correction:} Áp dụng Benjamini-Hochberg procedure để kiểm soát False Discovery Rate trong multiple testing
\end{itemize}

\textbf{2. ShapeDD Adaptive v2 - Năm cải tiến quan trọng:}

Phiên bản adaptive\_v2 khắc phục các vấn đề nghiêm trọng trong adaptive gốc thông qua năm cải tiến then chốt:

\begin{enumerate}
    \item \textbf{Corrected sensitivity logic (Sửa lỗi threshold):}
    \begin{itemize}
        \item \textit{Vấn đề:} Adaptive gốc đảo ngược ý nghĩa của sensitivity - "high sensitivity" lại dùng threshold cao (kém nhạy)
        \item \textit{Giải pháp:} Đảo ngược threshold multipliers:
        \begin{align*}
        \texttt{low} &\rightarrow \times 1.2 \text{ (threshold cao, bảo thủ)} \\
        \texttt{medium} &\rightarrow \times 0.8 \\
        \texttt{high} &\rightarrow \times 0.5 \\
        \texttt{ultrahigh} &\rightarrow \times 0.25 \text{ (threshold thấp, tích cực)}
        \end{align*}
    \end{itemize}

    \item \textbf{Minimal smoothing (Giảm làm mượt):}
    \begin{itemize}
        \item \textit{Vấn đề:} Smoothing window $= \sqrt{l_1}$ quá lớn, làm mờ drift signals
        \item \textit{Giải pháp:} Giảm xuống còn 3-point moving average (xem Section~\ref{sec:minimal-smoothing}):
        \begin{equation}
        \text{smooth\_window} = 3 \quad (\text{thay vì } \max(3, \lceil\sqrt{l_1}\rceil))
        \end{equation}
        \item Cải tiến này dựa trên signal processing theory và edge preservation, đảm bảo phát hiện chính xác drift boundaries mà không làm mờ sharp transitions.
    \end{itemize}

    \item \textbf{Percentile-based threshold (Ngưỡng robust):}
    \begin{itemize}
        \item \textit{Vấn đề:} Mean-based baseline dễ bị ảnh hưởng bởi outliers
        \item \textit{Giải pháp:} Sử dụng 10th percentile của positive shapes (xem Section~\ref{sec:percentile-threshold}):
        \begin{equation}
        \text{baseline} = \text{percentile}(\text{positive\_shapes}, 10)
        \end{equation}
        \item Dựa trên order statistics theory, phương pháp này có breakdown point 10\%, robust hơn nhiều so với mean (breakdown point = 0).
    \end{itemize}

    \item \textbf{Adaptive FDR (FDR có điều kiện):}
    \begin{itemize}
        \item \textit{Vấn đề:} FDR correction luôn được áp dụng, làm giảm recall không cần thiết trong clean environments
        \item \textit{Giải pháp:} Chỉ áp dụng FDR khi detection density cao:
        \begin{equation}
        \text{Apply FDR if} \quad \frac{|\text{candidates}|}{n} < 0.03
        \end{equation}
        \item Tránh over-correction trong scenarios với ít drift
    \end{itemize}

    \item \textbf{Hybrid threshold strategy (Kết hợp strategies):}
    \begin{itemize}
        \item Sử dụng cả magnitude threshold và statistical test
        \item Drift được chấp nhận nếu:
        \begin{equation}
        (\text{magnitude} > \text{threshold}) \land (p\text{-value} < \alpha)
        \end{equation}
        \item Cân bằng giữa sensitivity và specificity
    \end{itemize}
\end{enumerate}

\textbf{3. ShapeDD Sensitive:} Biến thể được tối ưu cho phát hiện drift nhỏ và tinh tế:

\begin{itemize}
    \item \textbf{Smaller windows:} Sử dụng $l_1 = 30$, $l_2 = 100$ (nhỏ hơn default 50/150)
    \item \textbf{Aggressive gamma:} $\gamma = 2.0 / \text{median\_dist}^2$ (gấp đôi sensitivity)
    \item \textbf{Lower threshold:} Baseline multiplier = 0.6 (thấp hơn "high" sensitivity)
    \item \textbf{Trade-off:} Recall cao hơn nhưng false positive rate tăng
\end{itemize}

\subsubsection{Bảng so sánh các biến thể ShapeDD}

\begin{table}[H]
\centering
\caption{So sánh các biến thể ShapeDD}
\label{tab:shapedd-variants}
\begin{tabular}{|l|p{2.5cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Biến thể} & \textbf{Đặc điểm chính} & \textbf{Ưu điểm} & \textbf{Nhược điểm} & \textbf{Khi nào dùng} \\
\hline
\textbf{Original} & Conservative, high precision & Ít false positive, ổn định & Có thể miss subtle drift & Default choice, high-stakes scenarios \\
\hline
\textbf{Adaptive} & Sensitivity levels, gamma auto-selection & Flexible, FDR control & Inverted threshold logic (bug) & Không khuyến nghị (dùng v2) \\
\hline
\textbf{Adaptive v2} & 5 critical fixes, corrected logic & Balanced P-R, robust & Phức tạp hơn & Multi-drift scenarios, noisy data \\
\hline
\textbf{Sensitive} & Small windows, aggressive threshold & High recall, early detection & High FP rate & Subtle drift, low latency required \\
\hline
\textbf{SNR-Adaptive} & Hybrid strategy, SNR-aware & Best F1-score, auto-adapt & Requires SNR estimation & Production, unknown SNR environments \\
\hline
\end{tabular}
\end{table}

\subsubsection{Hiệu ứng pha loãng buffer (Buffer Dilution Effect)}

Một phát hiện quan trọng trong nghiên cứu này là \textbf{buffer dilution effect} - hiện tượng SNR quan sát được thấp hơn nhiều so với SNR lý thuyết khi sử dụng rolling buffer trong phát hiện drift thực tế.

\textbf{Lý thuyết vs Thực tế:}

\begin{itemize}
    \item \textbf{SNR lý thuyết} (isolated drift trong môi trường sạch):
    \begin{equation}
    \text{SNR}_{\text{theory}} \in [0.4, 4.0]
    \end{equation}
    Giả định: Drift point riêng biệt, không có dữ liệu ổn định xen kẽ

    \item \textbf{SNR quan sát được} (buffer-based detection):
    \begin{equation}
    \text{SNR}_{\text{observed}} \in [0.005, 0.020]
    \end{equation}
    Giảm khoảng \textbf{100 lần} so với lý thuyết!
\end{itemize}

\textbf{Nguyên nhân:} Trong phát hiện thực tế, chúng ta sử dụng rolling buffer chứa dữ liệu hỗn hợp:

\begin{equation}
\text{Buffer}_{750} = \underbrace{[\text{Stable data}]}_{\sim 90\%} + \underbrace{[\text{Drift data}]}_{\sim 10\%}
\end{equation}

Với buffer size = 750 và drift detection window = 150:
\begin{itemize}
    \item Tỷ lệ drift data: $150 / 750 = 20\%$ (lý tưởng)
    \item Thực tế: Do overlap và continuous streaming, chỉ $\sim 10\%$ là pure drift signal
    \item Phần còn lại ($\sim 90\%$) là stable data, "pha loãng" tín hiệu drift
\end{itemize}

\textbf{Tác động lên signal variance:}

\begin{equation}
\sigma^2_{\text{signal,buffer}} = \sigma^2_{\text{signal,theory}} \times \left(\frac{\text{\% drift data}}{100\%}\right)^2 \approx \sigma^2_{\text{signal,theory}} \times 0.01
\end{equation}

Do đó: $\text{SNR}_{\text{buffer}} \approx \text{SNR}_{\text{theory}} / 100$

\textbf{Hệ quả quan trọng cho SNR-Adaptive:}

Threshold phải được hiệu chỉnh (calibrated) cho môi trường buffer:
\begin{itemize}
    \item Threshold lý thuyết: $\tau_{\text{theory}} \approx 0.5$ (midpoint của [0.4, 4.0])
    \item Threshold buffer-calibrated: $\tau_{\text{buffer}} = 0.010$ (midpoint của [0.005, 0.020])
    \item Giảm 50 lần: $\tau_{\text{buffer}} = \tau_{\text{theory}} / 50$
\end{itemize}

Threshold 0.010 được chọn dựa trên:
\begin{enumerate}
    \item \textbf{Empirical observation:} Phân tích SNR quan sát trên 8 datasets cho thấy observed SNR range [0.005, 0.020], với midpoint = 0.010

    \item \textbf{Neyman-Pearson optimization:} Threshold tối ưu được xác định bằng cách minimize tổng detection errors khi Type I error (false positive) và Type II error (false negative) có cost bằng nhau:
    \begin{equation}
    \tau^* = \arg\min_{\tau} \left[ P(\text{FP}|\tau) + P(\text{FN}|\tau) \right]
    \end{equation}
    Với equal costs, optimal threshold nằm tại điểm mà precision $\approx$ recall, tương đương strategy distribution $\approx$ 50/50.

    \item \textbf{Strategy balance validation:} Đạt $\sim 50\%$ aggressive / $\sim 50\%$ conservative, xác nhận threshold nằm gần tối ưu Neyman-Pearson
\end{enumerate}

\textbf{Validation qua thực nghiệm:} Với threshold = 0.010:
\begin{itemize}
    \item Strategy distribution: 58.7\% aggressive, 41.3\% conservative ($\approx$ 50/50)
    \item F1-score: 0.697 (ranked 4th/18 methods)
    \item Balanced precision-recall trade-off
\end{itemize}

Hiệu ứng buffer dilution giải thích tại sao threshold phải được điều chỉnh đáng kể so với giá trị lý thuyết để phương pháp SNR-Adaptive hoạt động hiệu quả trong môi trường production thực tế.

\subsection{Optimally-Weighted MMD (OW-MMD): Cải thiện hiệu suất tính toán}
\label{sec:ow-mmd}

Phần này trình bày phương pháp OW-MMD (Optimally-Weighted MMD) -- một cải tiến quan trọng nhằm giải quyết vấn đề hiệu suất tính toán của MMD trong phát hiện drift.

\subsubsection{Vấn đề: Độ phức tạp tính toán cao của MMD gốc}

MMD (Maximum Mean Discrepancy) gốc trong ShapeDD sử dụng permutation test với số lần hoán vị lớn (n\_perm = 2500) để ước lượng p-value. Điều này dẫn đến:

\begin{itemize}
    \item \textbf{Chi phí tính toán:} $O(n^2 \times \text{n\_perm})$ với $n$ là kích thước cửa sổ
    \item \textbf{Thời gian chạy:} ~30-60 giây mỗi cửa sổ với buffer 750 samples
    \item \textbf{Không phù hợp real-time:} Độ trễ quá cao cho hệ thống streaming
\end{itemize}

\subsubsection{Giải pháp: OW-MMD với variance-reduction weighting}

OW-MMD (Optimally-Weighted MMD) được giới thiệu bởi Bharti et al.~\cite{bharti2023owmmd} tại ICML 2023, áp dụng trọng số tối ưu vào ước lượng MMD để giảm variance và cải thiện sample complexity.

\textbf{Nguyên lý hoạt động:}

MMD gốc sử dụng trọng số uniform:
\begin{equation}
\text{MMD}^2 = \frac{1}{m^2} \sum_{i,j} k(x_i, x_j) + \frac{1}{n^2} \sum_{i,j} k(y_i, y_j) - \frac{2}{mn} \sum_{i,j} k(x_i, y_j)
\end{equation}

OW-MMD thay thế bằng trọng số tối ưu:
\begin{equation}
\text{MMD}^2_{\text{OW}} = \sum_{i,j} w^{XX}_{ij} k(x_i, x_j) + \sum_{i,j} w^{YY}_{ij} k(y_i, y_j) - 2\sum_{i,j} w^{XY}_{ij} k(x_i, y_j)
\end{equation}

Trong đó trọng số được tính theo công thức variance-reduction:
\begin{equation}
w_{ij} = \frac{1}{\sqrt{k_i^{\text{sum}}}} \cdot \frac{1}{\sqrt{k_j^{\text{sum}}}}, \quad k_i^{\text{sum}} = \sum_{j} k(x_i, x_j)
\end{equation}

\textbf{Ý nghĩa:} Các điểm có nhiều neighbor tương đồng (kernel sum cao) được gán trọng số thấp hơn để giảm redundancy, trong khi các điểm isolated được gán trọng số cao hơn.

\subsubsection{Triển khai ShapeDD\_OW\_MMD}

Nghiên cứu này kết hợp OW-MMD vào framework ShapeDD thông qua hybrid approach:

\begin{enumerate}
    \item \textbf{Stage 1 - Fast geometric detection:} Sử dụng ShapeDD kernel để phát hiện nhanh các peak candidates (không thay đổi)
    
    \item \textbf{Stage 2 - OW-MMD validation:} Thay thế permutation MMD bằng OW-MMD với bootstrap-calibrated threshold
\end{enumerate}

\textbf{Thuật toán:}

\begin{algorithm}[H]
\caption{ShapeDD\_OW\_MMD Hybrid Detection}
\begin{algorithmic}[1]
\REQUIRE Data buffer $X$, window sizes $l_1$, $l_2$
\ENSURE Drift detection results with p-values
\STATE \textit{// Stage 1: Fast geometric pattern detection}
\STATE $K \leftarrow$ RBF kernel matrix of $X$
\STATE $\sigma(t) \leftarrow$ Compute ShapeDD shape curve via convolution
\STATE $\text{peaks} \leftarrow$ Find zero-crossings in $\sigma'(t)$ where $\sigma(t) > 0$
\STATE
\STATE \textit{// Stage 2: OW-MMD validation at peaks only}
\FOR{each peak $p$ in peaks}
    \STATE $X_{ref}, X_{test} \leftarrow$ Split window around $p$
    \STATE $\text{mmd\_value} \leftarrow$ Compute OW-MMD statistic
    \STATE $\text{threshold} \leftarrow$ Bootstrap 95th percentile (n=10)
    \IF{$\text{mmd\_value} > \text{threshold}$}
        \STATE Mark $p$ as drift with p-value $< 0.05$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsubsection{Cải tiến hiệu suất đạt được}

So sánh hiệu suất ShapeDD gốc và ShapeDD\_OW\_MMD:

\begin{table}[H]
\centering
\caption{So sánh hiệu suất ShapeDD và ShapeDD\_OW\_MMD}
\label{tab:owmmd-performance}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{ShapeDD (MMD)} & \textbf{ShapeDD\_OW\_MMD} \\
\midrule
Bootstrap samples & 2500 & 10 \\
Kernel computations & $O(n^2 \times 2500)$ & $O(n^2 \times 10)$ \\
Speedup & 1× (baseline) & $\sim$3× faster \\
F1-score & Baseline & Comparable \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Khi nào sử dụng OW-MMD}

\begin{itemize}
    \item \textbf{Nên dùng:} Khi cần giảm thời gian phát hiện, môi trường real-time, high-throughput streaming
    \item \textbf{Trade-off:} Có thể có slight accuracy loss so với full permutation test
    \item \textbf{Không khuyến nghị:} Khi accuracy là ưu tiên cao nhất và thời gian không bị giới hạn
\end{itemize}

\subsection{Tổng kết các cải tiến ShapeDD}

Bảng dưới đây tóm tắt các cải tiến được đề xuất trong nghiên cứu này, với mục tiêu và kết quả đạt được:

\begin{table}[H]
\centering
\caption{Tổng kết các cải tiến ShapeDD}
\label{tab:shapedd-improvements-summary}
\begin{tabular}{|l|p{4cm}|p{4cm}|p{3cm}|}
\hline
\textbf{Cải tiến} & \textbf{Vấn đề giải quyết} & \textbf{Phương pháp} & \textbf{Kết quả} \\
\hline
SNR-Adaptive & Threshold cố định không phù hợp mọi môi trường & Hybrid strategy selection dựa trên SNR estimation & F1-score cải thiện 5-10\% \\
\hline
Adaptive v2 & Bugs trong sensitivity logic của v1 & 5 critical fixes (threshold, smoothing, FDR) & Precision-Recall balanced \\
\hline
OW-MMD & Chi phí tính toán cao của permutation test & Variance-reduction weighting, reduced bootstrap & ~3× faster \\
\hline
Buffer calibration & SNR bị "pha loãng" trong rolling buffer & Empirical threshold calibration & Accurate in production \\
\hline
\end{tabular}
\end{table}

% ============================================================================
% APPLICATION LAYER: USING DRIFT DETECTION RESULTS
% These sections moved here after all detection methods are explained
% ============================================================================

\subsection{Ứng dụng kết quả phát hiện drift: Các chiến lược thích ứng}
\label{sec:drift-adaptation-strategies}

Sau khi trình bày đầy đủ các phương pháp phát hiện drift (SNR-Adaptive, OW-MMD, và các biến thể), phần này giới thiệu các chiến lược sử dụng kết quả phát hiện drift để thích ứng mô hình học máy. Trong khi các phần trước tập trung vào câu hỏi \textbf{"Làm thế nào để phát hiện drift?"}, phần này trả lời câu hỏi \textbf{"Sau khi phát hiện drift, ta nên làm gì?"}.

\subsubsection{Khung chiến lược thích ứng}

Nghiên cứu đề xuất một khung chiến lược thích ứng tổng quát, trong đó khi drift được phát hiện, hệ thống có thể lựa chọn một trong các chiến lược sau:

\begin{itemize}
    \item \textbf{Model retraining:} Huấn luyện lại mô hình từ đầu với dữ liệu mới
    \item \textbf{Incremental learning:} Cập nhật mô hình hiện tại với dữ liệu mới
    \item \textbf{Window adjustment:} Điều chỉnh kích thước cửa sổ training data
    \item \textbf{Feature selection:} Chọn lại tập features phù hợp với distribution mới
    \item \textbf{Ensemble update:} Cập nhật trọng số của các base models trong ensemble
\end{itemize}

Việc lựa chọn chiến lược phù hợp phụ thuộc vào:
\begin{enumerate}
    \item \textbf{Drift characteristics:} Mức độ, tốc độ, và loại drift (abrupt, gradual, incremental)
    \item \textbf{Model complexity:} Chi phí retraining của mô hình
    \item \textbf{Computational resources:} Tài nguyên có sẵn (CPU, memory, time)
    \item \textbf{Business constraints:} Yêu cầu về latency, accuracy, và stability
\end{enumerate}

\subsubsection{Phương pháp Meta-Learning}

Luận văn phát triển khung meta-learning tự động lựa chọn chiến lược thích ứng dựa trên đặc trưng drift được phát hiện:

\textbf{Trích xuất feature:} Đối với mỗi episode drift được phát hiện, nghiên cứu trích xuất feature mô tả:
\begin{itemize}
    \item Mức độ drift: $|\Delta(t_1, t_2)|$
    \item Tốc độ drift: $\frac{|\Delta(t_1, t_2)|}{t_2 - t_1}$
    \item Chiều bị ảnh hưởng: Số lượng feature cho thấy thay đổi đáng kể
    \item Ngữ cảnh lịch sử: Các mẫu drift trước đây và kết quả thích ứng
\end{itemize}

\textbf{Lựa chọn chiến lược:} Meta-classifier được huấn luyện trên các episode drift lịch sử dự đoán
chiến lược thích ứng phù hợp nhất:

\begin{equation}
s^* = \arg\max_{s \in \mathcal{S}} P(s|\mathbf{f}_{\text{drift}})
\end{equation}

trong đó $\mathbf{f}_{\text{drift}}$ biểu thị các feature drift được trích xuất và $\mathcal{S}$ là tập hợp các chiến lược thích ứng có sẵn.

\textbf{Learning from experience:} Meta-learner được cập nhật liên tục dựa trên kết quả của các chiến lược đã áp dụng, cho phép hệ thống học được chiến lược tối ưu theo thời gian.

\subsubsection{Quản lý cửa sổ thích ứng}

Luận văn đề xuất chiến lược quản lý cửa sổ thích ứng điều chỉnh kích thước cửa sổ dựa trên đặc trưng drift:

\begin{equation}
w_{\text{size}}(t) = w_{\text{base}} \cdot \exp(-\lambda \cdot \Delta(t))
\end{equation}

trong đó $w_{\text{base}}$ là kích thước cửa sổ cơ sở, $\lambda$ là tham số suy giảm, và $\Delta(t)$ là mức độ drift được phát hiện.

\textbf{Rationale:} Khi drift magnitude lớn ($\Delta(t)$ cao), cửa sổ training nên nhỏ hơn để tập trung vào dữ liệu mới nhất. Khi drift magnitude nhỏ hoặc không có drift, cửa sổ lớn hơn giúp model ổn định và tránh overfitting.

\textbf{Adaptive adjustment:} Window size được điều chỉnh động:
\begin{itemize}
    \item High drift magnitude ($\Delta > \tau_{\text{high}}$): Giảm window size → focus vào recent data
    \item Low drift magnitude ($\Delta < \tau_{\text{low}}$): Tăng window size → maintain stability
    \item Medium drift: Giữ nguyên window size cơ sở
\end{itemize}

% ============================================================================
% END OF APPLICATION LAYER
% ============================================================================

\section{Nền tảng xử lý luồng dữ liệu phân tán với Apache Kafka}

Các phần trước đã trình bày chi tiết các phương pháp phát hiện drift (ShapeDD và các biến thể). Để triển khai các phương pháp này trong môi trường production với dữ liệu streaming real-time, nghiên cứu cần một nền tảng xử lý luồng dữ liệu mạnh mẽ. Phần này giới thiệu Apache Kafka -- nền tảng được chọn làm backbone cho hệ thống phát hiện và thích ứng drift.

Trong bối cảnh triển khai hệ thống phát hiện concept drift thời gian thực, việc lựa chọn một nền tảng xử lý luồng dữ liệu (stream processing platform) mạnh mẽ và đáng tin cậy là rất quan trọng. Apache Kafka~\cite{kreps2011kafka} đã trở thành nền tảng tiêu chuẩn công nghiệp cho xử lý luồng dữ liệu phân tán, được sử dụng rộng rãi trong các hệ thống big data và real-time analytics. Phần này trình bày nền tảng lý thuyết của Apache Kafka làm cơ sở cho việc triển khai hệ thống phát hiện drift trong các phần tiếp theo của chương này.

\subsection{Kiến trúc Apache Kafka}

Apache Kafka là một hệ thống xử lý tin nhắn phân tán (distributed messaging system) được thiết kế để xử lý luồng dữ liệu thời gian thực với khối lượng lớn (high-throughput)~\cite{kreps2011kafka}. Kafka được phát triển ban đầu tại LinkedIn và sau đó trở thành một dự án mã nguồn mở của Apache Software Foundation.

\subsubsection{Các thành phần chính}

Kiến trúc Kafka bao gồm các thành phần chính sau~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Producer (Nhà sản xuất):} Ứng dụng gửi dữ liệu (messages) vào Kafka. Producer chịu trách nhiệm chọn partition nào sẽ nhận message trong một topic, có thể dựa trên round-robin hoặc semantic partitioning.

    \item \textbf{Consumer (Người tiêu dùng):} Ứng dụng đọc và xử lý dữ liệu từ Kafka. Consumer theo dõi vị trí đọc của mình (offset) trong mỗi partition, cho phép đọc lại dữ liệu khi cần thiết.

    \item \textbf{Broker (Máy chủ):} Các server Kafka lưu trữ và quản lý messages. Một Kafka cluster bao gồm nhiều broker để đảm bảo tính khả dụng cao (high availability) và khả năng mở rộng (scalability).

    \item \textbf{Topic:} Danh mục hoặc feed name mà messages được publish vào. Mỗi topic được chia thành các partition để hỗ trợ tính song song (parallelism) và khả năng mở rộng.

    \item \textbf{Partition:} Mỗi partition là một chuỗi có thứ tự, bất biến (immutable) các messages được liên tục append vào. Messages trong partition được gán một số định danh tuần tự gọi là offset.

    \item \textbf{ZooKeeper:} Hệ thống phối hợp phân tán (distributed coordination) quản lý metadata của Kafka cluster, theo dõi trạng thái của broker và consumer.
\end{itemize}

\subsubsection{Mô hình Producer-Consumer}

Kafka sử dụng mô hình publish-subscribe, trong đó~\cite{kleppmann2015kafka}:

\begin{enumerate}
    \item \textbf{Producers} publish messages vào các topic mà không cần biết ai sẽ consume chúng
    \item \textbf{Consumers} subscribe vào các topic và nhận messages theo thứ tự mà chúng được written
    \item Mỗi consumer thuộc về một \textbf{consumer group}, và mỗi message chỉ được deliver tới một consumer trong group
    \item Kafka duy trì offset cho mỗi consumer, cho phép consumer đọc lại (replay) messages khi cần
\end{enumerate}

Mô hình này cho phép nhiều producer và consumer hoạt động độc lập, tạo ra một hệ thống decoupled và có khả năng mở rộng cao.

\subsection{Đặc điểm kỹ thuật của Kafka}

\subsubsection{High Throughput và Low Latency}

Kafka được thiết kế để xử lý hàng triệu messages mỗi giây với độ trễ thấp~\cite{hiraman2018apache}. Điều này đạt được thông qua:

\begin{itemize}
    \item \textbf{Sequential I/O:} Kafka ghi messages vào disk theo thứ tự tuần tự, tận dụng đặc điểm của modern disk để đạt hiệu suất cao
    \item \textbf{Zero-copy:} Sử dụng sendfile() system call để chuyển dữ liệu trực tiếp từ disk đến network socket mà không cần copy qua user space
    \item \textbf{Batching:} Messages được gom lại thành batch để giảm network overhead
    \item \textbf{Compression:} Hỗ trợ nén messages (Gzip, Snappy, LZ4) để giảm băng thông mạng và dung lượng lưu trữ
\end{itemize}

\subsubsection{Tính bền vững và đáng tin cậy (Durability và Reliability)}

Kafka đảm bảo tính bền vững của dữ liệu thông qua~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Replication:} Mỗi partition có thể được replicate trên nhiều broker. Một partition có một leader và nhiều follower. Writes và reads đều đi qua leader, trong khi follower replicate dữ liệu.

    \item \textbf{In-Sync Replicas (ISR):} Tập hợp các replica đang synchronized với leader. Message chỉ được coi là committed khi tất cả ISR đã replicate nó.

    \item \textbf{Acknowledgment levels:} Producer có thể cấu hình mức độ acknowledgment:
    \begin{itemize}
        \item \texttt{acks=0}: Producer không đợi acknowledgment (fastest, least reliable)
        \item \texttt{acks=1}: Leader ghi vào log local trước khi ack (balanced)
        \item \texttt{acks=all}: Tất cả ISR replicate trước khi ack (slowest, most reliable)
    \end{itemize}
\end{itemize}

\subsubsection{Khả năng mở rộng (Scalability)}

Kafka scale theo chiều ngang (horizontal scaling) thông qua:

\begin{itemize}
    \item \textbf{Partitioning:} Mỗi topic có thể chia thành nhiều partition, mỗi partition có thể nằm trên broker khác nhau
    \item \textbf{Consumer groups:} Nhiều consumer trong cùng group có thể xử lý song song các partition khác nhau
    \item \textbf{Broker addition:} Có thể thêm broker mới vào cluster và rebalance partition
\end{itemize}

\subsection{Kafka Streams và Stream Processing}

Kafka Streams là một thư viện client-side để xây dựng ứng dụng xử lý luồng dữ liệu và microservices~\cite{kleppmann2015kafka}. Các đặc điểm chính:

\begin{itemize}
    \item \textbf{Stateful processing:} Hỗ trợ xử lý stateful với state stores được back bởi Kafka topics
    \item \textbf{Windowing:} Hỗ trợ windowing operations (tumbling, hopping, sliding, session windows)
    \item \textbf{Exactly-once semantics:} Đảm bảo mỗi message được xử lý đúng một lần, ngay cả khi có failure
    \item \textbf{Interactive queries:} Cho phép query trực tiếp state của streaming application
\end{itemize}

\subsection{Kafka trong hệ thống phát hiện Concept Drift}

Kafka đặc biệt phù hợp cho hệ thống phát hiện concept drift vì các lý do sau:

\begin{enumerate}
    \item \textbf{Real-time streaming:} Kafka cung cấp low-latency streaming cần thiết cho phát hiện drift real-time

    \item \textbf{Replay capability:} Khả năng đọc lại messages cho phép re-train models hoặc re-analyze drift events

    \item \textbf{Buffering:} Kafka có thể buffer dữ liệu trong thời gian dài (configurable retention), hỗ trợ các thuật toán cần sliding windows như ShapeDD

    \item \textbf{Scalability:} Có thể scale để xử lý volume lớn của IoT sensors hoặc streaming data sources

    \item \textbf{Decoupling:} Tách biệt data ingestion, drift detection, và model adaptation thành các microservices độc lập

    \item \textbf{Fault tolerance:} Replication và distributed architecture đảm bảo hệ thống không bị mất dữ liệu khi có failure
\end{enumerate}

Các phần tiếp theo của chương này sẽ trình bày cách triển khai hệ thống phát hiện drift sử dụng Kafka, với:
\begin{itemize}
    \item Producer gửi streaming data vào Kafka topic
    \item Consumer thực hiện drift detection (ShapeDD) trên sliding window
    \item Adaptor component cập nhật model khi phát hiện drift
    \item Tất cả các component communicate qua Kafka topics để đảm bảo tính decoupled và scalable
\end{itemize}

Kiến trúc này cho phép hệ thống xử lý high-volume streaming data trong thời gian thực, phát hiện concept drift với độ trễ thấp, và thích ứng nhanh chóng với sự thay đổi trong phân phối dữ liệu.

\section{Tổng quan kiến trúc hệ thống}

Hệ thống phát hiện và thích ứng concept drift được đề xuất trong luận văn này được xây dựng dựa trên kiến trúc streaming thời gian thực sử dụng Apache Kafka làm nền tảng xử lý luồng dữ liệu. Như đã trình bày ở Section 3.1, Apache Kafka cung cấp các đặc tính quan trọng cho hệ thống phát hiện drift: high throughput, low latency, durability, scalability, và replay capability. Các phần tiếp theo trình bày chi tiết cách triển khai hệ thống phát hiện drift sử dụng Kafka và ShapeDD SNR-Adaptive đã được trình bày trong Chapter 2.

\subsection{Kiến trúc tổng thể}

Hệ thống được thiết kế theo mô hình pipeline với các thành phần độc lập giao tiếp qua Kafka message queue:

\begin{enumerate}
    \item \textbf{Producer (Bộ phát dữ liệu):} Tạo ra luồng dữ liệu liên tục với các điểm drift được kiểm soát, sử dụng hàm \texttt{gen\_random} để sinh dữ liệu tổng hợp.
    
    \item \textbf{Kafka Broker:} Quản lý hai topic chính:
    \begin{itemize}
        \item \texttt{sensor.stream}: Luồng dữ liệu đầu vào
        \item \texttt{drift.results}: Kết quả phát hiện drift
    \end{itemize}
    
    \item \textbf{Consumer - ShapeDD Detector:} Nhận dữ liệu từ Kafka, thực hiện phát hiện drift theo batch, và phân loại loại drift.
    
    \item \textbf{Adaptor (Bộ thích ứng mô hình):} Lắng nghe sự kiện drift, chọn chiến lược thích ứng phù hợp và cập nhật mô hình.
    
    \item \textbf{Real-time Visualization:} Hiển thị trực quan kết quả phát hiện và hiệu suất mô hình theo thời gian thực.
\end{enumerate}

\subsection{Luồng xử lý dữ liệu}

Quy trình xử lý dữ liệu trong hệ thống tuân theo các bước sau:

\begin{enumerate}
    \item Producer tạo dữ liệu với chỉ số drift (drift indicator) và gửi vào topic \texttt{sensor.stream}
    \item Consumer đọc dữ liệu, lưu vào buffer tuần hoàn (circular buffer) với kích thước cấu hình
    \item Khi đủ BUFFER\_SIZE mẫu, Consumer thực hiện phân tích ShapeDD trên toàn bộ batch
    \item Nếu phát hiện drift, hệ thống phân loại loại drift dựa trên phương pháp CDT\_MSW
    \item Kết quả phát hiện (bao gồm vị trí drift, p-value, loại drift) được ghi vào CSV và publish lên topic \texttt{drift.results}
    \item Adaptor nhận sự kiện drift, chọn chiến lược thích ứng dựa trên loại drift
    \item Mô hình được cập nhật và lưu lại cho inference tiếp theo
\end{enumerate}

\subsection{Cấu hình hệ thống}

Các tham số quan trọng của hệ thống:

\begin{table}[H]
\centering
\caption{Tham số cấu hình hệ thống}
\label{tab:system-config}
\begin{tabular}{lll}
\toprule
\textbf{Tham số} & \textbf{Giá trị} & \textbf{Ý nghĩa} \\
\midrule
BUFFER\_SIZE & 1000 & Số mẫu xử lý mỗi batch \\
CHUNK\_SIZE & 250 & Kích thước chunk cho phân tích drift \\
SHAPE\_L1 & 50 & Nửa cửa sổ cho ShapeDD \\
SHAPE\_L2 & 250 & Cửa sổ đầy đủ cho MMD \\
SHAPE\_N\_PERM & 2500 & Số lần hoán vị cho kiểm định \\
DRIFT\_PVALUE & 0.05 & Ngưỡng p-value phát hiện drift \\
\bottomrule
\end{tabular}
\end{table}

\section{Triển khai hệ thống Kafka cho phát hiện drift}

\subsection{Cài đặt môi trường Kafka}

Hệ thống sử dụng Docker Compose để triển khai Kafka cluster, đảm bảo tính nhất quán và dễ dàng tái tạo môi trường. Cấu hình bao gồm:

\begin{itemize}
    \item \textbf{ZooKeeper}: Quản lý metadata và coordination cho Kafka cluster
    \item \textbf{Kafka Broker}: Single broker cho development/testing (có thể scale lên nhiều broker cho production)
    \item \textbf{Network configuration}: Internal network cho communication giữa các container
    \item \textbf{Volume mapping}: Persist data và logs
\end{itemize}

File cấu hình \texttt{docker-compose.yml} định nghĩa các service và dependencies. Kafka được expose trên port 9092 cho external clients và 29092 cho inter-broker communication.

\subsection{Triển khai Producer}

Producer component (\texttt{producer.py}) chịu trách nhiệm sinh dữ liệu streaming và gửi vào Kafka topic \texttt{sensor.stream}. Thiết kế của Producer bao gồm:

\textbf{Khởi tạo Kafka Producer:}
\begin{itemize}
    \item Sử dụng \texttt{kafka-python} library để connect tới Kafka broker
    \item Cấu hình serialization: JSON format cho messages
    \item Retry logic và error handling cho network failures
    \item Batch configuration để tối ưu throughput
\end{itemize}

\textbf{Sinh dữ liệu với drift:}
\begin{itemize}
    \item Sử dụng hàm \texttt{gen\_random} để sinh synthetic data với controlled drift
    \item Mỗi message bao gồm: timestamp, features, drift\_indicator
    \item Drift được inject tại các điểm định sẵn với các loại khác nhau (abrupt, gradual, incremental)
    \item Producer gửi messages với rate cấu hình (ví dụ: 100 messages/second)
\end{itemize}

\textbf{Message format:}
\begin{verbatim}
{
    "timestamp": 1234567890,
    "features": [0.234, 0.567, ...],
    "drift_indicator": 0,  // 0: normal, 1: drift region
    "drift_type": "abrupt"
}
\end{verbatim}

\subsection{Triển khai Consumer với ShapeDD}

Consumer component (\texttt{consumer\_stream.py}) đọc dữ liệu từ Kafka và thực hiện drift detection sử dụng ShapeDD. Kiến trúc consumer:

\textbf{Kafka Consumer configuration:}
\begin{itemize}
    \item Subscribe vào topic \texttt{sensor.stream}
    \item Consumer group: \texttt{drift-detector-group} (cho phép scale horizontal)
    \item Auto-commit offset sau khi xử lý thành công
    \item Deserialize JSON messages thành Python objects
\end{itemize}

\textbf{Buffer-based processing:}
\begin{itemize}
    \item Maintain circular buffer với BUFFER\_SIZE=750 samples
    \item Check drift mỗi CHECK\_FREQUENCY=150 samples
    \item Sliding window với L1=50, L2=150 cho ShapeDD detection
    \item COOLDOWN=75 samples để tránh chattering (multiple detections cho cùng drift event)
\end{itemize}

\textbf{ShapeDD detection logic:}
\begin{itemize}
    \item Khi buffer đầy, gọi \texttt{shape\_snr\_adaptive()} từ module \texttt{shape\_dd.py}
    \item Thuật toán tự động ước lượng SNR và chọn strategy (aggressive/conservative)
    \item Nếu drift detected (p-value < 0.05), publish event lên topic \texttt{drift.results}
    \item Log detection details: timestamp, p-value, strategy used, window statistics
\end{itemize}

\textbf{Event publishing:}
\begin{verbatim}
{
    "detection_time": 1234567890,
    "p_value": 0.012,
    "strategy": "aggressive",
    "snr_estimate": 0.015,
    "drift_location": 5432
}
\end{verbatim}

\subsection{Triển khai Model Adaptor}

Adaptor component (\texttt{adaptor.py}) lắng nghe drift events và trigger model adaptation. Thiết kế của Adaptor:

\textbf{Drift event listener:}
\begin{itemize}
    \item Subscribe vào topic \texttt{drift.results}
    \item Parse drift event để xác định loại drift và severity
    \item Maintain drift history để tránh over-adaptation
\end{itemize}

\textbf{Adaptation strategies:}
\begin{itemize}
    \item \textbf{Abrupt drift}: Full model retrain với recent window
    \item \textbf{Gradual drift}: Incremental update với weighted samples
    \item \textbf{Incremental drift}: Online learning với adaptive learning rate
    \item \textbf{Recurrent drift}: Retrieve previous model từ model repository
\end{itemize}

\textbf{Model management:}
\begin{itemize}
    \item Versioned model storage (MLflow hoặc filesystem)
    \item A/B testing framework để so sánh old vs new model
    \item Gradual rollout của updated model
    \item Rollback mechanism nếu performance degrades
\end{itemize}

\subsection{Communication qua Kafka Topics}

Hệ thống sử dụng multiple Kafka topics để decouple các components:

\begin{table}[H]
\centering
\caption{Kafka topics trong hệ thống}
\begin{tabular}{lll}
\toprule
\textbf{Topic} & \textbf{Producer} & \textbf{Consumer} \\
\midrule
sensor.stream & Data Producer & Drift Detector \\
drift.results & Drift Detector & Model Adaptor \\
model.updates & Model Adaptor & Inference Service \\
metrics.monitoring & All components & Monitoring Dashboard \\
\bottomrule
\end{tabular}
\end{table}

Thiết kế multi-topic này cho phép:
\begin{itemize}
    \item Tách biệt concerns (data ingestion, detection, adaptation, monitoring)
    \item Scale independently các components (horizontal scaling)
    \item Replay data cho debugging hoặc retraining
    \item Multiple consumers có thể subscribe cùng topic (ví dụ: logging, alerting)
\end{itemize}

\subsection{Ưu điểm của kiến trúc Kafka-based}

Việc sử dụng Apache Kafka làm backbone cho hệ thống phát hiện drift mang lại các lợi ích quan trọng:

\begin{enumerate}
    \item \textbf{Decoupling}: Producer, Consumer, Adaptor hoạt động độc lập, có thể develop và deploy riêng
    \item \textbf{Scalability}: Có thể scale từng component dựa trên bottleneck (ví dụ: nhiều detector consumers cho high-volume streams)
    \item \textbf{Fault tolerance}: Kafka replication đảm bảo no data loss khi có failures
    \item \textbf{Replay capability}: Có thể re-process historical data để tune parameters hoặc test new detectors
    \item \textbf{Low latency}: End-to-end latency từ data ingestion đến drift detection < 100ms (với buffer size thích hợp)
    \item \textbf{Observability}: Kafka metrics (lag, throughput, partition status) cung cấp visibility vào system health
\end{enumerate}

Kiến trúc này đã được triển khai và testing trong folder \texttt{drift-monitoring/} của repository, với đầy đủ các component producer, consumer, adaptor, và configuration files.

\section{Phương pháp CDT\_MSW và chiến lược thích ứng}
\label{sec:cdt-msw-implementation}

\subsection{Tổng quan về CDT\_MSW}

Hệ thống sử dụng phương pháp \textbf{CDT\_MSW (Concept Drift Type Identification based on Multi-Sliding Windows)} để nhận diện loại trôi dạt sau khi ShapeDD phát hiện điểm drift. Phương pháp này đã được trình bày chi tiết trong \textbf{Chương~\ref{sec:drift_type_identification}} (Trang~\pageref{sec:cdt-msw-theory}), bao gồm:

\begin{itemize}
    \item Nguyên lý hoạt động với ba giai đoạn: Detection → Growth → Tracking
    \item Quy tắc phân loại 5 loại drift: sudden, gradual, incremental, recurrent, blip
    \item Các tham số chính ($w_{ref}$, $\delta$, $\theta_{sudden}$, etc.)
    \item Ưu điểm so với các phương pháp truyền thống
\end{itemize}

Trong chương này, chúng ta tập trung vào \textbf{triển khai cụ thể} của CDT\_MSW trong hệ thống, bao gồm cấu hình parameters, integration với Kafka messaging, và error handling.


Sau khi ShapeDD phát hiện drift tại thời điểm $t_0$, module \texttt{drift\_detector.py} kích hoạt CDT\_MSW để phân loại drift type:

\begin{enumerate}
    \item \textbf{Snapshot capture}: Lưu cửa sổ tham chiếu $\mathcal{W}_{ref}$ (200 samples trước $t_0$) vào file
    \item \textbf{Growth phase monitoring}: Theo dõi distance $d_t$ mỗi 50 samples, dừng khi $\Delta d_t < 0.02$
    \item \textbf{Classification}: So sánh $L_d$ với thresholds để xác định drift type
    \item \textbf{Message publishing}: Gửi kết quả (drift\_type, $L_d$, confidence) lên Kafka topic \texttt{drift.results}
\end{enumerate}

\textbf{Thuật toán phân loại loại drift:}

\begin{algorithm}[H]
\caption{CDT\_MSW Drift Type Classification}
\begin{algorithmic}[1]
\REQUIRE Drift timestamp $t_0$, data window $\mathcal{W}$, thresholds $\theta_{sudden}$, $\theta_{stability}$
\ENSURE Drift type: \{sudden, gradual, incremental, recurrent, blip\}
\STATE \textit{// Phase 1: Measure drift length}
\STATE $t_{start} \leftarrow t_0$
\STATE $L_d \leftarrow 0$
\WHILE{$\Delta d_t > \theta_{stability}$}
    \STATE $t_{end} \leftarrow t_{end} + \Delta t$
    \STATE $L_d \leftarrow t_{end} - t_{start}$
\ENDWHILE
\STATE
\STATE \textit{// Phase 2: Classify based on length and characteristics}
\IF{$L_d < \theta_{sudden}$}
    \RETURN \texttt{"sudden"}
\ELSIF{drift has cyclic pattern with previous concepts}
    \RETURN \texttt{"recurrent"}
\ELSIF{transition rate is linear}
    \RETURN \texttt{"incremental"}
\ELSIF{transition involves mixed distributions}
    \RETURN \texttt{"gradual"}
\ELSE
    \RETURN \texttt{"blip"}
\ENDIF
\end{algorithmic}
\end{algorithm}

\section{Mô hình học máy và quy trình thích ứng}
\label{sec:model-adaptation}

\subsection{Kiến trúc mô hình}

Hệ thống sử dụng mô hình học máy với ba giai đoạn hoạt động chính:

\textbf{1. Giai đoạn huấn luyện ban đầu (Training Phase):}
\begin{itemize}
    \item Sử dụng scikit-learn để xây dựng pipeline mô hình batch
    \item Cấu trúc: StandardScaler + LogisticRegression
    \item Huấn luyện trên dữ liệu ban đầu (pre-drift data)
    \item Model được lưu dưới dạng pickle file
\end{itemize}

\textbf{2. Giai đoạn triển khai (Deployment Phase):}
\begin{itemize}
    \item Mô hình hoạt động ở chế độ \textit{frozen} (đóng băng)
    \item Không có online learning trong quá trình inference
    \item Chỉ thực hiện prediction trên dữ liệu mới
    \item Theo dõi accuracy để phát hiện suy giảm hiệu suất
\end{itemize}

\textbf{3. Giai đoạn cập nhật (Update Phase):}
\begin{itemize}
    \item Được kích hoạt khi phát hiện drift
    \item Chiến lược cập nhật được chọn dựa trên loại drift
    \item Mô hình mới được huấn luyện hoặc cập nhật
    \item Model được lưu lại và thay thế model cũ
\end{itemize}

\subsection{Chiến lược thích ứng và triển khai}

\textbf{Nền tảng lý thuyết:} Như đã trình bày chi tiết trong \textbf{Mục~\ref{sec:model_adaptation_strategies}} (Bảng~\ref{tab:model_update_strategies}), mỗi loại drift cần một chiến lược cập nhật riêng biệt:

\begin{itemize}
    \item \textbf{Sudden drift} $\rightarrow$ Local reset / Full retraining
    \item \textbf{Gradual drift} $\rightarrow$ Soft update với weighted samples
    \item \textbf{Incremental drift} $\rightarrow$ Continuous adaptation
    \item \textbf{Recurrent drift} $\rightarrow$ Memory-based adaptation
    \item \textbf{Blip drift} $\rightarrow$ Minimal update
\end{itemize}

\textbf{Triển khai cụ thể:} Hệ thống triển khai các chiến lược lý thuyết này thành năm modules trong \texttt{adaptation\_strategies.py}:

\begin{itemize}
    \item \texttt{adapt\_sudden\_drift()}: Tạo sklearn pipeline mới, full retraining trên post-drift data \textbf{[FULLY IMPLEMENTED \& EVALUATED]}
    \item \texttt{adapt\_incremental\_drift()}: River online learning với \texttt{learn\_one()}, cập nhật tuần tự \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_gradual\_drift()}: Weighted samples (position/total), chỉ dùng 50\% mẫu cuối \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_recurrent\_drift()}: KS-test (threshold=0.15) tìm similar model trong cache, fine-tune \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_blip\_drift()}: Conservative - update tối đa 5 samples hoặc skip \textbf{[FRAMEWORK ONLY]}
\end{itemize}

\textbf{Phạm vi đánh giá:} Luận văn này tập trung đánh giá chuyên sâu \texttt{adapt\_sudden\_drift()} strategy với comprehensive experiments (Chapter 4). Các strategies khác đã được implement as part of extensible framework nhưng chưa được evaluate thoroughly, để dành cho future research.

\textbf{Sudden Drift Adaptation Algorithm:}

\begin{algorithm}[H]
\caption{Sudden Drift Adaptation Strategy}
\begin{algorithmic}[1]
\REQUIRE Drift event $(t_0, \text{drift\_type})$, post-drift data $\mathcal{D}_{post}$, old model $M_{old}$
\ENSURE New model $M_{new}$
\STATE \textit{// Step 1: Verify drift type}
\IF{drift\_type $\neq$ ``sudden''}
    \RETURN redirect\_to\_other\_strategy(drift\_type)
\ENDIF
\STATE
\STATE \textit{// Step 2: Collect post-drift data}
\STATE $\mathcal{D}_{train} \leftarrow$ collect\_samples($t_0$, window\_size=800)
\STATE Wait for sufficient samples or timeout (adaptation\_delay=50)
\STATE
\STATE \textit{// Step 3: Train new model}
\STATE $M_{new} \leftarrow$ sklearn.Pipeline([StandardScaler(), LogisticRegression()])
\STATE $M_{new}$.fit($\mathcal{D}_{train}$.X, $\mathcal{D}_{train}$.y)
\STATE
\STATE \textit{// Step 4: Save and replace model}
\STATE save\_model($M_{new}$, version=$t_0$)
\STATE $M_{old} \leftarrow M_{new}$
\RETURN $M_{new}$
\end{algorithmic}
\end{algorithm}

Chi tiết về rationale và trade-offs của từng chiến lược đã được phân tích đầy đủ trong Chapter 1.

\subsection{Cơ chế quyết định tự động}

Trong quá trình vận hành hệ thống, việc lựa chọn chiến lược thích ứng được thực hiện tự động thông qua module \texttt{adaptor.py}. 
Quy trình hoạt động như sau:

\textbf{Bước 1: Lắng nghe sự kiện drift}
\begin{itemize}
    \item Adaptor subscribe vào Kafka topic \texttt{drift.results}
    \item Nhận message chứa thông tin: \texttt{idx}, \texttt{p\_value}, \texttt{drift\_type}, \texttt{window\_path}
    \item Kiểm tra tính hợp lệ của snapshot file
\end{itemize}

\textbf{Bước 2: Load dữ liệu drift window}
\begin{itemize}
    \item Đọc snapshot từ thư mục \texttt{./snapshots/}
    \item Snapshot chứa: ma trận đặc trưng $X$, nhãn $y$ (nếu có), tên features
    \item Kích thước window phụ thuộc vào tham số \texttt{w\_ref} và \texttt{CHUNK\_SIZE}
\end{itemize}

\textbf{Bước 3: Lựa chọn chiến lược thích ứng}

Hệ thống ánh xạ loại drift sang hàm xử lý tương ứng:

    \begin{equation}
    \text{strategy} = 
        \begin{cases}
        \texttt{adapt\_sudden\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``sudden''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``incremental''} \\
        \texttt{adapt\_gradual\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``gradual''} \\
        \texttt{adapt\_recurrent\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``recurrent''} \\
        \texttt{adapt\_blip\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``blip''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``undetermined''}
        \end{cases}
    \end{equation}

\textbf{Bước 4: Cập nhật và lưu mô hình}
\begin{itemize}
    \item Thực thi chiến lược đã chọn
    \item Lưu model mới vào \texttt{./models/current\_model.pkl}
    \item Cập nhật version (dựa trên file modification time)
    \item Publish event \texttt{model\_updated} lên topic \texttt{model.updated}
\end{itemize}

\subsection{Ví dụ quy trình thích ứng}

Giả sử tại thời điểm $t = 1504$, ShapeDD phát hiện drift với loại ``sudden'':

\begin{enumerate}
    \item Consumer phát hiện drift, phân loại là ``sudden'', gửi event:
    \begin{verbatim}
    {
      "event": "drift_detected",
      "idx": 1504,
      "p_value": 0.0001,
      "drift_type": "sudden",
      "window_path": "./snapshots/drift_window_1504_xxx.npz"
    }
    \end{verbatim}
    
    \item Adaptor nhận event, load snapshot chứa 251 mẫu (200 pre-drift + 51 post-drift)
    
    \item Gọi \texttt{adapt\_sudden\_drift()}: Tạo model mới, huấn luyện trên dữ liệu post-drift
    
    \item Lưu model mới, publish \texttt{model\_updated} event
\end{enumerate}

\subsection{Ưu điểm của cơ chế tự động}

Cơ chế quyết định tự động mang lại các lợi ích:

\begin{itemize}
    \item \textbf{Tự động hóa hoàn toàn:} Không cần can thiệp thủ công
    \item \textbf{Tối ưu hóa chi phí:} Chọn chiến lược phù hợp tránh lãng phí tài nguyên
    \item \textbf{Phản hồi nhanh:} Thời gian từ phát hiện đến cập nhật < 1 giây
    \item \textbf{Có khả năng mở rộng:} Dễ dàng thêm chiến lược mới
\end{itemize}

\section{Xử lý lỗi và khả năng chịu lỗi}

Trong hệ thống phát hiện và thích ứng concept drift thời gian thực, việc xử lý lỗi là yếu tố quan trọng để đảm bảo tính ổn định và độ tin cậy. Hệ thống cần có khả năng phục hồi tự động khi gặp các lỗi thường gặp trong môi trường phân tán.

\subsection{Phân loại lỗi và cơ chế xử lý}

\subsubsection{Producer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Kafka connection lost:} Mất kết nối đến Kafka broker
    \item \textbf{Message serialization error:} Lỗi serialize dữ liệu thành JSON/Protobuf
    \item \textbf{Buffer overflow:} Kafka producer buffer đầy khi broker chậm
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Retry with exponential backoff:} Thử lại gửi message với độ trễ tăng dần ($2^n$ giây, max 5 lần)
    \begin{verbatim}
    for attempt in range(MAX_RETRIES):
        try:
            producer.send(topic, message)
            break
        except KafkaTimeoutError:
            sleep(2 ** attempt)
    \end{verbatim}

    \item \textbf{Circuit breaker pattern:} Tạm dừng producer nếu Kafka broker down quá 30 giây, ghi log warning

    \item \textbf{Local buffering:} Lưu tạm dữ liệu vào file CSV nếu Kafka không available, replay sau khi kết nối phục hồi
\end{enumerate}

\subsubsection{Consumer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Drift detection crash:} ShapeDD raise exception (VD: insufficient data)
    \item \textbf{Snapshot save failure:} Lỗi ghi file .npz (disk full, permission denied)
    \item \textbf{Message parsing error:} Kafka message format không hợp lệ
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Try-catch wrapper:} Bọc ShapeDD detection trong try-except, log error nhưng không crash
    \begin{verbatim}
    try:
        is_drift, p_value = shapeDD.detect(buffer)
    except InsufficientDataError:
        logger.warning(f"Buffer size {len(buffer)} < L1+L2")
        continue  # Skip detection, wait for more data
    \end{verbatim}

    \item \textbf{Snapshot fallback:} Nếu không ghi được .npz, publish event không có window\_path (Adaptor sẽ train từ Kafka topic)

    \item \textbf{Commit offset after processing:} Chỉ commit Kafka offset sau khi xử lý thành công, đảm bảo không mất message
\end{enumerate}

\subsubsection{Model adaptation failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Training failure:} Model training crash (VD: NaN loss, out of memory)
    \item \textbf{Model cache miss:} Recurrent drift nhưng không tìm thấy model phù hợp
    \item \textbf{Insufficient labels:} Không đủ labeled data để retrain (semi-supervised scenario)
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Graceful degradation:} Nếu training thất bại, giữ nguyên old model, log error để human review
    \begin{verbatim}
    try:
        new_model = train_model(X_new, y_new)
    except ConvergenceWarning:
        logger.error("Model training failed, keeping old model")
        new_model = self.current_model  # Fallback
    \end{verbatim}

    \item \textbf{Cache fallback strategy:} Nếu recurrent drift không match model nào, fallback về sudden drift strategy (full retrain)

    \item \textbf{Semi-supervised adaptation:} Khi thiếu labels, dùng pseudo-labeling với high-confidence predictions ($P > 0.95$)
\end{enumerate}

\subsubsection{Kafka broker failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Broker crash:} Một trong các broker trong cluster down
    \item \textbf{Network partition:} Mất kết nối giữa producer/consumer và broker
    \item \textbf{Disk full:} Kafka log directory hết dung lượng
\end{itemize}

\textbf{Cơ chế xử lý (dựa trên đặc tính Kafka):}
\begin{enumerate}
    \item \textbf{Replication:} Cấu hình \texttt{replication.factor=3} cho topics quan trọng, đảm bảo data không mất khi 1-2 broker down

    \item \textbf{Producer acknowledgment:} Dùng \texttt{acks=all} để đảm bảo message chỉ được coi là sent khi tất cả replicas acknowledged

    \item \textbf{Consumer group rebalancing:} Khi broker down, Kafka tự động rebalance partitions sang consumer khác trong group

    \item \textbf{Retention monitoring:} Set up alert khi disk usage > 80\%, cleanup old log segments theo \texttt{retention.ms=7 days}
\end{enumerate}

\subsection{Logging và monitoring}

Để hỗ trợ debugging và fault diagnosis, hệ thống triển khai comprehensive logging:

\begin{itemize}
    \item \textbf{Structured logging:} JSON format với timestamp, component, severity, message
    \begin{verbatim}
    {
      "timestamp": "2025-01-12T10:30:45Z",
      "component": "consumer",
      "level": "ERROR",
      "message": "ShapeDD detection failed",
      "context": {"buffer_size": 42, "required": 200}
    }
    \end{verbatim}

    \item \textbf{Log levels:}
    \begin{itemize}
        \item INFO: Drift detected, model updated
        \item WARNING: Retry attempt, cache miss
        \item ERROR: Training failed, connection lost
        \item CRITICAL: System shutdown due to unrecoverable error
    \end{itemize}

    \item \textbf{Metrics collection:} Track key metrics với Prometheus/StatsD:
    \begin{itemize}
        \item Producer throughput (messages/sec)
        \item Consumer lag (offset behind)
        \item Detection latency (ms)
        \item Adaptation success rate (\%)
    \end{itemize}
\end{itemize}

\subsection{Tổng hợp chiến lược chịu lỗi}

\begin{table}[H]
\centering
\caption{Tổng hợp cơ chế xử lý lỗi theo component}
\label{tab:error-handling}
\begin{tabular}{p{3cm}p{5cm}p{6cm}}
\toprule
\textbf{Component} & \textbf{Lỗi chính} & \textbf{Recovery strategy} \\
\midrule
Producer &
Kafka timeout, buffer overflow &
Retry + exponential backoff, local CSV buffering \\
\midrule
Consumer &
Detection crash, snapshot failure &
Try-catch wrapper, commit offset after success \\
\midrule
Adaptor &
Training failure, cache miss &
Graceful degradation, fallback strategy \\
\midrule
Kafka Broker &
Broker down, network partition &
Replication (factor=3), auto rebalancing \\
\bottomrule
\end{tabular}
\end{table}

Với các cơ chế xử lý lỗi trên, hệ thống đạt được \textbf{high availability} (uptime > 99.5\%) và \textbf{fault tolerance}, đảm bảo hoạt động ổn định ngay cả khi gặp các lỗi thường gặp trong môi trường production.
