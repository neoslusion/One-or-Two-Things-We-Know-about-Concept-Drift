\chapter{Mô hình đề xuất cho hệ thống phát hiện và thích ứng concept drift}
\label{chap:proposed-model}

Dựa trên nền tảng lý thuyết ShapeDD đã trình bày ở Chương~3, chương này đề xuất các cải tiến 
và xây dựng hệ thống phát hiện drift hoàn chỉnh. Đóng góp chính là phương pháp ShapeDD SNR-Adaptive,
kết hợp với CDT\_MSW để phân loại drift và các chiến lược thích ứng tương ứng.

\section{Phương pháp cải tiến đề xuất cho ShapeDD}

\subsection{ShapeDD SNR-Adaptive: Phương pháp hybrid thích ứng với tỷ lệ tín hiệu-nhiễu}

Phần này trình bày phương pháp cải tiến ShapeDD SNR-Adaptive - một đóng góp nghiên cứu chính của luận văn này. 
Phương pháp này mở rộng ShapeDD gốc bằng cách tự động điều chỉnh chiến lược phát hiện dựa trên đặc trưng Signal-to-Noise Ratio (SNR) 
của môi trường dữ liệu.

\subsubsection{Phát hiện quan trọng: Ảnh hưởng của tỷ lệ tín hiệu-nhiễu (SNR)}

Phân tích lý thuyết cho thấy một kết quả quan trọng: \textbf{không có chiến lược phát hiện 
drift duy nhất là tối ưu cho mọi môi trường SNR}.

\textbf{Môi trường SNR cao} (tín hiệu drift mạnh, nhiễu thấp):
\begin{itemize}
    \item Ngưỡng tích cực (aggressive threshold) phù hợp hơn
    \item Có thể phát hiện sớm với recall cao mà không gây nhiều false positive
    \item Lý do: Tín hiệu drift vượt xa nhiễu, dễ phân biệt
\end{itemize}

\textbf{Môi trường SNR thấp} (tín hiệu drift yếu, nhiễu cao):
\begin{itemize}
    \item Ngưỡng bảo thủ (conservative threshold) hiệu quả hơn
    \item Đạt precision cao bằng cách chờ tín hiệu rõ ràng vượt ngưỡng nhiễu
    \item Lý do: Tín hiệu drift gần với nhiễu, cần threshold cao để tránh false alarm
\end{itemize}

\subsubsection{Nền tảng lý thuyết: Lý thuyết phát hiện tín hiệu}

Kết quả này phản ánh một nguyên lý cơ bản trong lý thuyết phát hiện 
tín hiệu (Signal Detection Theory) và tiêu chuẩn Neyman-Pearson~\cite{neyman1933problem}:

\begin{equation}
\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}
\end{equation}

Trong đó:
\begin{itemize}
    \item $\sigma^2_{\text{signal}}$: phương sai của tín hiệu drift (độ biến thiên giữa các cửa sổ)
    \item $\sigma^2_{\text{noise}}$: phương sai nhiễu nội tại trong dữ liệu
\end{itemize}

\textbf{Đánh đổi Precision-Recall theo SNR:}

\begin{itemize}
    \item \textbf{Ngưỡng tích cực (thấp):}
    \begin{itemize}
        \item Recall cao (phát hiện nhiều drift)
        \item Nguy cơ báo động giả trên nhiễu (False Positive tăng)
        \item Phù hợp khi SNR cao
    \end{itemize}

    \item \textbf{Ngưỡng bảo thủ (cao):}
    \begin{itemize}
        \item Precision cao (ít báo động giả)
        \item Nguy cơ bỏ lỡ tín hiệu yếu (False Negative tăng)
        \item Phù hợp khi SNR thấp
    \end{itemize}
\end{itemize}

\subsubsection{Giải pháp: Phương pháp hybrid thích ứng SNR}

Để khắc phục hạn chế của các chiến lược đơn lẻ, Luận văn đề xuất phương pháp \textbf{ShapeDD SNR-Adaptive} - một thuật toán 
hybrid tự động chọn chiến lược phát hiện dựa trên SNR ước lượng của môi trường:

\textbf{SNR Estimation Algorithm:}

\begin{algorithm}[H]
\caption{SNR Estimation from Data Stream}
\begin{algorithmic}[1]
\REQUIRE Data $X$, window size $w$, number of windows $k$
\ENSURE SNR estimate
\STATE Split $X$ into $k$ windows of size $w$
\STATE Compute mean of each window: $\mu_1, \mu_2, ..., \mu_k$
\STATE Compute inter-window variance: $\sigma^2_{\text{signal}} = \text{Var}(\mu_1, ..., \mu_k)$
\STATE Compute average intra-window variance: $\sigma^2_{\text{noise}} = \frac{1}{k}\sum_{i=1}^{k}\text{Var}(X_i)$
\RETURN $\text{SNR} = \frac{\sigma^2_{\text{signal}}}{\sigma^2_{\text{noise}}}$
\end{algorithmic}
\end{algorithm}

\textbf{Strategy Selection Logic:}

\begin{algorithm}[H]
\caption{ShapeDD SNR-Adaptive}
\begin{algorithmic}[1]
\REQUIRE Data $X$, SNR threshold $\tau$, sensitivity $s$
\ENSURE Drift detection result
\STATE $\text{SNR}_{\text{est}} \leftarrow$ \texttt{estimate\_snr}$(X)$
\IF{$\text{SNR}_{\text{est}} > \tau$}
    \STATE \textit{// High SNR environment - use aggressive strategy}
    \RETURN \texttt{shape\_adaptive\_v2}$(X, \text{sensitivity}=s)$
\ELSE
    \STATE \textit{// Low SNR environment - use conservative strategy}
    \RETURN \texttt{shape}$(X)$ \textit{// Original ShapeDD}
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{image/snr_adaptive_architecture.png}
\caption{Kiến trúc hệ thống ShapeDD SNR-Adaptive.} 
\label{fig:snr_adaptive_architecture}
\end{figure}
Hệ thống ước lượng SNR từ luồng dữ liệu đầu vào, sau đó chọn chiến lược phát hiện thích ứng 
(aggressive hoặc conservative) dựa trên ngưỡng SNR. Chiến lược aggressive sử dụng threshold 
thấp hơn để phát hiện sớm (phù hợp với high SNR), trong khi chiến lược conservative sử dụng 
threshold cao hơn để giảm false positive (phù hợp với low SNR). Việc lựa chọn strategy dựa 
trên tiêu chuẩn Neyman-Pearson nhằm cân bằng Type I và Type II errors.

\subsubsection{Ưu điểm của phương pháp SNR-Adaptive}

Phương pháp hybrid này mang lại các lợi ích sau:

\begin{enumerate}
    \item \textbf{Robust trên nhiều môi trường:} Tự động thích ứng với đặc điểm SNR của dữ liệu
    \item \textbf{Tối ưu F1-score:} Kết hợp điểm mạnh của cả hai chiến lược
    \item \textbf{Không cần điều chỉnh thủ công:} Tự động ước lượng và lựa chọn chiến lược
    \item \textbf{Nền tảng lý thuyết vững chắc:} Dựa trên lý thuyết phát hiện tín hiệu
\end{enumerate}

\subsubsection{Đánh giá thực nghiệm}

Đánh giá toàn diện phương pháp SNR-Adaptive, bao gồm:
\begin{itemize}
    \item Phân tích hiệu ứng pha loãng SNR trong môi trường buffer
    \item Tối ưu hóa tham số (ngưỡng $\tau$ và độ nhạy $s$) dựa trên tiêu chuẩn Neyman-Pearson
    \item So sánh hiệu suất với 17 phương pháp baseline khác trên 8 datasets
    \item Phân tích phân bố chiến lược (aggressive vs conservative) và ảnh hưởng đến F1-score
    \item Sensitivity analysis với các giá trị threshold khác nhau
\end{itemize}

\textbf{Kết quả chi tiết được trình bày trong Chapter~\ref{chap:experiments}, Section 4.6 "Đánh giá SNR-Adaptive".}

\subsection{Khung chiến lược thích ứng}

\subsection{Phương pháp Meta-Learning}

Luận văn phát triển khung meta-learning tự động lựa chọn chiến lược thích ứng dựa trên đặc trưng drift được phát hiện:

\textbf{Trích xuất feature:} Đối với mỗi episode drift được phát hiện, nghiên cứu trích xuất feature mô tả:
\begin{itemize}
    \item Mức độ drift: $|\Delta(t_1, t_2)|$
    \item Tốc độ drift: $\frac{|\Delta(t_1, t_2)|}{t_2 - t_1}$
    \item Chiều bị ảnh hưởng: Số lượng feature cho thấy thay đổi đáng kể
    \item Ngữ cảnh lịch sử: Các mẫu drift trước đây và kết quả thích ứng
\end{itemize}

\textbf{Lựa chọn chiến lược:} Meta-classifier được huấn luyện trên các episode drift lịch sử dự đoán 
chiến lược thích ứng phù hợp nhất:

\begin{equation}
s^* = \arg\max_{s \in \mathcal{S}} P(s|\mathbf{f}_{\text{drift}})
\end{equation}

trong đó $\mathbf{f}_{\text{drift}}$ biểu thị các feature drift được trích xuất và $\mathcal{S}$ là tập hợp các chiến lược thích ứng có sẵn.

\subsection{Quản lý cửa sổ thích ứng}

Luận văn đề xuất chiến lược quản lý cửa sổ thích ứng điều chỉnh kích thước cửa sổ dựa trên đặc trưng drift:

\begin{equation}
w_{\text{size}}(t) = w_{\text{base}} \cdot \exp(-\lambda \cdot \Delta(t))
\end{equation}

trong đó $w_{\text{base}}$ là kích thước cửa sổ cơ sở, $\lambda$ là tham số suy giảm, và $\Delta(t)$ là mức độ drift được phát hiện.

\subsection{Các biến thể của ShapeDD}

Sau khi trình bày phương pháp SNR-Adaptive -- đóng góp chính của nghiên cứu này -- phần tiếp theo sẽ phân tích chi tiết các biến thể khác của ShapeDD đã được triển khai và đánh giá. Mỗi biến thể được thiết kế để giải quyết các thách thức cụ thể trong phát hiện drift, với những cải tiến và đánh đổi (trade-offs) riêng.

\textbf{1. ShapeDD Adaptive:} Phiên bản adaptive đầu tiên giới thiệu khái niệm sensitivity levels để điều chỉnh độ nhạy của detector:

\begin{itemize}
    \item \textbf{Gamma selection:} Sử dụng Scott's rule để tự động chọn bandwidth kernel:
    \begin{equation}
    \gamma = \frac{1}{2\sigma^2}, \quad \sigma = \sigma_{\text{data}} \cdot n^{-1/(d+4)}
    \end{equation}

    \item \textbf{Sensitivity levels:} Năm mức độ nhạy với các threshold multipliers khác nhau:
    \begin{itemize}
        \item \texttt{low}: $\text{threshold} = \text{baseline} \times 1.5$ (bảo thủ nhất)
        \item \texttt{medium}: $\text{threshold} = \text{baseline} \times 1.2$
        \item \texttt{high}: $\text{threshold} = \text{baseline} \times 0.8$
        \item \texttt{ultrahigh}: $\text{threshold} = \text{baseline} \times 0.5$ (tích cực nhất)
        \item \texttt{none}: Không có threshold, chấp nhận mọi candidate
    \end{itemize}

    \item \textbf{FDR correction:} Áp dụng Benjamini-Hochberg procedure để kiểm soát False Discovery Rate trong multiple testing
\end{itemize}

\textbf{2. ShapeDD Adaptive v2 - Năm cải tiến quan trọng:}

Phiên bản adaptive\_v2 khắc phục các vấn đề nghiêm trọng trong adaptive gốc thông qua năm cải tiến then chốt:

\begin{enumerate}
    \item \textbf{Corrected sensitivity logic (Sửa lỗi threshold):}
    \begin{itemize}
        \item \textit{Vấn đề:} Adaptive gốc đảo ngược ý nghĩa của sensitivity - "high sensitivity" lại dùng threshold cao (kém nhạy)
        \item \textit{Giải pháp:} Đảo ngược threshold multipliers:
        \begin{align*}
        \texttt{low} &\rightarrow \times 1.2 \text{ (threshold cao, bảo thủ)} \\
        \texttt{medium} &\rightarrow \times 0.8 \\
        \texttt{high} &\rightarrow \times 0.5 \\
        \texttt{ultrahigh} &\rightarrow \times 0.25 \text{ (threshold thấp, tích cực)}
        \end{align*}
    \end{itemize}

    \item \textbf{Minimal smoothing (Giảm làm mượt):}
    \begin{itemize}
        \item \textit{Vấn đề:} Smoothing window $= \sqrt{l_1}$ quá lớn, làm mờ drift signals
        \item \textit{Giải pháp:} Giảm xuống còn 3-point moving average:
        \begin{equation}
        \text{smooth\_window} = 3 \quad (\text{thay vì } \max(3, \lceil\sqrt{l_1}\rceil))
        \end{equation}
    \end{itemize}

    \item \textbf{Percentile-based threshold (Ngưỡng robust):}
    \begin{itemize}
        \item \textit{Vấn đề:} Mean-based baseline dễ bị ảnh hưởng bởi outliers
        \item \textit{Giải pháp:} Sử dụng 10th percentile của positive shapes:
        \begin{equation}
        \text{baseline} = \text{percentile}(\text{positive\_shapes}, 10)
        \end{equation}
        \item Robust hơn với extreme values và noise spikes
    \end{itemize}

    \item \textbf{Adaptive FDR (FDR có điều kiện):}
    \begin{itemize}
        \item \textit{Vấn đề:} FDR correction luôn được áp dụng, làm giảm recall không cần thiết trong clean environments
        \item \textit{Giải pháp:} Chỉ áp dụng FDR khi detection density cao:
        \begin{equation}
        \text{Apply FDR if} \quad \frac{|\text{candidates}|}{n} < 0.03
        \end{equation}
        \item Tránh over-correction trong scenarios với ít drift
    \end{itemize}

    \item \textbf{Hybrid threshold strategy (Kết hợp strategies):}
    \begin{itemize}
        \item Sử dụng cả magnitude threshold và statistical test
        \item Drift được chấp nhận nếu:
        \begin{equation}
        (\text{magnitude} > \text{threshold}) \land (p\text{-value} < \alpha)
        \end{equation}
        \item Cân bằng giữa sensitivity và specificity
    \end{itemize}
\end{enumerate}

\textbf{3. ShapeDD Sensitive:} Biến thể được tối ưu cho phát hiện drift nhỏ và tinh tế:

\begin{itemize}
    \item \textbf{Smaller windows:} Sử dụng $l_1 = 30$, $l_2 = 100$ (nhỏ hơn default 50/150)
    \item \textbf{Aggressive gamma:} $\gamma = 2.0 / \text{median\_dist}^2$ (gấp đôi sensitivity)
    \item \textbf{Lower threshold:} Baseline multiplier = 0.6 (thấp hơn "high" sensitivity)
    \item \textbf{Trade-off:} Recall cao hơn nhưng false positive rate tăng
\end{itemize}

\subsubsection{Bảng so sánh các biến thể ShapeDD}

\begin{table}[H]
\centering
\caption{So sánh các biến thể ShapeDD}
\label{tab:shapedd-variants}
\begin{tabular}{|l|p{2.5cm}|p{3cm}|p{3cm}|p{3cm}|}
\hline
\textbf{Biến thể} & \textbf{Đặc điểm chính} & \textbf{Ưu điểm} & \textbf{Nhược điểm} & \textbf{Khi nào dùng} \\
\hline
\textbf{Original} & Conservative, high precision & Ít false positive, ổn định & Có thể miss subtle drift & Default choice, high-stakes scenarios \\
\hline
\textbf{Adaptive} & Sensitivity levels, gamma auto-selection & Flexible, FDR control & Inverted threshold logic (bug) & Không khuyến nghị (dùng v2) \\
\hline
\textbf{Adaptive v2} & 5 critical fixes, corrected logic & Balanced P-R, robust & Phức tạp hơn & Multi-drift scenarios, noisy data \\
\hline
\textbf{Sensitive} & Small windows, aggressive threshold & High recall, early detection & High FP rate & Subtle drift, low latency required \\
\hline
\textbf{SNR-Adaptive} & Hybrid strategy, SNR-aware & Best F1-score, auto-adapt & Requires SNR estimation & Production, unknown SNR environments \\
\hline
\end{tabular}
\end{table}

\subsubsection{Hiệu ứng pha loãng buffer (Buffer Dilution Effect)}

Một phát hiện quan trọng trong nghiên cứu này là \textbf{buffer dilution effect} - hiện tượng SNR quan sát được thấp hơn nhiều so với SNR lý thuyết khi sử dụng rolling buffer trong phát hiện drift thực tế.

\textbf{Lý thuyết vs Thực tế:}

\begin{itemize}
    \item \textbf{SNR lý thuyết} (isolated drift trong môi trường sạch):
    \begin{equation}
    \text{SNR}_{\text{theory}} \in [0.4, 4.0]
    \end{equation}
    Giả định: Drift point riêng biệt, không có dữ liệu ổn định xen kẽ

    \item \textbf{SNR quan sát được} (buffer-based detection):
    \begin{equation}
    \text{SNR}_{\text{observed}} \in [0.005, 0.020]
    \end{equation}
    Giảm khoảng \textbf{100 lần} so với lý thuyết!
\end{itemize}

\textbf{Nguyên nhân:} Trong phát hiện thực tế, chúng ta sử dụng rolling buffer chứa dữ liệu hỗn hợp:

\begin{equation}
\text{Buffer}_{750} = \underbrace{[\text{Stable data}]}_{\sim 90\%} + \underbrace{[\text{Drift data}]}_{\sim 10\%}
\end{equation}

Với buffer size = 750 và drift detection window = 150:
\begin{itemize}
    \item Tỷ lệ drift data: $150 / 750 = 20\%$ (lý tưởng)
    \item Thực tế: Do overlap và continuous streaming, chỉ $\sim 10\%$ là pure drift signal
    \item Phần còn lại ($\sim 90\%$) là stable data, "pha loãng" tín hiệu drift
\end{itemize}

\textbf{Tác động lên signal variance:}

\begin{equation}
\sigma^2_{\text{signal,buffer}} = \sigma^2_{\text{signal,theory}} \times \left(\frac{\text{\% drift data}}{100\%}\right)^2 \approx \sigma^2_{\text{signal,theory}} \times 0.01
\end{equation}

Do đó: $\text{SNR}_{\text{buffer}} \approx \text{SNR}_{\text{theory}} / 100$

\textbf{Hệ quả quan trọng cho SNR-Adaptive:}

Threshold phải được hiệu chỉnh (calibrated) cho môi trường buffer:
\begin{itemize}
    \item Threshold lý thuyết: $\tau_{\text{theory}} \approx 0.5$ (midpoint của [0.4, 4.0])
    \item Threshold buffer-calibrated: $\tau_{\text{buffer}} = 0.010$ (midpoint của [0.005, 0.020])
    \item Giảm 50 lần: $\tau_{\text{buffer}} = \tau_{\text{theory}} / 50$
\end{itemize}

Threshold 0.010 được chọn dựa trên:
\begin{enumerate}
    \item \textbf{Empirical observation:} Phân tích SNR quan sát trên 8 datasets cho thấy observed SNR range [0.005, 0.020], với midpoint = 0.010

    \item \textbf{Neyman-Pearson optimization:} Threshold tối ưu được xác định bằng cách minimize tổng detection errors khi Type I error (false positive) và Type II error (false negative) có cost bằng nhau:
    \begin{equation}
    \tau^* = \arg\min_{\tau} \left[ P(\text{FP}|\tau) + P(\text{FN}|\tau) \right]
    \end{equation}
    Với equal costs, optimal threshold nằm tại điểm mà precision $\approx$ recall, tương đương strategy distribution $\approx$ 50/50.

    \item \textbf{Strategy balance validation:} Đạt $\sim 50\%$ aggressive / $\sim 50\%$ conservative, xác nhận threshold nằm gần tối ưu Neyman-Pearson
\end{enumerate}

\textbf{Validation qua thực nghiệm:} Với threshold = 0.010:
\begin{itemize}
    \item Strategy distribution: 58.7\% aggressive, 41.3\% conservative ($\approx$ 50/50)
    \item F1-score: 0.697 (ranked 4th/18 methods)
    \item Balanced precision-recall trade-off
\end{itemize}

Hiệu ứng buffer dilution giải thích tại sao threshold phải được điều chỉnh đáng kể so với giá trị lý thuyết để phương pháp SNR-Adaptive hoạt động hiệu quả trong môi trường production thực tế.

\subsection{Optimally-Weighted MMD (OW-MMD): Cải thiện hiệu suất tính toán}
\label{sec:ow-mmd}

Phần này trình bày phương pháp OW-MMD (Optimally-Weighted MMD) -- một cải tiến quan trọng nhằm giải quyết vấn đề hiệu suất tính toán của MMD trong phát hiện drift.

\subsubsection{Vấn đề: Độ phức tạp tính toán cao của MMD gốc}

MMD (Maximum Mean Discrepancy) gốc trong ShapeDD sử dụng permutation test với số lần hoán vị lớn (n\_perm = 2500) để ước lượng p-value. Điều này dẫn đến:

\begin{itemize}
    \item \textbf{Chi phí tính toán:} $O(n^2 \times \text{n\_perm})$ với $n$ là kích thước cửa sổ
    \item \textbf{Thời gian chạy:} ~30-60 giây mỗi cửa sổ với buffer 750 samples
    \item \textbf{Không phù hợp real-time:} Độ trễ quá cao cho hệ thống streaming
\end{itemize}

\subsubsection{Giải pháp: OW-MMD với variance-reduction weighting}

OW-MMD (Optimally-Weighted MMD) được giới thiệu bởi Bharti et al.~\cite{bharti2023owmmd} tại ICML 2023, áp dụng trọng số tối ưu vào ước lượng MMD để giảm variance và cải thiện sample complexity.

\textbf{Nguyên lý hoạt động:}

MMD gốc sử dụng trọng số uniform:
\begin{equation}
\text{MMD}^2 = \frac{1}{m^2} \sum_{i,j} k(x_i, x_j) + \frac{1}{n^2} \sum_{i,j} k(y_i, y_j) - \frac{2}{mn} \sum_{i,j} k(x_i, y_j)
\end{equation}

OW-MMD thay thế bằng trọng số tối ưu:
\begin{equation}
\text{MMD}^2_{\text{OW}} = \sum_{i,j} w^{XX}_{ij} k(x_i, x_j) + \sum_{i,j} w^{YY}_{ij} k(y_i, y_j) - 2\sum_{i,j} w^{XY}_{ij} k(x_i, y_j)
\end{equation}

Trong đó trọng số được tính theo công thức variance-reduction:
\begin{equation}
w_{ij} = \frac{1}{\sqrt{k_i^{\text{sum}}}} \cdot \frac{1}{\sqrt{k_j^{\text{sum}}}}, \quad k_i^{\text{sum}} = \sum_{j} k(x_i, x_j)
\end{equation}

\textbf{Ý nghĩa:} Các điểm có nhiều neighbor tương đồng (kernel sum cao) được gán trọng số thấp hơn để giảm redundancy, trong khi các điểm isolated được gán trọng số cao hơn.

\subsubsection{Triển khai ShapeDD\_OW\_MMD}

Nghiên cứu này kết hợp OW-MMD vào framework ShapeDD thông qua hybrid approach:

\begin{enumerate}
    \item \textbf{Stage 1 - Fast geometric detection:} Sử dụng ShapeDD kernel để phát hiện nhanh các peak candidates (không thay đổi)
    
    \item \textbf{Stage 2 - OW-MMD validation:} Thay thế permutation MMD bằng OW-MMD với bootstrap-calibrated threshold
\end{enumerate}

\textbf{Thuật toán:}

\begin{algorithm}[H]
\caption{ShapeDD\_OW\_MMD Hybrid Detection}
\begin{algorithmic}[1]
\REQUIRE Data buffer $X$, window sizes $l_1$, $l_2$
\ENSURE Drift detection results with p-values
\STATE \textit{// Stage 1: Fast geometric pattern detection}
\STATE $K \leftarrow$ RBF kernel matrix of $X$
\STATE $\sigma(t) \leftarrow$ Compute ShapeDD shape curve via convolution
\STATE $\text{peaks} \leftarrow$ Find zero-crossings in $\sigma'(t)$ where $\sigma(t) > 0$
\STATE
\STATE \textit{// Stage 2: OW-MMD validation at peaks only}
\FOR{each peak $p$ in peaks}
    \STATE $X_{ref}, X_{test} \leftarrow$ Split window around $p$
    \STATE $\text{mmd\_value} \leftarrow$ Compute OW-MMD statistic
    \STATE $\text{threshold} \leftarrow$ Bootstrap 95th percentile (n=10)
    \IF{$\text{mmd\_value} > \text{threshold}$}
        \STATE Mark $p$ as drift with p-value $< 0.05$
    \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

\subsubsection{Cải tiến hiệu suất đạt được}

So sánh hiệu suất ShapeDD gốc và ShapeDD\_OW\_MMD:

\begin{table}[H]
\centering
\caption{So sánh hiệu suất ShapeDD và ShapeDD\_OW\_MMD}
\label{tab:owmmd-performance}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{ShapeDD (MMD)} & \textbf{ShapeDD\_OW\_MMD} \\
\midrule
Bootstrap samples & 2500 & 10 \\
Kernel computations & $O(n^2 \times 2500)$ & $O(n^2 \times 10)$ \\
Speedup & 1× (baseline) & $\sim$3× faster \\
F1-score & Baseline & Comparable \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Khi nào sử dụng OW-MMD}

\begin{itemize}
    \item \textbf{Nên dùng:} Khi cần giảm thời gian phát hiện, môi trường real-time, high-throughput streaming
    \item \textbf{Trade-off:} Có thể có slight accuracy loss so với full permutation test
    \item \textbf{Không khuyến nghị:} Khi accuracy là ưu tiên cao nhất và thời gian không bị giới hạn
\end{itemize}

\subsection{Tổng kết các cải tiến ShapeDD}

Bảng dưới đây tóm tắt các cải tiến được đề xuất trong nghiên cứu này, với mục tiêu và kết quả đạt được:

\begin{table}[H]
\centering
\caption{Tổng kết các cải tiến ShapeDD}
\label{tab:shapedd-improvements-summary}
\begin{tabular}{|l|p{4cm}|p{4cm}|p{3cm}|}
\hline
\textbf{Cải tiến} & \textbf{Vấn đề giải quyết} & \textbf{Phương pháp} & \textbf{Kết quả} \\
\hline
SNR-Adaptive & Threshold cố định không phù hợp mọi môi trường & Hybrid strategy selection dựa trên SNR estimation & F1-score cải thiện 5-10\% \\
\hline
Adaptive v2 & Bugs trong sensitivity logic của v1 & 5 critical fixes (threshold, smoothing, FDR) & Precision-Recall balanced \\
\hline
OW-MMD & Chi phí tính toán cao của permutation test & Variance-reduction weighting, reduced bootstrap & ~3× faster \\
\hline
Buffer calibration & SNR bị "pha loãng" trong rolling buffer & Empirical threshold calibration & Accurate in production \\
\hline
\end{tabular}
\end{table}

\section{Nền tảng xử lý luồng dữ liệu phân tán với Apache Kafka}

Các phần trước đã trình bày chi tiết các phương pháp phát hiện drift (ShapeDD và các biến thể). Để triển khai các phương pháp này trong môi trường production với dữ liệu streaming real-time, nghiên cứu cần một nền tảng xử lý luồng dữ liệu mạnh mẽ. Phần này giới thiệu Apache Kafka -- nền tảng được chọn làm backbone cho hệ thống phát hiện và thích ứng drift.

Trong bối cảnh triển khai hệ thống phát hiện concept drift thời gian thực, việc lựa chọn một nền tảng xử lý luồng dữ liệu (stream processing platform) mạnh mẽ và đáng tin cậy là rất quan trọng. Apache Kafka~\cite{kreps2011kafka} đã trở thành nền tảng tiêu chuẩn công nghiệp cho xử lý luồng dữ liệu phân tán, được sử dụng rộng rãi trong các hệ thống big data và real-time analytics. Phần này trình bày nền tảng lý thuyết của Apache Kafka làm cơ sở cho việc triển khai hệ thống phát hiện drift trong các phần tiếp theo của chương này.

\subsection{Kiến trúc Apache Kafka}

Apache Kafka là một hệ thống xử lý tin nhắn phân tán (distributed messaging system) được thiết kế để xử lý luồng dữ liệu thời gian thực với khối lượng lớn (high-throughput)~\cite{kreps2011kafka}. Kafka được phát triển ban đầu tại LinkedIn và sau đó trở thành một dự án mã nguồn mở của Apache Software Foundation.

\subsubsection{Các thành phần chính}

Kiến trúc Kafka bao gồm các thành phần chính sau~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Producer (Nhà sản xuất):} Ứng dụng gửi dữ liệu (messages) vào Kafka. Producer chịu trách nhiệm chọn partition nào sẽ nhận message trong một topic, có thể dựa trên round-robin hoặc semantic partitioning.

    \item \textbf{Consumer (Người tiêu dùng):} Ứng dụng đọc và xử lý dữ liệu từ Kafka. Consumer theo dõi vị trí đọc của mình (offset) trong mỗi partition, cho phép đọc lại dữ liệu khi cần thiết.

    \item \textbf{Broker (Máy chủ):} Các server Kafka lưu trữ và quản lý messages. Một Kafka cluster bao gồm nhiều broker để đảm bảo tính khả dụng cao (high availability) và khả năng mở rộng (scalability).

    \item \textbf{Topic:} Danh mục hoặc feed name mà messages được publish vào. Mỗi topic được chia thành các partition để hỗ trợ tính song song (parallelism) và khả năng mở rộng.

    \item \textbf{Partition:} Mỗi partition là một chuỗi có thứ tự, bất biến (immutable) các messages được liên tục append vào. Messages trong partition được gán một số định danh tuần tự gọi là offset.

    \item \textbf{ZooKeeper:} Hệ thống phối hợp phân tán (distributed coordination) quản lý metadata của Kafka cluster, theo dõi trạng thái của broker và consumer.
\end{itemize}

\subsubsection{Mô hình Producer-Consumer}

Kafka sử dụng mô hình publish-subscribe, trong đó~\cite{kleppmann2015kafka}:

\begin{enumerate}
    \item \textbf{Producers} publish messages vào các topic mà không cần biết ai sẽ consume chúng
    \item \textbf{Consumers} subscribe vào các topic và nhận messages theo thứ tự mà chúng được written
    \item Mỗi consumer thuộc về một \textbf{consumer group}, và mỗi message chỉ được deliver tới một consumer trong group
    \item Kafka duy trì offset cho mỗi consumer, cho phép consumer đọc lại (replay) messages khi cần
\end{enumerate}

Mô hình này cho phép nhiều producer và consumer hoạt động độc lập, tạo ra một hệ thống decoupled và có khả năng mở rộng cao.

\subsection{Đặc điểm kỹ thuật của Kafka}

\subsubsection{High Throughput và Low Latency}

Kafka được thiết kế để xử lý hàng triệu messages mỗi giây với độ trễ thấp~\cite{hiraman2018apache}. Điều này đạt được thông qua:

\begin{itemize}
    \item \textbf{Sequential I/O:} Kafka ghi messages vào disk theo thứ tự tuần tự, tận dụng đặc điểm của modern disk để đạt hiệu suất cao
    \item \textbf{Zero-copy:} Sử dụng sendfile() system call để chuyển dữ liệu trực tiếp từ disk đến network socket mà không cần copy qua user space
    \item \textbf{Batching:} Messages được gom lại thành batch để giảm network overhead
    \item \textbf{Compression:} Hỗ trợ nén messages (Gzip, Snappy, LZ4) để giảm băng thông mạng và dung lượng lưu trữ
\end{itemize}

\subsubsection{Tính bền vững và đáng tin cậy (Durability và Reliability)}

Kafka đảm bảo tính bền vững của dữ liệu thông qua~\cite{wang2015building}:

\begin{itemize}
    \item \textbf{Replication:} Mỗi partition có thể được replicate trên nhiều broker. Một partition có một leader và nhiều follower. Writes và reads đều đi qua leader, trong khi follower replicate dữ liệu.

    \item \textbf{In-Sync Replicas (ISR):} Tập hợp các replica đang synchronized với leader. Message chỉ được coi là committed khi tất cả ISR đã replicate nó.

    \item \textbf{Acknowledgment levels:} Producer có thể cấu hình mức độ acknowledgment:
    \begin{itemize}
        \item \texttt{acks=0}: Producer không đợi acknowledgment (fastest, least reliable)
        \item \texttt{acks=1}: Leader ghi vào log local trước khi ack (balanced)
        \item \texttt{acks=all}: Tất cả ISR replicate trước khi ack (slowest, most reliable)
    \end{itemize}
\end{itemize}

\subsubsection{Khả năng mở rộng (Scalability)}

Kafka scale theo chiều ngang (horizontal scaling) thông qua:

\begin{itemize}
    \item \textbf{Partitioning:} Mỗi topic có thể chia thành nhiều partition, mỗi partition có thể nằm trên broker khác nhau
    \item \textbf{Consumer groups:} Nhiều consumer trong cùng group có thể xử lý song song các partition khác nhau
    \item \textbf{Broker addition:} Có thể thêm broker mới vào cluster và rebalance partition
\end{itemize}

\subsection{Kafka Streams và Stream Processing}

Kafka Streams là một thư viện client-side để xây dựng ứng dụng xử lý luồng dữ liệu và microservices~\cite{kleppmann2015kafka}. Các đặc điểm chính:

\begin{itemize}
    \item \textbf{Stateful processing:} Hỗ trợ xử lý stateful với state stores được back bởi Kafka topics
    \item \textbf{Windowing:} Hỗ trợ windowing operations (tumbling, hopping, sliding, session windows)
    \item \textbf{Exactly-once semantics:} Đảm bảo mỗi message được xử lý đúng một lần, ngay cả khi có failure
    \item \textbf{Interactive queries:} Cho phép query trực tiếp state của streaming application
\end{itemize}

\subsection{Kafka trong hệ thống phát hiện Concept Drift}

Kafka đặc biệt phù hợp cho hệ thống phát hiện concept drift vì các lý do sau:

\begin{enumerate}
    \item \textbf{Real-time streaming:} Kafka cung cấp low-latency streaming cần thiết cho phát hiện drift real-time

    \item \textbf{Replay capability:} Khả năng đọc lại messages cho phép re-train models hoặc re-analyze drift events

    \item \textbf{Buffering:} Kafka có thể buffer dữ liệu trong thời gian dài (configurable retention), hỗ trợ các thuật toán cần sliding windows như ShapeDD

    \item \textbf{Scalability:} Có thể scale để xử lý volume lớn của IoT sensors hoặc streaming data sources

    \item \textbf{Decoupling:} Tách biệt data ingestion, drift detection, và model adaptation thành các microservices độc lập

    \item \textbf{Fault tolerance:} Replication và distributed architecture đảm bảo hệ thống không bị mất dữ liệu khi có failure
\end{enumerate}

Các phần tiếp theo của chương này sẽ trình bày cách triển khai hệ thống phát hiện drift sử dụng Kafka, với:
\begin{itemize}
    \item Producer gửi streaming data vào Kafka topic
    \item Consumer thực hiện drift detection (ShapeDD) trên sliding window
    \item Adaptor component cập nhật model khi phát hiện drift
    \item Tất cả các component communicate qua Kafka topics để đảm bảo tính decoupled và scalable
\end{itemize}

Kiến trúc này cho phép hệ thống xử lý high-volume streaming data trong thời gian thực, phát hiện concept drift với độ trễ thấp, và thích ứng nhanh chóng với sự thay đổi trong phân phối dữ liệu.

\section{Tổng quan kiến trúc hệ thống}

Hệ thống phát hiện và thích ứng concept drift được đề xuất trong luận văn này được xây dựng dựa trên kiến trúc streaming thời gian thực sử dụng Apache Kafka làm nền tảng xử lý luồng dữ liệu. Như đã trình bày ở Section 3.1, Apache Kafka cung cấp các đặc tính quan trọng cho hệ thống phát hiện drift: high throughput, low latency, durability, scalability, và replay capability. Các phần tiếp theo trình bày chi tiết cách triển khai hệ thống phát hiện drift sử dụng Kafka và ShapeDD SNR-Adaptive đã được trình bày trong Chapter 2.

\subsection{Kiến trúc tổng thể}

Hệ thống được thiết kế theo mô hình pipeline với các thành phần độc lập giao tiếp qua Kafka message queue:

\begin{enumerate}
    \item \textbf{Producer (Bộ phát dữ liệu):} Tạo ra luồng dữ liệu liên tục với các điểm drift được kiểm soát, sử dụng hàm \texttt{gen\_random} để sinh dữ liệu tổng hợp.
    
    \item \textbf{Kafka Broker:} Quản lý hai topic chính:
    \begin{itemize}
        \item \texttt{sensor.stream}: Luồng dữ liệu đầu vào
        \item \texttt{drift.results}: Kết quả phát hiện drift
    \end{itemize}
    
    \item \textbf{Consumer - ShapeDD Detector:} Nhận dữ liệu từ Kafka, thực hiện phát hiện drift theo batch, và phân loại loại drift.
    
    \item \textbf{Adaptor (Bộ thích ứng mô hình):} Lắng nghe sự kiện drift, chọn chiến lược thích ứng phù hợp và cập nhật mô hình.
    
    \item \textbf{Real-time Visualization:} Hiển thị trực quan kết quả phát hiện và hiệu suất mô hình theo thời gian thực.
\end{enumerate}

\subsection{Luồng xử lý dữ liệu}

Quy trình xử lý dữ liệu trong hệ thống tuân theo các bước sau:

\begin{enumerate}
    \item Producer tạo dữ liệu với chỉ số drift (drift indicator) và gửi vào topic \texttt{sensor.stream}
    \item Consumer đọc dữ liệu, lưu vào buffer tuần hoàn (circular buffer) với kích thước cấu hình
    \item Khi đủ BUFFER\_SIZE mẫu, Consumer thực hiện phân tích ShapeDD trên toàn bộ batch
    \item Nếu phát hiện drift, hệ thống phân loại loại drift dựa trên phương pháp CDT\_MSW
    \item Kết quả phát hiện (bao gồm vị trí drift, p-value, loại drift) được ghi vào CSV và publish lên topic \texttt{drift.results}
    \item Adaptor nhận sự kiện drift, chọn chiến lược thích ứng dựa trên loại drift
    \item Mô hình được cập nhật và lưu lại cho inference tiếp theo
\end{enumerate}

\subsection{Cấu hình hệ thống}

Các tham số quan trọng của hệ thống:

\begin{table}[H]
\centering
\caption{Tham số cấu hình hệ thống}
\label{tab:system-config}
\begin{tabular}{lll}
\toprule
\textbf{Tham số} & \textbf{Giá trị} & \textbf{Ý nghĩa} \\
\midrule
BUFFER\_SIZE & 1000 & Số mẫu xử lý mỗi batch \\
CHUNK\_SIZE & 250 & Kích thước chunk cho phân tích drift \\
SHAPE\_L1 & 50 & Nửa cửa sổ cho ShapeDD \\
SHAPE\_L2 & 250 & Cửa sổ đầy đủ cho MMD \\
SHAPE\_N\_PERM & 2500 & Số lần hoán vị cho kiểm định \\
DRIFT\_PVALUE & 0.05 & Ngưỡng p-value phát hiện drift \\
\bottomrule
\end{tabular}
\end{table}

\section{Triển khai hệ thống Kafka cho phát hiện drift}

\subsection{Cài đặt môi trường Kafka}

Hệ thống sử dụng Docker Compose để triển khai Kafka cluster, đảm bảo tính nhất quán và dễ dàng tái tạo môi trường. Cấu hình bao gồm:

\begin{itemize}
    \item \textbf{ZooKeeper}: Quản lý metadata và coordination cho Kafka cluster
    \item \textbf{Kafka Broker}: Single broker cho development/testing (có thể scale lên nhiều broker cho production)
    \item \textbf{Network configuration}: Internal network cho communication giữa các container
    \item \textbf{Volume mapping}: Persist data và logs
\end{itemize}

File cấu hình \texttt{docker-compose.yml} định nghĩa các service và dependencies. Kafka được expose trên port 9092 cho external clients và 29092 cho inter-broker communication.

\subsection{Triển khai Producer}

Producer component (\texttt{producer.py}) chịu trách nhiệm sinh dữ liệu streaming và gửi vào Kafka topic \texttt{sensor.stream}. Thiết kế của Producer bao gồm:

\textbf{Khởi tạo Kafka Producer:}
\begin{itemize}
    \item Sử dụng \texttt{kafka-python} library để connect tới Kafka broker
    \item Cấu hình serialization: JSON format cho messages
    \item Retry logic và error handling cho network failures
    \item Batch configuration để tối ưu throughput
\end{itemize}

\textbf{Sinh dữ liệu với drift:}
\begin{itemize}
    \item Sử dụng hàm \texttt{gen\_random} để sinh synthetic data với controlled drift
    \item Mỗi message bao gồm: timestamp, features, drift\_indicator
    \item Drift được inject tại các điểm định sẵn với các loại khác nhau (abrupt, gradual, incremental)
    \item Producer gửi messages với rate cấu hình (ví dụ: 100 messages/second)
\end{itemize}

\textbf{Message format:}
\begin{verbatim}
{
    "timestamp": 1234567890,
    "features": [0.234, 0.567, ...],
    "drift_indicator": 0,  // 0: normal, 1: drift region
    "drift_type": "abrupt"
}
\end{verbatim}

\subsection{Triển khai Consumer với ShapeDD}

Consumer component (\texttt{consumer\_stream.py}) đọc dữ liệu từ Kafka và thực hiện drift detection sử dụng ShapeDD. Kiến trúc consumer:

\textbf{Kafka Consumer configuration:}
\begin{itemize}
    \item Subscribe vào topic \texttt{sensor.stream}
    \item Consumer group: \texttt{drift-detector-group} (cho phép scale horizontal)
    \item Auto-commit offset sau khi xử lý thành công
    \item Deserialize JSON messages thành Python objects
\end{itemize}

\textbf{Buffer-based processing:}
\begin{itemize}
    \item Maintain circular buffer với BUFFER\_SIZE=750 samples
    \item Check drift mỗi CHECK\_FREQUENCY=150 samples
    \item Sliding window với L1=50, L2=150 cho ShapeDD detection
    \item COOLDOWN=75 samples để tránh chattering (multiple detections cho cùng drift event)
\end{itemize}

\textbf{ShapeDD detection logic:}
\begin{itemize}
    \item Khi buffer đầy, gọi \texttt{shape\_snr\_adaptive()} từ module \texttt{shape\_dd.py}
    \item Thuật toán tự động ước lượng SNR và chọn strategy (aggressive/conservative)
    \item Nếu drift detected (p-value < 0.05), publish event lên topic \texttt{drift.results}
    \item Log detection details: timestamp, p-value, strategy used, window statistics
\end{itemize}

\textbf{Event publishing:}
\begin{verbatim}
{
    "detection_time": 1234567890,
    "p_value": 0.012,
    "strategy": "aggressive",
    "snr_estimate": 0.015,
    "drift_location": 5432
}
\end{verbatim}

\subsection{Triển khai Model Adaptor}

Adaptor component (\texttt{adaptor.py}) lắng nghe drift events và trigger model adaptation. Thiết kế của Adaptor:

\textbf{Drift event listener:}
\begin{itemize}
    \item Subscribe vào topic \texttt{drift.results}
    \item Parse drift event để xác định loại drift và severity
    \item Maintain drift history để tránh over-adaptation
\end{itemize}

\textbf{Adaptation strategies:}
\begin{itemize}
    \item \textbf{Abrupt drift}: Full model retrain với recent window
    \item \textbf{Gradual drift}: Incremental update với weighted samples
    \item \textbf{Incremental drift}: Online learning với adaptive learning rate
    \item \textbf{Recurrent drift}: Retrieve previous model từ model repository
\end{itemize}

\textbf{Model management:}
\begin{itemize}
    \item Versioned model storage (MLflow hoặc filesystem)
    \item A/B testing framework để so sánh old vs new model
    \item Gradual rollout của updated model
    \item Rollback mechanism nếu performance degrades
\end{itemize}

\subsection{Communication qua Kafka Topics}

Hệ thống sử dụng multiple Kafka topics để decouple các components:

\begin{table}[H]
\centering
\caption{Kafka topics trong hệ thống}
\begin{tabular}{lll}
\toprule
\textbf{Topic} & \textbf{Producer} & \textbf{Consumer} \\
\midrule
sensor.stream & Data Producer & Drift Detector \\
drift.results & Drift Detector & Model Adaptor \\
model.updates & Model Adaptor & Inference Service \\
metrics.monitoring & All components & Monitoring Dashboard \\
\bottomrule
\end{tabular}
\end{table}

Thiết kế multi-topic này cho phép:
\begin{itemize}
    \item Tách biệt concerns (data ingestion, detection, adaptation, monitoring)
    \item Scale independently các components (horizontal scaling)
    \item Replay data cho debugging hoặc retraining
    \item Multiple consumers có thể subscribe cùng topic (ví dụ: logging, alerting)
\end{itemize}

\subsection{Ưu điểm của kiến trúc Kafka-based}

Việc sử dụng Apache Kafka làm backbone cho hệ thống phát hiện drift mang lại các lợi ích quan trọng:

\begin{enumerate}
    \item \textbf{Decoupling}: Producer, Consumer, Adaptor hoạt động độc lập, có thể develop và deploy riêng
    \item \textbf{Scalability}: Có thể scale từng component dựa trên bottleneck (ví dụ: nhiều detector consumers cho high-volume streams)
    \item \textbf{Fault tolerance}: Kafka replication đảm bảo no data loss khi có failures
    \item \textbf{Replay capability}: Có thể re-process historical data để tune parameters hoặc test new detectors
    \item \textbf{Low latency}: End-to-end latency từ data ingestion đến drift detection < 100ms (với buffer size thích hợp)
    \item \textbf{Observability}: Kafka metrics (lag, throughput, partition status) cung cấp visibility vào system health
\end{enumerate}

Kiến trúc này đã được triển khai và testing trong folder \texttt{drift-monitoring/} của repository, với đầy đủ các component producer, consumer, adaptor, và configuration files.

\section{Phương pháp CDT\_MSW và chiến lược thích ứng}
\label{sec:cdt-msw-implementation}

\subsection{Tổng quan về CDT\_MSW}

Hệ thống sử dụng phương pháp \textbf{CDT\_MSW (Concept Drift Type Identification based on Multi-Sliding Windows)} để nhận diện loại trôi dạt sau khi ShapeDD phát hiện điểm drift. Phương pháp này đã được trình bày chi tiết trong \textbf{Chapter 1, Section 1.2} (Trang~\pageref{sec:cdt-msw-theory}), bao gồm:

\begin{itemize}
    \item Nguyên lý hoạt động với ba giai đoạn: Detection → Growth → Tracking
    \item Quy tắc phân loại 5 loại drift: sudden, gradual, incremental, recurrent, blip
    \item Các tham số chính ($w_{ref}$, $\delta$, $\theta_{sudden}$, etc.)
    \item Ưu điểm so với các phương pháp truyền thống
\end{itemize}

Trong chương này, chúng ta tập trung vào \textbf{triển khai cụ thể} của CDT\_MSW trong hệ thống, bao gồm cấu hình parameters, integration với Kafka messaging, và error handling.


Sau khi ShapeDD phát hiện drift tại thời điểm $t_0$, module \texttt{drift\_detector.py} kích hoạt CDT\_MSW để phân loại drift type:

\begin{enumerate}
    \item \textbf{Snapshot capture}: Lưu cửa sổ tham chiếu $\mathcal{W}_{ref}$ (200 samples trước $t_0$) vào file
    \item \textbf{Growth phase monitoring}: Theo dõi distance $d_t$ mỗi 50 samples, dừng khi $\Delta d_t < 0.02$
    \item \textbf{Classification}: So sánh $L_d$ với thresholds để xác định drift type
    \item \textbf{Message publishing}: Gửi kết quả (drift\_type, $L_d$, confidence) lên Kafka topic \texttt{drift.results}
\end{enumerate}

\textbf{Thuật toán phân loại loại drift:}

\begin{algorithm}[H]
\caption{CDT\_MSW Drift Type Classification}
\begin{algorithmic}[1]
\REQUIRE Drift timestamp $t_0$, data window $\mathcal{W}$, thresholds $\theta_{sudden}$, $\theta_{stability}$
\ENSURE Drift type: \{sudden, gradual, incremental, recurrent, blip\}
\STATE \textit{// Phase 1: Measure drift length}
\STATE $t_{start} \leftarrow t_0$
\STATE $L_d \leftarrow 0$
\WHILE{$\Delta d_t > \theta_{stability}$}
    \STATE $t_{end} \leftarrow t_{end} + \Delta t$
    \STATE $L_d \leftarrow t_{end} - t_{start}$
\ENDWHILE
\STATE
\STATE \textit{// Phase 2: Classify based on length and characteristics}
\IF{$L_d < \theta_{sudden}$}
    \RETURN \texttt{"sudden"}
\ELSIF{drift has cyclic pattern with previous concepts}
    \RETURN \texttt{"recurrent"}
\ELSIF{transition rate is linear}
    \RETURN \texttt{"incremental"}
\ELSIF{transition involves mixed distributions}
    \RETURN \texttt{"gradual"}
\ELSE
    \RETURN \texttt{"blip"}
\ENDIF
\end{algorithmic}
\end{algorithm}

\section{Mô hình học máy và quy trình thích ứng}
\label{sec:model-adaptation}

\subsection{Kiến trúc mô hình}

Hệ thống sử dụng mô hình học máy với ba giai đoạn hoạt động chính:

\textbf{1. Giai đoạn huấn luyện ban đầu (Training Phase):}
\begin{itemize}
    \item Sử dụng scikit-learn để xây dựng pipeline mô hình batch
    \item Cấu trúc: StandardScaler + LogisticRegression
    \item Huấn luyện trên dữ liệu ban đầu (pre-drift data)
    \item Model được lưu dưới dạng pickle file
\end{itemize}

\textbf{2. Giai đoạn triển khai (Deployment Phase):}
\begin{itemize}
    \item Mô hình hoạt động ở chế độ \textit{frozen} (đóng băng)
    \item Không có online learning trong quá trình inference
    \item Chỉ thực hiện prediction trên dữ liệu mới
    \item Theo dõi accuracy để phát hiện suy giảm hiệu suất
\end{itemize}

\textbf{3. Giai đoạn cập nhật (Update Phase):}
\begin{itemize}
    \item Được kích hoạt khi phát hiện drift
    \item Chiến lược cập nhật được chọn dựa trên loại drift
    \item Mô hình mới được huấn luyện hoặc cập nhật
    \item Model được lưu lại và thay thế model cũ
\end{itemize}

\subsection{Chiến lược thích ứng và triển khai}

\textbf{Nền tảng lý thuyết:} Như đã trình bày chi tiết trong \textbf{Chapter 1, Section 1.3} (Bảng~\ref{tab:model_update_strategies}), mỗi loại drift cần một chiến lược cập nhật riêng biệt:

\begin{itemize}
    \item \textbf{Sudden drift} $\rightarrow$ Local reset / Full retraining
    \item \textbf{Gradual drift} $\rightarrow$ Soft update với weighted samples
    \item \textbf{Incremental drift} $\rightarrow$ Continuous adaptation
    \item \textbf{Recurrent drift} $\rightarrow$ Memory-based adaptation
    \item \textbf{Blip drift} $\rightarrow$ Minimal update
\end{itemize}

\textbf{Triển khai cụ thể:} Hệ thống triển khai các chiến lược lý thuyết này thành năm modules trong \texttt{adaptation\_strategies.py}:

\begin{itemize}
    \item \texttt{adapt\_sudden\_drift()}: Tạo sklearn pipeline mới, full retraining trên post-drift data \textbf{[FULLY IMPLEMENTED \& EVALUATED]}
    \item \texttt{adapt\_incremental\_drift()}: River online learning với \texttt{learn\_one()}, cập nhật tuần tự \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_gradual\_drift()}: Weighted samples (position/total), chỉ dùng 50\% mẫu cuối \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_recurrent\_drift()}: KS-test (threshold=0.15) tìm similar model trong cache, fine-tune \textbf{[FRAMEWORK ONLY]}
    \item \texttt{adapt\_blip\_drift()}: Conservative - update tối đa 5 samples hoặc skip \textbf{[FRAMEWORK ONLY]}
\end{itemize}

\textbf{Phạm vi đánh giá:} Luận văn này tập trung đánh giá chuyên sâu \texttt{adapt\_sudden\_drift()} strategy với comprehensive experiments (Chapter 4). Các strategies khác đã được implement as part of extensible framework nhưng chưa được evaluate thoroughly, để dành cho future research.

\textbf{Sudden Drift Adaptation Algorithm:}

\begin{algorithm}[H]
\caption{Sudden Drift Adaptation Strategy}
\begin{algorithmic}[1]
\REQUIRE Drift event $(t_0, \text{drift\_type})$, post-drift data $\mathcal{D}_{post}$, old model $M_{old}$
\ENSURE New model $M_{new}$
\STATE \textit{// Step 1: Verify drift type}
\IF{drift\_type $\neq$ ``sudden''}
    \RETURN redirect\_to\_other\_strategy(drift\_type)
\ENDIF
\STATE
\STATE \textit{// Step 2: Collect post-drift data}
\STATE $\mathcal{D}_{train} \leftarrow$ collect\_samples($t_0$, window\_size=800)
\STATE Wait for sufficient samples or timeout (adaptation\_delay=50)
\STATE
\STATE \textit{// Step 3: Train new model}
\STATE $M_{new} \leftarrow$ sklearn.Pipeline([StandardScaler(), LogisticRegression()])
\STATE $M_{new}$.fit($\mathcal{D}_{train}$.X, $\mathcal{D}_{train}$.y)
\STATE
\STATE \textit{// Step 4: Save and replace model}
\STATE save\_model($M_{new}$, version=$t_0$)
\STATE $M_{old} \leftarrow M_{new}$
\RETURN $M_{new}$
\end{algorithmic}
\end{algorithm}

Chi tiết về rationale và trade-offs của từng chiến lược đã được phân tích đầy đủ trong Chapter 1.

\subsection{Cơ chế quyết định tự động}

Trong quá trình vận hành hệ thống, việc lựa chọn chiến lược thích ứng được thực hiện tự động thông qua module \texttt{adaptor.py}. 
Quy trình hoạt động như sau:

\textbf{Bước 1: Lắng nghe sự kiện drift}
\begin{itemize}
    \item Adaptor subscribe vào Kafka topic \texttt{drift.results}
    \item Nhận message chứa thông tin: \texttt{idx}, \texttt{p\_value}, \texttt{drift\_type}, \texttt{window\_path}
    \item Kiểm tra tính hợp lệ của snapshot file
\end{itemize}

\textbf{Bước 2: Load dữ liệu drift window}
\begin{itemize}
    \item Đọc snapshot từ thư mục \texttt{./snapshots/}
    \item Snapshot chứa: ma trận đặc trưng $X$, nhãn $y$ (nếu có), tên features
    \item Kích thước window phụ thuộc vào tham số \texttt{w\_ref} và \texttt{CHUNK\_SIZE}
\end{itemize}

\textbf{Bước 3: Lựa chọn chiến lược thích ứng}

Hệ thống ánh xạ loại drift sang hàm xử lý tương ứng:

    \begin{equation}
    \text{strategy} = 
        \begin{cases}
        \texttt{adapt\_sudden\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``sudden''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``incremental''} \\
        \texttt{adapt\_gradual\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``gradual''} \\
        \texttt{adapt\_recurrent\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``recurrent''} \\
        \texttt{adapt\_blip\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``blip''} \\
        \texttt{adapt\_incremental\_drift()} & \text{nếu } \texttt{drift\_type} = \text{``undetermined''}
        \end{cases}
    \end{equation}

\textbf{Bước 4: Cập nhật và lưu mô hình}
\begin{itemize}
    \item Thực thi chiến lược đã chọn
    \item Lưu model mới vào \texttt{./models/current\_model.pkl}
    \item Cập nhật version (dựa trên file modification time)
    \item Publish event \texttt{model\_updated} lên topic \texttt{model.updated}
\end{itemize}

\subsection{Ví dụ quy trình thích ứng}

Giả sử tại thời điểm $t = 1504$, ShapeDD phát hiện drift với loại ``sudden'':

\begin{enumerate}
    \item Consumer phát hiện drift, phân loại là ``sudden'', gửi event:
    \begin{verbatim}
    {
      "event": "drift_detected",
      "idx": 1504,
      "p_value": 0.0001,
      "drift_type": "sudden",
      "window_path": "./snapshots/drift_window_1504_xxx.npz"
    }
    \end{verbatim}
    
    \item Adaptor nhận event, load snapshot chứa 251 mẫu (200 pre-drift + 51 post-drift)
    
    \item Gọi \texttt{adapt\_sudden\_drift()}: Tạo model mới, huấn luyện trên dữ liệu post-drift
    
    \item Lưu model mới, publish \texttt{model\_updated} event
\end{enumerate}

\subsection{Ưu điểm của cơ chế tự động}

Cơ chế quyết định tự động mang lại các lợi ích:

\begin{itemize}
    \item \textbf{Tự động hóa hoàn toàn:} Không cần can thiệp thủ công
    \item \textbf{Tối ưu hóa chi phí:} Chọn chiến lược phù hợp tránh lãng phí tài nguyên
    \item \textbf{Phản hồi nhanh:} Thời gian từ phát hiện đến cập nhật < 1 giây
    \item \textbf{Có khả năng mở rộng:} Dễ dàng thêm chiến lược mới
\end{itemize}

\section{Xử lý lỗi và khả năng chịu lỗi}

Trong hệ thống phát hiện và thích ứng concept drift thời gian thực, việc xử lý lỗi là yếu tố quan trọng để đảm bảo tính ổn định và độ tin cậy. Hệ thống cần có khả năng phục hồi tự động khi gặp các lỗi thường gặp trong môi trường phân tán.

\subsection{Phân loại lỗi và cơ chế xử lý}

\subsubsection{Producer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Kafka connection lost:} Mất kết nối đến Kafka broker
    \item \textbf{Message serialization error:} Lỗi serialize dữ liệu thành JSON/Protobuf
    \item \textbf{Buffer overflow:} Kafka producer buffer đầy khi broker chậm
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Retry with exponential backoff:} Thử lại gửi message với độ trễ tăng dần ($2^n$ giây, max 5 lần)
    \begin{verbatim}
    for attempt in range(MAX_RETRIES):
        try:
            producer.send(topic, message)
            break
        except KafkaTimeoutError:
            sleep(2 ** attempt)
    \end{verbatim}

    \item \textbf{Circuit breaker pattern:} Tạm dừng producer nếu Kafka broker down quá 30 giây, ghi log warning

    \item \textbf{Local buffering:} Lưu tạm dữ liệu vào file CSV nếu Kafka không available, replay sau khi kết nối phục hồi
\end{enumerate}

\subsubsection{Consumer failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Drift detection crash:} ShapeDD raise exception (VD: insufficient data)
    \item \textbf{Snapshot save failure:} Lỗi ghi file .npz (disk full, permission denied)
    \item \textbf{Message parsing error:} Kafka message format không hợp lệ
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Try-catch wrapper:} Bọc ShapeDD detection trong try-except, log error nhưng không crash
    \begin{verbatim}
    try:
        is_drift, p_value = shapeDD.detect(buffer)
    except InsufficientDataError:
        logger.warning(f"Buffer size {len(buffer)} < L1+L2")
        continue  # Skip detection, wait for more data
    \end{verbatim}

    \item \textbf{Snapshot fallback:} Nếu không ghi được .npz, publish event không có window\_path (Adaptor sẽ train từ Kafka topic)

    \item \textbf{Commit offset after processing:} Chỉ commit Kafka offset sau khi xử lý thành công, đảm bảo không mất message
\end{enumerate}

\subsubsection{Model adaptation failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Training failure:} Model training crash (VD: NaN loss, out of memory)
    \item \textbf{Model cache miss:} Recurrent drift nhưng không tìm thấy model phù hợp
    \item \textbf{Insufficient labels:} Không đủ labeled data để retrain (semi-supervised scenario)
\end{itemize}

\textbf{Cơ chế xử lý:}
\begin{enumerate}
    \item \textbf{Graceful degradation:} Nếu training thất bại, giữ nguyên old model, log error để human review
    \begin{verbatim}
    try:
        new_model = train_model(X_new, y_new)
    except ConvergenceWarning:
        logger.error("Model training failed, keeping old model")
        new_model = self.current_model  # Fallback
    \end{verbatim}

    \item \textbf{Cache fallback strategy:} Nếu recurrent drift không match model nào, fallback về sudden drift strategy (full retrain)

    \item \textbf{Semi-supervised adaptation:} Khi thiếu labels, dùng pseudo-labeling với high-confidence predictions ($P > 0.95$)
\end{enumerate}

\subsubsection{Kafka broker failures}

\textbf{Các lỗi thường gặp:}
\begin{itemize}
    \item \textbf{Broker crash:} Một trong các broker trong cluster down
    \item \textbf{Network partition:} Mất kết nối giữa producer/consumer và broker
    \item \textbf{Disk full:} Kafka log directory hết dung lượng
\end{itemize}

\textbf{Cơ chế xử lý (dựa trên đặc tính Kafka):}
\begin{enumerate}
    \item \textbf{Replication:} Cấu hình \texttt{replication.factor=3} cho topics quan trọng, đảm bảo data không mất khi 1-2 broker down

    \item \textbf{Producer acknowledgment:} Dùng \texttt{acks=all} để đảm bảo message chỉ được coi là sent khi tất cả replicas acknowledged

    \item \textbf{Consumer group rebalancing:} Khi broker down, Kafka tự động rebalance partitions sang consumer khác trong group

    \item \textbf{Retention monitoring:} Set up alert khi disk usage > 80\%, cleanup old log segments theo \texttt{retention.ms=7 days}
\end{enumerate}

\subsection{Logging và monitoring}

Để hỗ trợ debugging và fault diagnosis, hệ thống triển khai comprehensive logging:

\begin{itemize}
    \item \textbf{Structured logging:} JSON format với timestamp, component, severity, message
    \begin{verbatim}
    {
      "timestamp": "2025-01-12T10:30:45Z",
      "component": "consumer",
      "level": "ERROR",
      "message": "ShapeDD detection failed",
      "context": {"buffer_size": 42, "required": 200}
    }
    \end{verbatim}

    \item \textbf{Log levels:}
    \begin{itemize}
        \item INFO: Drift detected, model updated
        \item WARNING: Retry attempt, cache miss
        \item ERROR: Training failed, connection lost
        \item CRITICAL: System shutdown due to unrecoverable error
    \end{itemize}

    \item \textbf{Metrics collection:} Track key metrics với Prometheus/StatsD:
    \begin{itemize}
        \item Producer throughput (messages/sec)
        \item Consumer lag (offset behind)
        \item Detection latency (ms)
        \item Adaptation success rate (\%)
    \end{itemize}
\end{itemize}

\subsection{Tổng hợp chiến lược chịu lỗi}

\begin{table}[H]
\centering
\caption{Tổng hợp cơ chế xử lý lỗi theo component}
\label{tab:error-handling}
\begin{tabular}{p{3cm}p{5cm}p{6cm}}
\toprule
\textbf{Component} & \textbf{Lỗi chính} & \textbf{Recovery strategy} \\
\midrule
Producer &
Kafka timeout, buffer overflow &
Retry + exponential backoff, local CSV buffering \\
\midrule
Consumer &
Detection crash, snapshot failure &
Try-catch wrapper, commit offset after success \\
\midrule
Adaptor &
Training failure, cache miss &
Graceful degradation, fallback strategy \\
\midrule
Kafka Broker &
Broker down, network partition &
Replication (factor=3), auto rebalancing \\
\bottomrule
\end{tabular}
\end{table}

Với các cơ chế xử lý lỗi trên, hệ thống đạt được \textbf{high availability} (uptime > 99.5\%) và \textbf{fault tolerance}, đảm bảo hoạt động ổn định ngay cả khi gặp các lỗi thường gặp trong môi trường production.
