\chapter{Mô hình đề xuất}
\label{chap:proposed-model}

\textit{Tóm tắt: Trên cơ sở lý thuyết về ShapeDD và các phương pháp phát hiện concept drift đã trình bày ở Chương~\ref{chap:theoretical-foundation}, chương này trình bày việc tích hợp \textbf{Weighted MMD với phân phối tiệm cận} vào framework ShapeDD nhằm cải thiện hiệu suất tính toán, đồng thời đề xuất phương pháp mới SE-CDT cho phân loại drift không giám sát. Báo cáo cũng trình bày kiến trúc hệ thống xử lý luồng dữ liệu thời gian thực dựa trên Apache Kafka. Các đóng góp chính bao gồm: (1) Tích hợp Inverse Density-Weighted MMD (IDW-MMD) với asymptotic p-value để tăng tốc độ xử lý, (2) Xây dựng khung chiến lược thích ứng đa dạng dựa trên loại drift, và (3) Thiết kế kiến trúc hệ thống có khả năng mở rộng và chịu lỗi cao.}

\section{Động lực và tổng quan cách tiếp cận}

Mặc dù ShapeDD gốc thể hiện nhiều ưu điểm về độ chính xác định vị và khả năng khử nhiễu, việc áp dụng phương pháp này trong các hệ thống thời gian thực (real-time) quy mô lớn gặp phải hai thách thức chính:

\begin{enumerate}
	\item \textbf{Chi phí tính toán cao:} Việc sử dụng kiểm định hoán vị (permutation test) với số lượng lớn (thường là 2500 lần) để ước lượng p-value tạo ra nút thắt cổ chai về hiệu năng, giới hạn thông lượng (throughput) xử lý.
	\item \textbf{Độ nhạy với tham số:} Hiệu suất của ShapeDD phụ thuộc nhiều vào việc lựa chọn độ rộng hạt nhân (kernel bandwidth) và kích thước cửa sổ, làm giảm khả năng tổng quát hóa trên các luồng dữ liệu có đặc tính drift đa dạng.
	\item \textbf{Thiếu cơ chế thích ứng:} Phát hiện drift chỉ là bước đầu; hệ thống cần một cơ chế để tự động cập nhật mô hình một cách phù hợp với bản chất của sự thay đổi (đột ngột hay dần dần).
\end{enumerate}

Để giải quyết các thách thức trên, luận văn xây dựng hệ thống \textbf{ShapeDD-Stream} --- một framework tích hợp kết hợp các phương pháp MMD tiên tiến với kiến trúc streaming, bao gồm ba tầng xử lý chính:
\begin{itemize}
	\item \textbf{Tầng thuật toán:} Cải tiến ShapeDD bằng cách tích hợp \textit{Inverse Density-Weighted MMD (IDW-MMD)} với phân phối tiệm cận để giảm phương sai và chi phí tính toán, loại bỏ nhu cầu permutation test tốn kém.
	\item \textbf{Tầng chiến lược:} Xây dựng khung thích ứng thông minh, sử dụng kết quả phân loại từ \textit{CDT\_MSW} để kích hoạt chiến lược cập nhật mô hình tối ưu (Reset, Incremental, hoặc Reuse).
	\item \textbf{Tầng kiến trúc:} Triển khai hệ thống trên nền tảng \textit{Apache Kafka}, đảm bảo khả năng xử lý luồng dữ liệu phân tán, độ trễ thấp và khả năng chịu lỗi.
\end{itemize}

\section{Cải tiến thuật toán phát hiện concept drift}

\subsection{Inverse Density-Weighted MMD (IDW-MMD): Tối ưu hóa hiệu suất và độ chính xác}
\label{sec:adw-mmd}

Trong các hệ thống học máy dòng dữ liệu (data stream), concept drift xảy ra khi các đặc tính thống kê của biến mục tiêu thay đổi đột ngột hoặc từ từ theo thời gian. Các phương pháp MMD truyền thống thường gặp khó khăn về chi phí tính toán khi áp dụng cho dữ liệu lớn.

\subsubsection{Vấn đề của ước lượng MMD truyền thống}
Trong ShapeDD gốc, thống kê MMD được tính toán dựa trên trọng số đều (uniform weights), coi vai trò của mọi điểm dữ liệu trong cửa sổ là như nhau. Để đạt được độ mạnh thống kê (statistical power --- khả năng phát hiện sự khác biệt khi có) mong muốn, phương pháp này yêu cầu kích thước mẫu lớn hoặc quy trình kiểm định hoán vị tốn kém ($O(N_{perm} \cdot n^2)$). Điều này không phù hợp với các ứng dụng yêu cầu phản hồi tức thì.

\subsubsection{Giải pháp: Trọng số nghịch biến mật độ (Inverse Density Weighting)}
Luận văn đề xuất sử dụng phương pháp \textbf{IDW-MMD} (Inverse Density-Weighted MMD), một heuristic đơn giản lấy cảm hứng từ ý tưởng ``Optimally-Weighted MMD'' của Bharti et al.~\cite{bharti2023owmmd}.

\textbf{Lưu ý quan trọng:} Phương pháp của Bharti et al. (2023) được thiết kế cho \textit{likelihood-free inference} và đề xuất trọng số tối ưu phức tạp. Implementation trong luận văn này sử dụng một \textbf{heuristic đơn giản hơn} --- trọng số nghịch biến với căn bậc hai của mật độ kernel --- để phù hợp với bài toán drift detection trong streaming.

Cụ thể, các trọng số vector $w \in \mathbb{R}^n$ được tính tỷ lệ nghịch với căn bậc hai của tổng kernel (proxy cho mật độ cục bộ):
\begin{equation}
	w_i \propto \frac{1}{\sqrt{\sum_{j} k(x_i, x_j)}} \quad \text{(Inverse Density Weighting)}
\end{equation}

\textbf{Trực giác:} Điểm dữ liệu ở vùng thưa thớt (biên phân phối) có $\sum_{j} k(x_i, x_j)$ nhỏ $\Rightarrow$ trọng số $w_i$ lớn. Điểm ở vùng dày đặc (trung tâm phân phối) có $\sum_{j} k(x_i, x_j)$ lớn $\Rightarrow$ trọng số $w_i$ nhỏ. Cơ chế này giúp phát hiện nhạy hơn các thay đổi ở biên phân phối, nơi drift thường xuất hiện đầu tiên.

Công thức MMD bình phương có trọng số được định nghĩa cụ thể:
\begin{equation}
	\text{MMD}^2_{\text{IDW}} = \underbrace{\sum_{i,j} w_i w_j k(x_i, x_j)}_{\text{Weighted } XX} + \underbrace{\sum_{p,q} v_p v_q k(y_p, y_q)}_{\text{Weighted } YY} - 2\underbrace{\sum_{i,p} \frac{1}{nm} k(x_i, y_p)}_{\text{Uniform } XY}
\end{equation}

\subsubsection{Quy trình tính toán}
Luận văn cài đặt IDW-MMD như sau:

\begin{algorithm}[H]
	\caption{Inverse Density-Weighted MMD (IDW-MMD)}
	\label{alg:adw_mmd}
	\begin{algorithmic}[1]
		\REQUIRE Reference window $X_{ref}$, test window $X_{test}$, kernel $k(\cdot, \cdot)$
		\ENSURE IDW-MMD Statistic $\widehat{\text{MMD}}^2_{\text{IDW}}$
		\STATE Combine samples: $Z = X_{ref} \cup X_{test}$
		\STATE Compute Kernel Matrix $K$ on $Z$
		\STATE \textbf{1. Compute Inverse Density Weights}
		\FOR{each sample $z_i \in Z$}
		\STATE Calculate local density: $d_i = \sum_{j} K_{ij}$
		\STATE Assign inverse-sqrt weight: $w_i \propto \frac{1}{\sqrt{d_i} + \epsilon}$ \COMMENT{$\epsilon=0.5$ for stability}
		\ENDFOR
		\STATE Normalize weights: $\sum_{i \in X_{ref}} w_i = 1$, $\sum_{j \in X_{test}} w_j = 1$
		\STATE \textbf{2. Compute Weighted Statistic}
		\STATE $\widehat{\text{MMD}}^2_{\text{IDW}} = \sum_{i,j} w_i w_j k(x_i, x_j) + \sum_{p,q} w_p w_q k(y_p, y_q) - \frac{2}{mn} \sum_{i,p} k(x_i, y_p)$
		\COMMENT{Cross-term sử dụng uniform weights $(1/mn)$ để ổn định ước lượng}
		\RETURN $\widehat{\text{MMD}}^2_{\text{IDW}}$
	\end{algorithmic}
\end{algorithm}

\subsubsection{Phân tích độ phức tạp tính toán}

Độ phức tạp của IDW-MMD được phân tích như sau:

\begin{table}[H]
	\centering
	\caption{Độ phức tạp tính toán của IDW-MMD và các phương pháp liên quan}
	\label{tab:complexity}
	\begin{tabular}{|l|c|c|l|}
		\hline
		\textbf{Thành phần}     & \textbf{Thời gian}   & \textbf{Bộ nhớ} & \textbf{Ghi chú}    \\
		\hline
		Kernel Matrix           & $O(n^2)$             & $O(n^2)$        & $n$ = window size   \\
		Density weights         & $O(n)$               & $O(n)$          & Sum over rows       \\
		Weighted MMD            & $O(n^2)$             & $O(1)$          & Scalar output       \\
		Asymptotic p-value      & $O(n^2)$             & $O(n^2)$        & Eigenvalue decomposition \\
		\hline
		\textbf{IDW-MMD + Asymptotic} & $O(n^2)$        & $O(n^2)$        & Không cần permutation \\
		\hline
		ShapeDD gốc (2500 perm) & $O(n^2 \times 2500)$ & $O(n^2)$        & Permutation test    \\
		\hline
	\end{tabular}
\end{table}

\textbf{Cải tiến chính:} Thay vì sử dụng permutation test ($O(n^2 \times N_{perm})$), luận văn sử dụng \textit{phân phối tiệm cận} (asymptotic distribution) để tính p-value, chỉ cần $O(n^2)$. Điều này giúp giảm thời gian tính toán từ $\sim$125ms xuống $\sim$7--9ms mỗi window, tăng throughput xử lý \textbf{17--20 lần} (từ 8,000 lên 111,000--131,000 mẫu/giây).


\subsection{MMD-Agg: Tăng cường độ bền vững và tính thích nghi (Lý thuyết tham khảo)}
\label{sec:mmdagg}

\textbf{Ghi chú:} Phần này trình bày lý thuyết của MMD-Agg để tham khảo. Trong quá trình thực nghiệm, MMD-Agg được loại khỏi benchmark vì thời gian tính toán quá cao (~500ms/window) và không mang lại cải thiện đáng kể so với IDW-MMD với median heuristic trong bài toán concept drift detection.

Một hạn chế cốt yếu của các phương pháp MMD truyền thống là sự phụ thuộc nhạy cảm vào việc lựa chọn tham số độ rộng hạt nhân (kernel bandwidth, $\sigma$). Trong thực tế, sự trôi dạt khái niệm có thể diễn ra ở nhiều quy mô khác nhau: sự thay đổi nhỏ cục bộ (yêu cầu $\sigma$ nhỏ) hoặc sự dịch chuyển phân phối toàn cục (yêu cầu $\sigma$ lớn). Việc cố định một giá trị $\sigma$ (thường dùng median heuristic) thường dẫn đến việc mất mát thông tin quan trọng, làm giảm độ mạnh (power) của kiểm định.

Để khắc phục vấn đề này, Schrab et al.~\cite{schrab2023mmdagg} đề xuất phương pháp \textbf{MMD-Agg} (MMD Aggregated). Đây là một bước tiến quan trọng về mặt lý thuyết so với các phương pháp lựa chọn kernel heuristic.

\subsubsection{Cơ chế thích nghi đa hạt nhân (Adaptive Multi-Kernel Strategy)}
Thay vì chọn một kernel đơn lẻ $k_{\sigma}$, MMD-Agg thực hiện kiểm định trên một tập hợp các kernel $\mathcal{K} = \{k_{\sigma_1}, k_{\sigma_2}, \dots, k_{\sigma_M}\}$ với các độ rộng băng thông trải dài trên nhiều quy mô khác nhau.

Thống kê kiểm định không còn là một giá trị MMD duy nhất, mà là giá trị tổng hợp từ tập hợp này:
\begin{equation}
	\Delta_{Agg} = \max_{k \in \mathcal{K}} \left( \widehat{\text{MMD}}_k^2 - \lambda_k \right)
\end{equation}
trong đó $\lambda_k$ là các ngưỡng điều chỉnh (correction thresholds) cho từng kernel, được tính toán từ phân phối null của $\widehat{\text{MMD}}_k^2$ thông qua bootstrap hoặc asymptotic quantile (xem Algorithm~\ref{alg:mmd_agg}, bước 2). Cơ chế này cho phép bộ phát hiện ``quét'' qua nhiều độ phân giải của dữ liệu, tự động ``thích nghi'' để chọn ra kernel phản ánh tốt nhất sự thay đổi phân phối hiện tại mà không cần tham số hóa thủ công.

\subsubsection{Đảm bảo lý thuyết}
Điểm vượt trội của MMD-Agg so với các phương pháp ensemble thông thường nằm ở các đảm bảo lý thuyết vững chắc:
\begin{enumerate}
	\item \textbf{Khả năng phát hiện tối ưu:} Schrab et al. đã chứng minh về mặt lý thuyết rằng MMD-Agg có thể phát hiện sự khác biệt nhỏ nhất có thể phân biệt được, mà không cần biết trước đặc tính của dữ liệu. Điều này giúp phương pháp hoạt động tốt trong nhiều tình huống khác nhau.
	\item \textbf{Kiểm soát báo động giả với mẫu nhỏ:} Khác với nhiều phương pháp chỉ hoạt động tốt khi có nhiều dữ liệu, MMD-Agg đảm bảo kiểm soát chặt chẽ tỷ lệ báo động giả ngay cả với cửa sổ dữ liệu nhỏ. Điều này phù hợp với môi trường streaming, nơi dữ liệu đến liên tục và cửa sổ thường có kích thước hạn chế.
\end{enumerate}

Nhờ tích hợp MMD-Agg, ShapeDD không còn phụ thuộc vào việc chọn tham số kernel thủ công. Bộ phát hiện có thể tự động phát hiện cả các thay đổi nhỏ lẫn các thay đổi lớn trong phân phối dữ liệu.

\begin{algorithm}[H]
	\caption{MMD Aggregated (MMD-Agg)}
	\label{alg:mmd_agg}
	\begin{algorithmic}[1]
		\REQUIRE Windows $X, Y$, collection of bandwidths $\Lambda = \{\sigma_1, \dots, \sigma_M\}$, level $\alpha$
		\ENSURE Test decision (Drift/No Drift)
		\STATE \textbf{1. Kernel Collection}
		\FOR{each $\sigma_m \in \Lambda$}
		\STATE Define kernel $k_m(x, y) = \exp(-\|x-y\|^2 / 2\sigma_m^2)$
		\STATE Compute standard MMD estimator $\widehat{\text{MMD}}^2_m(X, Y)$ using $k_m$
		\ENDFOR
		\STATE \textbf{2. Aggregation}
		\FOR{each $m \in \{1, \dots, M\}$}
		\STATE Compute threshold $u_{\alpha, m}$ (via bootstrap or asymptotic quantile)
		\STATE Compute adjusted statistic: $T_m = \widehat{\text{MMD}}^2_m - u_{\alpha, m}$
		\ENDFOR
		\STATE \textbf{3. Decision}
		\STATE Global statistic $\Delta_{Agg} = \max_{m} T_m$
		\IF{$\Delta_{Agg} > 0$}
		\RETURN \textbf{Drift Detected} (Reject $H_0$)
		\ELSE
		\RETURN \textbf{No Drift} (Fail to reject $H_0$)
		\ENDIF
	\end{algorithmic}
\end{algorithm}

Sau khi tích hợp IDW-MMD với phân phối tiệm cận, hệ thống có thể phát hiện drift với độ chính xác cao và chi phí tính toán thấp. Tuy nhiên, phát hiện drift chỉ là bước đầu tiên --- để chọn chiến lược thích ứng phù hợp, hệ thống cần biết \textit{loại drift} đã xảy ra. Phần tiếp theo trình bày phương pháp SE-CDT cho bài toán phân loại drift không giám sát.

\section{Phương pháp phân loại drift: SE-CDT}
\label{sec:shaped-cdt}

Phương pháp CDT\_MSW gốc~\cite{guo2022cdtmsw} yêu cầu \textit{labels} để tính toán accuracy ratio, điều này không phù hợp trong môi trường streaming không giám sát. Luận văn đề xuất \textbf{SE-CDT} (ShapeDD-Enhanced Concept Drift Type), một phương pháp thay thế sử dụng trực tiếp tín hiệu drift magnitude $\sigma(t)$ từ ShapeDD để phân loại drift type.

\subsection{Cơ sở lý thuyết}
Theo phân loại của CDT\_MSW, drift được chia thành:
\begin{itemize}
	\item \textbf{TCD (Transient Concept Drift):} Drift tạm thời với thời gian chuyển đổi ngắn --- bao gồm \textit{sudden} và \textit{blip}.
	\item \textbf{PCD (Progressive Concept Drift):} Drift tiến triển với thời gian chuyển đổi dài --- bao gồm \textit{gradual}, \textit{incremental}, và \textit{recurrent}.
\end{itemize}

\subsection{Đặc trưng phân loại từ tín hiệu $\sigma(t)$}
\begin{enumerate}
	\item \textbf{Peak Width Ratio:} $\text{WR} = \frac{\text{FWHM}}{2L}$. TCD có $\text{WR} < 0.12$, PCD có $\text{WR} \geq 0.12$.
	\item \textbf{Peak Count:} Số lượng peaks phát hiện được. Sudden có ít peaks ($\leq 4$), Recurrent có nhiều peaks đều đặn ($\geq 5$).
	\item \textbf{Periodicity CV:} Hệ số biến thiên khoảng cách giữa peaks. Recurrent có CV $< 0.2$ (đều đặn).
	\item \textbf{Signal-to-Noise Ratio:} $\text{SNR} = \frac{\max(\sigma)}{\text{median}(\sigma)}$ --- TCD có SNR cao (peaks sắc nét).
\end{enumerate}

\subsection{Thuật toán phân loại}
\begin{algorithm}[H]
	\caption{SE-CDT: Phân loại drift không giám sát}
	\label{alg:se-cdt}
	\begin{algorithmic}[1]
		\REQUIRE Tín hiệu drift magnitude $\sigma(t)$ từ ShapeDD
		\ENSURE Loại drift (TCD/PCD) và subcategory
		\STATE Làm mịn tín hiệu: $\sigma_s \leftarrow \text{GaussianFilter}(\sigma, \sigma=4)$
		\STATE Phát hiện peaks: $P \leftarrow \text{FindPeaks}(\sigma_s, \text{threshold}=\bar{\sigma} + 0.3\sigma_{std})$
		\STATE Tính các đặc trưng: $n_p \leftarrow |P|$, $\text{WR}$, $\text{CV}$, $\text{SNR}$
		\IF{$n_p \leq 4$ AND $\text{WR} < 0.12$}
		\RETURN \textbf{SUDDEN} (TCD)
		\ELSIF{$n_p \geq 4$ AND $\text{CV} < 0.3$}
		\RETURN \textbf{RECURRENT} (PCD)
		\ELSIF{$\text{WR} \geq 0.12$}
		\RETURN \textbf{GRADUAL} (PCD)
		\ELSIF{$n_p \geq 10$ AND $\text{SignalMean} \approx 0$}
		\RETURN \textbf{INCREMENTAL} (PCD)
		\ELSE
		\RETURN \textbf{GRADUAL} (PCD) \COMMENT{Default}
		\ENDIF
	\end{algorithmic}
\end{algorithm}

\subsection{Ưu điểm và độ phức tạp}
\textbf{Ưu điểm của SE-CDT:}
\begin{itemize}
	\item \textbf{Không giám sát:} Không cần labels, phù hợp với streaming data.
	\item \textbf{Tích hợp:} Sử dụng cùng tín hiệu $\sigma(t)$ đã tính cho detection, không cần tính toán thêm.
	\item \textbf{Thời gian thực:} Phân loại ngay sau khi phát hiện drift.
	\item \textbf{Sử dụng standard MMD:} Phù hợp hơn IDW-MMD cho classification vì standard MMD giữ lại tất cả sự khác biệt bao gồm cả những thay đổi nhỏ từ PCD (Gradual, Incremental).
\end{itemize}

\textbf{Độ phức tạp tính toán:}
\begin{itemize}
	\item Gaussian smoothing: $O(m)$ với $m$ = độ dài tín hiệu
	\item Peak detection: $O(m)$ sử dụng thuật toán scipy.signal.find\_peaks
	\item Feature extraction: $O(n_p)$ với $n_p$ = số peaks
	\item Classification: $O(1)$ - chỉ so sánh ngưỡng
	\item \textbf{Tổng:} $O(m)$ - tuyến tính theo độ dài tín hiệu
\end{itemize}

\subsection{Giải thích lựa chọn ngưỡng}
Các ngưỡng trong Algorithm~\ref{alg:se-cdt} được xác định dựa trên phân tích thực nghiệm trên synthetic datasets:
\begin{itemize}
	\item \textbf{WR $<$ 0.12 (TCD):} Sudden drift tạo peak sắc nét với FWHM $<$ 24\% window size. Ngưỡng này phân biệt peak ``nhọn'' của sudden với peak ``rộng'' của gradual.
	\item \textbf{$n_p \geq 4$ và CV $<$ 0.3 (Recurrent):} Recurrent drift có nhiều peaks đều đặn. CV (Coefficient of Variation) thấp chỉ ra khoảng cách giữa các peaks ổn định.
	\item \textbf{$n_p \geq 10$ (Incremental):} Incremental drift tạo nhiều peaks nhỏ liên tục do sự thay đổi từ từ trong phân phối.
\end{itemize}
\textit{Ghi chú: Các ngưỡng này được tối ưu trên synthetic data và có thể cần điều chỉnh cho từng domain cụ thể.}

\textbf{Lưu ý về biến thể IDW-MMD:}
Luận văn cũng thử nghiệm sử dụng IDW-MMD (trọng số nghịch mật độ) thay cho standard MMD trong SE-CDT. Tuy nhiên, kết quả cho thấy IDW-MMD không phù hợp cho classification do cơ chế giảm phương sai có xu hướng loại bỏ những thay đổi nhỏ (coi là noise). IDW-MMD phù hợp hơn cho drift \textit{detection} (nhị phân: có/không có drift), nhưng standard MMD tốt hơn cho \textit{classification} (phân loại loại drift). Chi tiết thử nghiệm và so sánh định lượng được trình bày ở Chương~\ref{chap:experiments}.

Kết quả phân loại từ SE-CDT sẽ được sử dụng để kích hoạt chiến lược thích ứng phù hợp, được trình bày trong phần tiếp theo.

\section{Khung chiến lược thích ứng mô hình}
\label{sec:model-adaptation-framework}

Dựa trên kết quả phân loại drift từ SE-CDT, hệ thống có thể kích hoạt chiến lược cập nhật mô hình phù hợp. Phần này trình bày khung chiến lược thích ứng (Adaptation Framework).

\subsection{Ma trận quyết định chiến lược}

Thay vì áp dụng một chiến lược duy nhất (như huấn luyện lại toàn bộ) cho mọi trường hợp, hệ thống đề xuất sử dụng thông tin về loại drift để tối ưu hóa chi phí và hiệu suất. Bảng~\ref{tab:adaptation-strategies} mô tả ánh xạ giữa loại drift và chiến lược thích ứng:

\begin{table}[H]
	\centering
	\caption{Chiến lược thích ứng theo loại Drift}
	\label{tab:adaptation-strategies}
	\begin{tabular}{|l|p{5.5cm}|p{5cm}|}
		\hline
		\textbf{Loại Drift}  & \textbf{Chiến lược Thích ứng}                                                                                               & \textbf{Cơ sở lý luận}                                                                  \\
		\hline
		\textbf{Sudden}      & \textbf{Full Model Reset:} Khởi tạo lại mô hình và huấn luyện lại trên cửa sổ dữ liệu mới nhất (post-drift).                & Dữ liệu cũ không còn giá trị, cần loại bỏ hoàn toàn để tránh nhiễu (negative transfer). \\
		\hline
		\textbf{Incremental} & \textbf{Continuous Update:} Cập nhật mô hình hiện tại với dữ liệu mới (online learning/fine-tuning).                        & Sự thay đổi mang tính tiệm tiến, kiến thức cũ vẫn còn giá trị một phần.                 \\
		\hline
		\textbf{Gradual}     & \textbf{Weighted Ensemble/Window:} Sử dụng cửa sổ trượt có trọng số, ưu tiên dữ liệu mới nhưng giữ lại một phần dữ liệu cũ. & Giai đoạn chuyển tiếp có sự pha trộn giữa hai phân phối, cần bộ nhớ đệm.                \\
		\hline
		\textbf{Recurrent}   & \textbf{Model Caching \& Reuse:} Tìm kiếm trong kho lưu trữ mô hình cũ phù hợp và kích hoạt lại.                            & Tái sử dụng tri thức đã học, tiết kiệm chi phí huấn luyện lại.                          \\
		\hline
		\textbf{Blip}        & \textbf{No Action / Minimal Update:} Bỏ qua hoặc cập nhật với trọng số rất thấp.                                            & Thay đổi chỉ là nhiễu tạm thời, tránh việc mô hình "quên" kiến thức ổn định.            \\
		\hline
	\end{tabular}
\end{table}

\subsection{Triển khai các chiến lược}

\subsubsection{Chiến lược cho Sudden Drift (Trọng tâm nghiên cứu)}
Trong phạm vi luận văn, chiến lược cho \textit{Sudden Drift} được cài đặt và đánh giá chi tiết nhất. Quy trình cụ thể như sau:
\begin{enumerate}
	\item \textbf{Kích hoạt:} Khi CDT\_MSW phân loại drift là "Sudden".
	\item \textbf{Thu thập dữ liệu:} Hệ thống chờ và thu thập một lượng dữ liệu mới ($N_{new}$) ngay sau điểm drift.
	\item \textbf{Huấn luyện lại:} Một instance mô hình mới (ví dụ: Logistic Regression) được khởi tạo với trọng số ngẫu nhiên và huấn luyện trên $N_{new}$.
	\item \textbf{Thay thế:} Mô hình cũ bị loại bỏ hoàn toàn, mô hình mới được đưa vào sử dụng (hot-swap).
\end{enumerate}

\subsubsection{Cơ chế Model Caching cho Recurrent Drift}
Để xử lý drift lặp lại, hệ thống duy trì một \textit{Model Repository}. Mỗi khi một mô hình bị thay thế (do drift), nó được lưu lại cùng với "chữ ký" phân phối (distribution signature) của dữ liệu mà nó đã học.
\begin{itemize}
	\item \textbf{Signature:} Vector trung bình và ma trận hiệp phương sai của đặc trưng.
	\item \textbf{Matching:} Khi drift xảy ra, hệ thống so sánh phân phối dữ liệu mới với các signature trong kho bằng khoảng cách Kolmogorov-Smirnov (KS). Nếu độ tương đồng cao (khoảng cách nhỏ hơn ngưỡng $\epsilon$), mô hình cũ sẽ được tải lại và tinh chỉnh nhẹ.
\end{itemize}

\subsubsection{Cơ chế Meta-Learning (Hướng phát triển)}
Hệ thống được thiết kế để hỗ trợ Meta-Learning trong tương lai: một mô hình cấp cao (meta-learner) sẽ học cách chọn chiến lược tốt nhất dựa trên lịch sử các lần thích ứng thành công hay thất bại, thay vì chỉ dựa vào quy tắc cố định.

\section{Kiến trúc đề xuất cho hệ thống Streaming Real-time với Apache Kafka}

Để hiện thực hóa các phương pháp trên trong môi trường thực tế, luận văn đề xuất một kiến trúc xử lý luồng dữ liệu phân tán dựa trên Apache Kafka. Kiến trúc này được thiết kế để đảm bảo tính tách biệt (decoupling), khả năng mở rộng (scalability) và độ tin cậy (reliability).

\begin{quotation}
\textbf{Lưu ý về phạm vi triển khai:} Phần này trình bày \textbf{thiết kế kiến trúc đề xuất}, không phải triển khai production hoàn chỉnh. Cụ thể:
\begin{itemize}
	\item \textbf{Đã triển khai:} Mô phỏng streaming qua Kafka-compatible API (Redpanda) với các thuật toán detection và classification.
	\item \textbf{Chưa đánh giá:} Hiệu năng hệ thống phân tán (latency dưới tải cao, throughput với nhiều partitions, fault recovery time).
\end{itemize}
Đánh giá benchmark trong Chương~\ref{chap:experiments} tập trung vào hiệu năng thuật toán (detection accuracy, runtime), không phải infrastructure performance.
\end{quotation}

\subsection{Tổng quan kiến trúc}

Hệ thống được thiết kế theo mô hình \textbf{Event-Driven Architecture} gồm 5 thành phần chính hoạt động độc lập và giao tiếp qua các Kafka topics:

\begin{figure}[h]
	\centering
	% System Architecture Diagram
	\includegraphics[width=0.95\textwidth]{image/system_architecture.png}
	\caption{Sơ đồ kiến trúc hệ thống phát hiện và thích ứng Drift}
	\label{fig:system_architecture}
\end{figure}

\begin{enumerate}
	\item \textbf{Data Producer (Nguồn dữ liệu):} Mô phỏng hoặc thu thập dữ liệu từ cảm biến/nguồn phát, gửi vào topic \texttt{sensor.stream}.
	\item \textbf{Drift Detection Consumer (Bộ phát hiện):} Đọc dữ liệu từ stream, duy trì cửa sổ trượt và thực thi thuật toán ShapeDD\_ADW\_MMD.
	\item \textbf{Drift Classifier (Bộ phân loại):} Được kích hoạt khi có tín hiệu drift, thực thi CDT\_MSW để xác định loại drift và gửi sự kiện vào topic \texttt{drift.results}.
	\item \textbf{Adaptation Manager (Bộ thích ứng):} Lắng nghe sự kiện drift, thực thi chiến lược thích ứng (huấn luyện lại/cập nhật) và publish mô hình mới.
	\item \textbf{Monitoring Dashboard:} Trực quan hóa dữ liệu, điểm drift và hiệu suất mô hình theo thời gian thực.
\end{enumerate}

\subsection{Thiết kế chi tiết các thành phần}

\subsubsection{Producer và Data Ingestion}
Producer được thiết kế để chịu lỗi và đảm bảo tính toàn vẹn dữ liệu:
\begin{itemize}
	\item Sử dụng cơ chế \textbf{retry with exponential backoff} để xử lý mất kết nối mạng.
	\item Dữ liệu được serialize dưới dạng JSON bao gồm timestamp, feature vector và metadata.
	\item Hỗ trợ điều chỉnh tốc độ phát tin (throughput control) để mô phỏng các tải hệ thống khác nhau.
\end{itemize}

\subsubsection{Consumer và Cơ chế Windowing}
Thành phần Consumer đóng vai trò quan trọng nhất, thực hiện phát hiện drift:
\begin{itemize}
	\item \textbf{Circular Buffer:} Duy trì một bộ đệm tuần hoàn (ví dụ: 1000 mẫu) trong bộ nhớ để phục vụ tính toán cửa sổ trượt mà không cần truy xuất lại Kafka quá nhiều.
	\item \textbf{4-Phase Lifecycle:}
	      \begin{enumerate}
		      \item \textit{Pre-training:} Thu thập dữ liệu ban đầu để huấn luyện mô hình gốc.
		      \item \textit{Warm-up:} Giai đoạn ổn định, thiết lập baseline hiệu suất.
		      \item \textit{Monitoring (Frozen):} Mô hình chạy ở chế độ dự đoán (không học), liên tục kiểm tra drift bằng ShapeDD.
		      \item \textit{Adaptation:} Tạm dừng monitoring để cập nhật mô hình khi có drift.
	      \end{enumerate}
\end{itemize}

\subsubsection{Quản lý Topic và Giao tiếp}
Hệ thống sử dụng các topic riêng biệt để phân tách luồng dữ liệu và luồng điều khiển:
\begin{table}[H]
	\centering
	\caption{Danh sách Kafka Topics và Chức năng}
	\label{tab:kafka-topics}
	\begin{tabular}{|l|l|l|}
		\hline
		\textbf{Topic Name}     & \textbf{Nội dung}   & \textbf{Mục đích}                               \\
		\hline
		\texttt{sensor.stream}  & Raw data samples    & Luồng dữ liệu đầu vào cho mô hình và detector.  \\
		\hline
		\texttt{drift.results}  & Drift events        & Thông báo drift đã được phát hiện và phân loại. \\
		\hline
		\texttt{model.updated}  & Model metadata      & Thông báo mô hình mới đã sẵn sàng (hot-reload). \\
		\hline
		\texttt{model.accuracy} & Performance metrics & Dữ liệu giám sát độ chính xác real-time.        \\
		\hline
	\end{tabular}
\end{table}

\section{Cơ chế chịu lỗi và đảm bảo độ tin cậy}

Trong môi trường phân tán, các sự cố là không thể tránh khỏi. Hệ thống đề xuất tích hợp các cơ chế chịu lỗi (Fault Tolerance) ở nhiều cấp độ:

\subsection{Xử lý lỗi ở mức ứng dụng}
\begin{itemize}
	\item \textbf{Graceful Degradation:} Nếu module Adaptor gặp lỗi (ví dụ: tràn bộ nhớ khi huấn luyện), hệ thống sẽ fallback về mô hình cũ và ghi log cảnh báo, thay vì dừng toàn bộ pipeline.
	\item \textbf{Try-Catch Wrapper:} Quá trình tính toán ShapeDD được bọc trong các khối an toàn để xử lý các ngoại lệ số học (như ma trận không nghịch đảo) mà không làm crash Consumer.
\end{itemize}

\subsection{Xử lý lỗi ở mức hạ tầng (Kafka)}
\begin{itemize}
	\item \textbf{Replication:} Các topic quan trọng được cấu hình \texttt{replication.factor=3} để đảm bảo không mất dữ liệu ngay cả khi 1-2 broker bị lỗi.
	\item \textbf{Offset Management:} Consumer chỉ commit offset sau khi đã xử lý xong batch dữ liệu, đảm bảo ngữ nghĩa "at-least-once" (không bỏ sót dữ liệu).
	\item \textbf{Consumer Rebalancing:} Nếu một instance của Consumer bị lỗi, Kafka sẽ tự động phân phối lại các partition cho các consumer còn lại trong nhóm.
\end{itemize}

\section{Kết luận chương}
Chương này đã trình bày chi tiết mô hình đề xuất \textbf{ShapeDD-Stream}, bao gồm cải tiến thuật toán (IDW-MMD với phân phối tiệm cận), chiến lược thích ứng thông minh, và kiến trúc hệ thống dựa trên Kafka. Cải tiến thuật toán được đánh giá thực nghiệm chi tiết trong Chương~\ref{chap:experiments}, trong khi kiến trúc Kafka được trình bày như một thiết kế đề xuất cho triển khai production trong tương lai.
