\chapter{Công trình liên quan}

\section{Các phương pháp phát hiện trôi dạt}

\subsection{Khái niệm và bối cảnh}

\subsection{Các loại hiện tượng trôi dạt}

Concept drift, hay còn gọi là sự trôi dạt khái niệm, đề cập đến những thay đổi trong phân phối dữ liệu được tạo ra theo thời gian, đặc biệt là trong môi trường động và thay đổi theo thời gian, chẳng hạn như trong ứng dụng về IoT [17]. Cụ thể hơn, sự trôi dạt khái niệm là một vấn đề trong đó các mối quan hệ thống kê giữa các giá trị đầu vào và giá trị mục tiêu bị thay đổi theo thời gian theo cách không thể dự đoán được [18]. 
Có nhiều loại trôi dạt khác nhau, tùy thuộc vào các yếu tố dữ liệu đang thay đổi. Các loại chính của sự trôi dạt khái niệm bao gồm:
Sự trôi dạt ảo (Virtual Drift): Còn được gọi là sự dịch chuyển biến phụ, đề cập đến tình huống mà sự thay đổi xảy ra trong phân phối các trường hợp đầu vào, trong khi xác suất sau của các giá trị mục tiêu vẫn không đổi [3].
Sự trôi dạt thực (Real Drift): Sự thay đổi trong xác suất sau của các giá trị mục tiêu (tức là các lớp) được gọi là sự trôi dạt thực. Sự trôi dạt thực có thể không ảnh hưởng đến sự phân phối các trường hợp đầu vào. Ví dụ, người ta có thể đề cập đến sự thay đổi trong sở thích của người dùng khi họ theo dõi các kênh tin tức phát trực tuyến, trong khi sự phân phối các mục tin tức nhận được thường không thay đổi [3].
Sự trôi dạt dần dần và đột ngột (Gradual and abrupt drift): Về tốc độ, sự trôi dạt có thể được phân loại thành sự trôi dạt dần dần và đột ngột. Sự trôi dạt dần dần biểu thị trường hợp khi sự phân phối dữ liệu thay đổi dần dần theo thời gian, trong khi sự trôi dạt đột ngột có thể xảy ra khi sự thay đổi trong phân phối dữ liệu xảy ra đột ngột [3].
Sự trôi tăng dần (Increamental Drift):, thể hiện cho sự tiến hóa dần dần của phân phối dữ liệu. Ví dụ như sự tiến hóa dần dần của hệ thống đề xuất người dùng ngày càng tiến hóa và nhiều hơn dựa trên sự thay đổi của người dùng.[19]
Sự trôi dạt lặp lại (Recurrent Drift): Trôi dạt lặp lại là khi dữ liệu quay trở lại trạng thái cũ sau một thời gian, hoặc lặp lại theo chu kỳ. Những thay đổi trong dữ liệu không phải mới mà đã từng xảy ra trước đó. Ví dụ như xu hướng thời trang thay đổi theo mùa, tuần hoàn theo từng năm. [19]

Sự trôi dạt khái niệm có thể dẫn đến hiệu suất giảm trong quá trình vận hành thực tế của mô hình học máy, điểu này trái ngược với hiệu suất được đánh giá trên tập dữ liệu thử nghiệm tĩnh trong quá trình phát triển.
Sự trôi dạt khái niệm có thể ảnh hưởng lớn đến hiệu suất của mô hình dự đoán, đặc biệt là khi mô hình học từ luồng dữ liệu. Một loạt các dịch vụ/ứng dụng trong bối cảnh hệ thống và mạng truyền thông có thể bị cản trở bởi sự trôi dạt khái niệm như: Hệ thống phát hiện xâm nhập (Intrusion Detection Systems  - IDS, hệ thống phân loại và dự đoán lưu lượng và IIoT. Ví dụ, người ta có thể tham khảo các kỹ thuật bảo trì dựa trên tình trạng (Condition-Based Maintenance - CBM) trong IIoT được sử dụng để dự đoán các điều kiện bất thường và thời gian bảo trì thông qua phân tích dữ liệu IIoT. Sự trôi dạt khái niệm ảnh hưởng đáng kể đến hiệu suất của CBM và do đó làm giảm chất lượng sản phẩm. 
Điều này có thể được giải thích bởi thực tế là sự phân phối các mẫu lỗi có thể thay đổi theo thời gian do máy móc lão hóa và quy trình bảo trì. Do đó, một kỹ thuật CBM không có khả năng xử lý sự trôi dạt khái niệm sẽ hoạt động kém. Thật vậy, sự trôi dạt khái niệm có thể ảnh hưởng đến hiệu quả và tính mạnh mẽ của phân tích luồng dữ liệu.
Sự trôi dạt khái niệm cũng là vấn đề đối với các ứng dụng IoT khác, chẳng hạn như thành phố thông minh. Trong các thành phố thông minh, dữ liệu có thể được thu thập vì nhiều lý do khác nhau, chẳng hạn như đảm bảo an ninh mạng, dự đoán ô nhiễm không khí, dự đoán giao thông đường bộ và dự báo tải điện. Tuy nhiên, theo thời gian, những thay đổi không lường trước có thể xảy ra trong dữ liệu được thu thập (sự trôi dạt khái niệm) và do đó, nó đặt ra những thách thức nghiêm trọng đối với độ chính xác của các mô hình dự đoán.
Trong môi trường không cố định, có một số cân nhắc mà các mô hình dự đoán phải tính đến để phát hiện và tự thích ứng với sự trôi dạt khái niệm, nếu không, hiệu suất của các mô hình này sẽ giảm sút về độ chính xác và độ mạnh mẽ. Theo thời gian, một mô hình dự đoán có thể cần cập nhật các tham số và cấu trúc của nó bằng cách kết hợp các dữ liệu huấn luyện mới hoặc thay thế hoàn toàn mô hình cũ để xử lý sự trôi dạt khái niệm.


\subsection{Lịch sử phát triển các phương pháp phát hiện trôi dạt khái niệm}
Trải qua nhiều thập kỷ, bài toán phát hiện hiện tượng trôi dạt đã được nghiên cứu với nhiều cách tiếp cận khác nhau. Từ những năm 1990, các hệ thống học máy đầu tiên có khả năng thích ứng với concept drift (ví dụ: STAGGER 1986, FLORA 1996) chủ yếu dựa trên chiến lược cửa sổ trượt hoặc bỏ quên mẫu cũ để dần thích nghi với dữ liệu mới. Tuy nhiên, giai đoạn này chưa có phương pháp “phát hiện” drift tách rời; các mô hình thường tự điều chỉnh dựa trên độ lỗi hoặc trọng số mẫu theo thời gian. 

Bước ngoặt xảy ra vào giữa những năm 2000 khi các thuật toán chuyên biệt để phát hiện điểm thay đổi bắt đầu ra đời. 

Nhìn chung, các phương pháp phát hiện trôi dạt có thể phân thành các nhóm chính theo kỹ thuật cốt lõi, bao gồm: (1) nhóm phương pháp thống kê (phân tích thay đổi phân phối dữ liệu), (2) nhóm phương pháp theo dõi hiệu năng mô hình (dựa trên sai số/độ chính xác), (3) nhóm phương pháp học máy truyền thống (ví dụ sử dụng ensemble hoặc mô hình phụ để nhận biết drift), và (4) nhóm phương pháp học sâu (deep learning) mới nổi gần đây.

\subsubsection{Các phương pháp thống kê}
Nhóm phương pháp thống kê tập trung vào việc phát hiện thay đổi phân phối dữ liệu một cách trực tiếp, thường thông qua các phép kiểm định thống kê hoặc quan sát cửa sổ trượt trên dòng dữ liệu. 
Một trong những kỹ thuật kinh điển là sử dụng các biểu đồ kiểm soát thống kê liên tục như \textit{CUSUM} hay kiểm định \textit{Page-Hinkley (PH)}. 

Chẳng hạn, thuật toán PH (nguồn gốc từ năm 1954) được áp dụng trong bối cảnh concept drift để giám sát trung bình của một chuỗi số liệu và phát hiện khi nào trung bình thay đổi đáng kể [1].

PH thực chất triển khai biểu đồ CUSUM để nhạy với những thay đổi nhỏ trong giá trị trung bình và có thể phát hiện cả xu hướng tăng lẫn giảm. 

Tương tự, các kiểm định thống kê hai mẫu (như Kolmogorov–Smirnov, Student t-test) cũng được tận dụng để so sánh phân phối của hai cửa sổ dữ liệu (mới và cũ) nhằm tìm ra sự khác biệt có ý nghĩa.

Một dấu mốc quan trọng trong nhóm này là phương pháp \textbf{ADWIN} (Adaptive Windowing) do Bifet và Gavaldà đề xuất năm 2007~\cite{bifet2007learning}. 

ADWIN sử dụng cửa sổ trượt có kích thước thay đổi một cách thích ứng: nó duy trì một cửa sổ dữ liệu với độ dài biến thiên sao cho giả thiết "không có thay đổi" được đảm bảo bên trong cửa sổ đó. 

Cụ thể, tại mỗi thời điểm, ADWIN tách cửa sổ hiện tại thành hai phần $W_0$ và $W_1$ (phần đầu và phần cuối của cửa sổ) rồi so sánh sự khác biệt về giá trị trung bình giữa $W_0$ và $W_1$.

Nếu chênh lệch trung bình vượt quá một ngưỡng thống kê (xác định dựa trên khoảng tin cậy với mức ý nghĩa $\delta$ đã chọn), thuật toán kết luận rằng phân phối dữ liệu đã thay đổi và kích hoạt báo động drift. 

Ưu điểm nổi bật của ADWIN là nó cung cấp đảm bảo về mặt lý thuyết cho độ chính xác của phát hiện thay đổi, đồng thời tự động điều chỉnh kích thước cửa sổ thay vì yêu cầu người dùng cố định trước. 

Phương pháp này tỏ ra hiệu quả trong việc phát hiện cả drift đột ngột lẫn dần dần, và đã tạo nền tảng cho nhiều kỹ thuật nâng cao sau này.

Tuy nhiên, ADWIN cũng có nhược điểm: chi phí tính toán khá cao do phải kiểm tra nhiều kích thước cửa sổ, và nhạy cảm với nhiễu (noise) trong dữ liệu~\cite{hinder2024survey_partA}.

Bên cạnh ADWIN, nhiều phương pháp thống kê khác lần lượt xuất hiện. 

Nishida và Yamauchi (2007) đề xuất sử dụng trực tiếp phép kiểm định thống kê (như kiểm định $t$ hoặc K-S) để xác định concept drift trong dữ liệu streaming. 

Một phương pháp khác là \textbf{KSWIN} (Kolmogorov–Smirnov WINdowing, Raab et al., 2020), kết hợp kiểm định Kolmogorov–Smirnov với cửa sổ trượt nhằm phát hiện thay đổi phân phối một cách phi tham số. 

Các phương pháp thống kê thuần túy này có ưu điểm là không phụ thuộc vào mô hình học máy cụ thể, do đó có thể áp dụng trong môi trường phi giám sát (không cần nhãn). 

Mặt khác, chúng thường đòi hỏi giả định mạnh về độc lập và phân phối dữ liệu, và có thể bỏ sót những thay đổi nhỏ nếu kích thước mẫu không đủ lớn. 

Dù vậy, nhóm phương pháp thống kê đã đặt nền móng quan trọng cho lĩnh vực phát hiện drift, đặc biệt cho các bài toán mà ta quan tâm trực tiếp đến sự thay đổi của dữ liệu hơn là hiệu năng mô hình.


Shape Drift Detector (ShapeDD) là một detector drift dựa trên meta-statistic hoạt động thông qua quá trình đa giai đoạn để xác định concept drift trong luồng dữ liệu. Thuật toán sử dụng MMD như thước đo thống kê cốt lõi và theo một cách tiếp cận có hệ thống bao gồm bốn giai đoạn chính.

\subsubsection{Giai đoạn 1: Thu thập dữ liệu}

Giai đoạn đầu tiên bao gồm thu thập dữ liệu sử dụng kỹ thuật cửa sổ trượt. Nhiều chiến lược cửa sổ có thể được sử dụng:

\begin{itemize}
    \item \textbf{Cửa sổ trượt kích thước cố định}: Duy trì kích thước cửa sổ không đổi $w$ trượt trên luồng dữ liệu
    \item \textbf{Cửa sổ thích ứng}: Điều chỉnh động kích thước cửa sổ dựa trên đặc trưng dữ liệu
    \item \textbf{Cửa sổ chồng chéo}: Sử dụng các đoạn chồng chéo để đảm bảo chuyển tiếp mượt mà
\end{itemize}

Đối với luồng dữ liệu $\mathcal{S} = \{x_1, x_2, \ldots, x_n\}$, chúng ta duy trì cửa sổ trượt $W_t$ có kích thước $l_1$ tại thời điểm $t$:
\begin{equation}
W_t = \{x_{t-l_1+1}, x_{t-l_1+2}, \ldots, x_t\}
\end{equation}

\subsubsection{Giai đoạn 2: Xây dựng feature}

Trong giai đoạn này, chúng ta xây dựng ma trận tương đồng sử dụng hàm kernel để nắm bắt mối quan hệ giữa các điểm dữ liệu. Gaussian RBF kernel thường được sử dụng:

\begin{equation}
k(x_i, x_j) = \exp\left(-\frac{\|x_i - x_j\|^2}{2\sigma^2}\right)
\end{equation}

Điều này tạo ra ma trận kernel $K \in \mathbb{R}^{n \times n}$ trong đó $K_{ij} = k(x_i, x_j)$ biểu thị sự tương đồng giữa các điểm dữ liệu $x_i$ và $x_j$.

\subsubsection{Giai đoạn 3: Tính toán sự khác biệt}

Cốt lõi của ShapeDD bao gồm tính toán sự khác biệt thống kê giữa các đoạn dữ liệu liên tiếp sử dụng MMD. Chúng ta định nghĩa hàm trọng số $w(t)$ tạo ra trọng số tương phản cho các nửa khác nhau của cửa sổ trượt:

\begin{equation}
w(t) = \begin{cases}
\frac{1}{l_1} & \text{nếu } t \in [1, l_1] \\
-\frac{1}{l_1} & \text{nếu } t \in [l_1+1, 2l_1]
\end{cases}
\end{equation}

Thống kê MMD sau đó được tính như:
\begin{equation}
\text{MMD}^2_t = \sum_{i,j=1}^{2l_1} w_i w_j K_{ij}
\end{equation}

Tính toán này được thực hiện trên toàn bộ luồng dữ liệu sử dụng phương pháp cửa sổ trượt, tạo ra chuỗi các giá trị MMD $\{\text{MMD}^2_1, \text{MMD}^2_2, \ldots, \text{MMD}^2_T\}$.

\subsubsection{Giai đoạn 4: Xác thực thống kê}

Giai đoạn cuối cùng bao gồm chuẩn hóa các thống kê MMD và xác định các điểm thay đổi tiềm năng thông qua phát hiện zero-crossing. Các giá trị shape được tính bằng convolution:

\begin{equation}
\text{shape\_values}_t = \sum_{i} \text{MMD}^2_{t+i} \cdot h_i
\end{equation}

trong đó $h$ là kernel convolution (thường là $[1, -1]$ cho phát hiện biên đơn giản).

Các điểm thay đổi tiềm năng được xác định khi các giá trị shape liên tiếp có dấu trái ngược. Những ứng cử viên này sau đó được xác thực bằng permutation test để tính p-value và xác định ý nghĩa thống kê.
Nếu p-value nhỏ hơn mức ý nghĩa $\alpha$ đã chọn, chúng ta kết luận rằng có concept drift tại thời điểm đó.

\subsubsection{Các phương pháp dựa trên hiệu năng mô hình}
Đây là nhóm phương pháp phổ biến trong giai đoạn giữa những năm 2000, khi các nhà nghiên cứu tập trung vào việc giám sát chất lượng dự đoán của mô hình học máy theo thời gian để phát hiện drift. 

Ý tưởng chính là: nếu mô hình hiện tại bỗng nhiên dự đoán kém (tỉ lệ lỗi tăng lên đáng kể) thì có khả năng khái niệm đã thay đổi. 

Phương pháp tiêu biểu mở đầu cho hướng tiếp cận này là \textbf{DDM} (\textit{Drift Detection Method}) do Gama và cộng sự giới thiệu năm 2004[6]. 

DDM được xem như cột mốc quan trọng, đặt nền tảng cho hàng loạt nghiên cứu tiếp theo về phát hiện drift[6]. 

Thuật toán DDM giám sát tỉ lệ lỗi (error rate) của mô hình theo dòng dữ liệu bằng cách xem mỗi mẫu dự đoán sai như một thử nghiệm Bernoulli (lỗi = 1 nếu dự đoán sai)[7]. 

Giả sử $p_i$ là xác suất lỗi tại mẫu thứ $i$, DDM ước lượng $p_i$ và độ lệch chuẩn $s_i$ tương ứng. 

Trong quá trình cập nhật, DDM ghi nhận giá trị tối thiểu của $p_i + 3s_i$ (biên trên của khoảng tin cậy 3 sigma) đạt được cho đến hiện tại. 

Khi nào $p_j + 3s_j$ ở thời điểm $j$ vượt quá giá trị tối thiểu trước đó một lượng đáng kể, mô hình suy luận rằng đã có drift xảy ra. 

Cụ thể, DDM đặt hai ngưỡng: mức \textit{cảnh báo} khi $p_j + 2s_j$ vượt quá min$(p_i+3s_i)$, và mức \textit{drift} khi $p_j + 3s_j$ vượt quá min$(p_i+3s_i)$[7]. 

\begin{itemize}
    \item \textbf{Mức cảnh báo:} Được kích hoạt khi $p_i + s_i \geq p_{\text{min}} + 2 \cdot s_{\text{min}}$
    \item \textbf{Mức phát hiện drift:} Được kích hoạt khi $p_i + s_i \geq p_{\text{min}} + 3 \cdot s_{\text{min}}$
\end{itemize}

trong đó $p_i$ là tỷ lệ lỗi hiện tại, $s_i$ là độ lệch chuẩn, và $p_{\text{min}}, s_{\text{min}}$ là các giá trị tối thiểu đã quan sát được.

Tỷ lệ lỗi $p_i$ và độ lệch chuẩn $s_i$ được tính như sau:
\begin{equation}
p_i = \frac{\sum_{j=1}^{i} \text{error}_j}{i}
\end{equation}

\begin{equation}
s_i = \sqrt{\frac{p_i(1-p_i)}{i}}
\end{equation}

Khi chạm ngưỡng cảnh báo, hệ thống có thể chuẩn bị (ví dụ lưu dữ liệu); khi chạm ngưỡng drift, DDM phát tín hiệu rằng concept drift đã diễn ra, và mô hình cần được điều chỉnh hoặc huấn luyện lại. DDM tỏ ra hiệu quả, đơn giản và rất phù hợp cho các ứng dụng dòng dữ liệu thời gian thực, bởi nó chỉ yêu cầu tính toán nhẹ (cập nhật thống kê lỗi)[8]. 

Tuy nhiên, nhược điểm của DDM là trong môi trường dữ liệu nhiễu, tỉ lệ lỗi dao động có thể gây ra nhiều báo động giả (false alarm)[9]. Đặc biệt, DDM phản ứng chậm trước các dạng drift từ từ (gradual drift) do nó chỉ dựa vào sự gia tăng đột biến của lỗi. Nhược điểm này đã dẫn đến sự ra đời của các biến thể cải tiến. 

Năm 2006, \textbf{EDDM} (\textit{Early DDM}) được đề xuất nhằm nâng cao khả năng phát hiện drift dần dần[9][10]. Thay vì theo dõi trực tiếp xác suất lỗi, EDDM tập trung vào khoảng cách (số mẫu) giữa các lần dự đoán sai liên tiếp. Ý tưởng là khi sự trôi dạt chưa xảy ra, các lỗi phân bố ngẫu nhiên; còn khi sự trôi dạt bắt đầu thay đổi từ từ, lỗi sẽ xuất hiện ngày một thường xuyên hơn. EDDM tính trung bình khoảng cách lỗi và độ lệch chuẩn của khoảng cách đó, rồi đặt ngưỡng tương tự DDM để phát hiện drift dựa trên việc khoảng cách lỗi giảm mạnh[10]. Nhờ vậy, EDDM nhạy hơn với các thay đổi từ từ, báo hiệu sớm hơn so với DDM trong nhiều trường hợp.

EDDM tính toán khoảng cách trung bình ($p'_i$) giữa hai lỗi phân loại gần đây và độ lệch chuẩn của nó ($s'_i$) tại mỗi bước thời gian. Phương pháp lưu trữ giá trị tối đa đã quan sát của $p'_i + 2 \cdot s'_i$ (ký hiệu là $p'_{\text{max}} + 2 \cdot s'_{\text{max}}$), đại diện cho điểm mà mô hình hiện tại xấp xỉ tốt nhất các khái niệm dữ liệu cơ bản.

EDDM sử dụng hai ngưỡng $\alpha$ và $\beta$ để báo hiệu các thay đổi:
\begin{itemize}
    \item \textbf{Mức cảnh báo:} Drift tiềm ẩn được chỉ báo khi tỷ số $\frac{p'_i + 2 \cdot s'_i}{p'_{\text{max}} + 2 \cdot s'_{\text{max}}} < \alpha$ (thường $\alpha = 0.95$)
    \item \textbf{Mức drift:} Concept drift được phát hiện khi tỷ số $\frac{p'_i + 2 \cdot s'_i}{p'_{\text{max}} + 2 \cdot s'_{\text{max}}} < \beta$ (thường $\beta = 0.90$)
\end{itemize}


EDDM chỉ bắt đầu tìm kiếm concept drift sau khi ít nhất 30 lỗi phân loại đã xảy ra, vì điều này cần thiết để ước lượng đáng tin cậy phân phối khoảng cách giữa các lỗi.

Sau DDM và EDDM, hàng loạt thuật toán dựa trên theo dõi hiệu năng ra đời, cho thấy sự phát triển mạnh mẽ trong giai đoạn cuối 2000s và 2010s. Một hướng cải tiến quan trọng là áp dụng các ràng buộc thống kê chặt chẽ hơn để giảm giả định phân phối. Ví dụ, \textbf{HDDM} (\textit{Hoeffding's DDM}, Frías-Blanco et al., 2015) sử dụng bất đẳng thức Hoeffding để xây dựng tiêu chí phát hiện drift phi tham số (không giả định phân phối cụ thể của lỗi)[11]. HDDM có hai biến thể: HDDM\_A dùng trung bình tỷ lệ lỗi với bound Hoeffding, và HDDM\_W dùng tỷ lệ lỗi gán trọng số. 

Tiếp đó, \textbf{FHDDM} (\textit{Fast HDDM}, Pesaranghader \& Viktor, 2016) được giới thiệu như phiên bản tăng tốc của HDDM, cải thiện cả tốc độ và độ nhạy trong việc phát hiện drift[12]. FHDDM vẫn dựa trên bất đẳng thức Hoeffding nhưng tối ưu thuật toán tính toán để phù hợp với dòng dữ liệu tốc độ cao, nhờ đó phản ứng nhanh với cả drift đột ngột lẫn dần dần[12]. 

Phương pháp FHDDMS (\textit{Fast Hoeffding's DDM with Multiple Sliding Windows}, Pesaranghader \& Viktor, 2016) mở rộng phương pháp FHDDM bằng cách duy trì hai cửa sổ trượt chồng lên nhau với kích thước khác nhau: một cửa sổ ngắn và một cửa sổ dài. Thiết kế này cho phép phương pháp tận dụng những ưu điểm của cả hai kích thước cửa sổ:

\begin{itemize}
    \item \textbf{Cửa sổ ngắn:} Được thiết kế để phát hiện drift đột ngột nhanh hơn
    \item \textbf{Cửa sổ dài:} Nhằm phát hiện drift dần dần với tỷ lệ âm tính giả thấp hơn
\end{itemize}

Đối với cả hai cửa sổ, thuật toán chèn '1' nếu dự đoán đúng và '0' nếu sai. FHDDMS liên tục tính toán giá trị trung bình hiện tại của các phần tử trong mỗi cửa sổ ($\mu_{tl}$ cho cửa sổ dài, $\mu_{ts}$ cho cửa sổ ngắn) và cập nhật giá trị trung bình tối đa đã quan sát ($\mu_{ml}$ cho cửa sổ dài, $\mu_{ms}$ cho cửa sổ ngắn) nếu giá trị hiện tại cao hơn.

Concept drift được báo hiệu nếu sự khác biệt giữa giá trị trung bình tối đa đã quan sát và giá trị trung bình hiện tại ($\Delta\mu = \mu_m - \mu_t$) của một trong hai cửa sổ vượt quá ngưỡng được xác định trước ($\varepsilon_l$ hoặc $\varepsilon_s$), được tính toán bằng bất đẳng thức Hoeffding:

\begin{equation}
\varepsilon = \sqrt{\frac{\ln(1/\delta)}{2n}}
\end{equation}

trong đó $\delta$ là mức độ tin cậy và $n$ là kích thước cửa sổ.

Điều kiện phát hiện drift cho FHDDMS:
\begin{equation}
(\mu_{ml} - \mu_{tl} > \varepsilon_l) \vee (\mu_{ms} - \mu_{ts} > \varepsilon_s)
\end{equation}

MDDM là một phương pháp mới được thiết kế để phát hiện nhanh chóng và hiệu quả các concept drift trong luồng dữ liệu đang phát triển. Phương pháp này tận dụng bất đẳng thức McDiarmid, một bất đẳng thức tập trung mạnh mẽ, để phát hiện chính xác những thay đổi đáng kể trong phân phối dữ liệu.

MDDM hoạt động bằng cách trượt một cửa sổ có kích thước cố định $W$ trên kết quả dự đoán (1 cho đúng, 0 cho sai). Một cải tiến quan trọng là việc áp dụng các lược đồ trọng số cho các phần tử trong cửa sổ, gán trọng số cao hơn cho các mục gần đây hơn để nhấn mạnh tầm quan trọng và thúc đẩy phát hiện nhanh hơn.

Thuật toán liên tục tính toán giá trị trung bình có trọng số hiện tại ($\mu_{tw}$) của cửa sổ:
\begin{equation}
\mu_{tw} = \frac{\sum_{i=1}^{W} w_i \cdot x_i}{\sum_{i=1}^{W} w_i}
\end{equation}

và so sánh với giá trị trung bình có trọng số tối đa đã quan sát ($\mu_{mw}$). Sự khác biệt có ý nghĩa thống kê giữa hai giá trị này, được giới hạn bởi bất đẳng thức McDiarmid, báo hiệu sự xuất hiện của concept drift.

Bất đẳng thức McDiarmid được áp dụng như sau:
\begin{equation}
P(|\mu_{tw} - \mathbb{E}[\mu_{tw}]| \geq \varepsilon) \leq 2\exp\left(-\frac{2\varepsilon^2 W^2}{\sum_{i=1}^{W} c_i^2}\right)
\end{equation}

Trong đó $c_i$ là hằng số bounded difference cho biến thứ $i$.

MDDM cung cấp các biến thể dựa trên lược đồ trọng số khác nhau:
\begin{itemize}
    \item \textbf{MDDM-A (Arithmetic):} Sử dụng trọng số tuyến tính: $w_i = i$
    \item \textbf{MDDM-G (Geometric):} Sử dụng trọng số hình học: $w_i = r^{i-1}$ với $r > 1$
    \item \textbf{MDDM-E (Euler):} Sử dụng trọng số Euler: $w_i = e^{(i-1)/c}$ với hằng số $c$
\end{itemize}

Song song, Barros et al. (2017) đề xuất \textbf{RDDM} (\textit{Reactive DDM}), tối ưu thời gian phản ứng bằng cách rút ngắn giai đoạn cảnh báo, giúp phát hiện nhanh các thay đổi đột ngột[13]. Những năm gần đây còn xuất hiện các biến thể hướng đến các tình huống đặc thù: như \textbf{ADDM} (Adaptive DDM) và \textbf{EDDM-CP} (EDDM kết hợp kiểm soát false alarm), \textbf{ACDDM} (Accurate DDM) năm 2020 cải thiện độ chính xác cho cả drift lặp lại[14][15], \textbf{DMDDM} (Diversity-Measure DDM, 2020) tận dụng sự đa dạng của một tập classifier để nhận biết drift[16], hay \textbf{DDM-FPW} (2020) kiểm soát tỷ lệ dương tính giả khi drift trong luồng dữ liệu IoT nhiều nhãn[17]. 

Mục tiêu chung của các cải tiến này là tăng độ nhạy với nhiều loại drift (đột ngột, dần dần, lặp lại), đồng thời giảm báo động giả và phân biệt được nhiễu.
Tóm lại, nhóm phương pháp dựa trên hiệu năng mô hình đã phát triển mạnh từ giữa thập niên 2000 và vẫn đang được mở rộng. Bắt đầu từ DDM như một chuẩn mực nền tảng[6], các nghiên cứu nối tiếp đã dần hoàn thiện nó thành một họ phương pháp đa dạng, cân bằng hơn giữa tốc độ, độ chính xác và độ tin cậy trong môi trường dữ liệu phức tạp[8].


\subsubsection{Các phương pháp học máy truyền thống}
Bên cạnh việc dùng trực tiếp thống kê hoặc sai số mô hình, các nhà nghiên cứu còn phát triển những kỹ thuật phát hiện drift dựa trên mô hình học máy hoặc tổ hợp nhiều mô hình. Những phương pháp này thường có tính “chủ động” hơn: không chỉ chờ hiệu năng giảm mà còn tìm dấu hiệu thay đổi trong cấu trúc dữ liệu hoặc trong phản ứng của nhiều mô hình khác nhau.

Một ví dụ tiêu biểu là \textbf{Paired Learners} của Bach và Maloof (2008)[18]. Phương pháp này sử dụng hai mô hình học song song trên dòng dữ liệu: một mô hình “ổn định” được huấn luyện trên toàn bộ dữ liệu tích lũy (dài hạn), và một mô hình “nhanh” liên tục huấn luyện trên cửa sổ ngắn hạn gần đây. Khi có concept drift, mô hình nhanh sẽ thích nghi sớm và phân phối dự đoán của nó sẽ khác biệt rõ so với mô hình ổn định. Paired Learners theo dõi mức độ bất đồng giữa hai mô hình này: nếu sai khác vượt ngưỡng, ta kết luận đã có drift. Cách tiếp cận này cho phép phát hiện cả drift đột ngột (mô hình nhanh thay đổi tức thời) lẫn drift dần dần (mô hình nhanh dần dần phân kỳ khỏi mô hình cũ). Nghiên cứu cho thấy Paired Learners phát hiện drift khá hiệu quả và thường vượt trội các detector đơn lẻ trong nhiều kịch bản[4].

Một hướng khác là tận dụng \textit{ensemble learning} – sử dụng nhiều mô hình phân loại chạy song song – không chỉ để nâng cao độ chính xác, mà còn để nhận biết concept drift thông qua sự đa dạng. Ví dụ, phương pháp \textbf{ACE} (Adaptive Classifier Ensemble, 2009) duy trì một tập phân loại viên và liên tục đánh giá mỗi mô hình trên luồng dữ liệu. Khi có mô hình suy giảm độ chính xác, nó bị thay thế bởi mô hình mới huấn luyện trên dữ liệu gần đây. Mặc dù ACE tập trung vào thích ứng mô hình, việc mô hình cũ bị loại bỏ chính là dấu hiệu của drift (tức concept cũ không còn phù hợp). Tương tự, \textbf{Learn++.NSE} (Elwell \& Polikar, 2011) mở rộng ý tưởng ensemble bằng cách gán trọng số thời gian cho các classifier theo độ tuổi – classifier mới được thêm vào để học concept mới còn classifier cũ mờ dần. Nếu quan sát chuỗi trọng số hoặc lỗi của ensemble thay đổi đáng kể, ta có thể xác định có drift xảy ra. Nhìn chung, các phương pháp ensemble cho phép "phát hiện" drift một cách gián tiếp thông qua cơ chế tự điều chỉnh: drift được phản ánh khi cấu trúc hoặc thành phần của ensemble thay đổi.

Ngoài ra, nhiều phương pháp học máy khác tập trung vào việc so sánh mô hình hoặc phân cụm giữa hai khoảng thời gian. Một số kỹ thuật huấn luyện mô hình đặc biệt để dự đoán độ khác biệt giữa phân phối dữ liệu hiện tại và quá khứ (hay gọi là concept drift indicators). Ví dụ, người ta có thể huấn luyện một mô hình phân loại nhằm phân biệt “dữ liệu cũ” và “dữ liệu mới”; nếu mô hình này đạt độ chính xác cao nghĩa là hai phân phối khác nhau rõ (drift lớn). Cách làm này biến phát hiện drift thành một bài toán học máy hai lớp (gọi là \textit{classifier-based drift detection}), tuy nhiên cần cẩn trọng với tính ngẫu nhiên. Trong môi trường không có nhãn liên tục, một số phương pháp sử dụng phân cụm hoặc mô hình one-class (như one-class SVM, autoencoder) để mô tả dữ liệu; khi phân cụm thay đổi hình dạng hoặc mô hình one-class tăng lỗi ngoại lệ, đó là dấu hiệu drift (ví dụ \textbf{OCDD} – One-Class Drift Detector).

Nhìn lại lịch sử, nhóm phương pháp dựa trên học máy truyền thống phát triển mạnh khoảng 2008–2015, khi khả năng tính toán cho phép triển khai nhiều mô hình song song. Những phương pháp này tận dụng sức mạnh của ensemble và mô hình meta để phát hiện các thay đổi tinh vi mà các phương pháp đơn lẻ có thể bỏ lỡ. Chúng tạo bước chuyển từ các kỹ thuật thuần thống kê sang các hệ thống linh hoạt, kết hợp chặt chẽ quá trình phát hiện drift với quá trình học liên tục. Đồng thời, các phương pháp này mở đường cho việc tích hợp sâu hơn cơ chế phát hiện drift vào các mô hình phức tạp như mạng neural, mà ta sẽ xét trong nhóm tiếp theo.

\subsubsection{Các phương pháp học sâu}
Trong những năm gần đây (từ khoảng 2015 trở lại đây), với sự bùng nổ của học sâu, bài toán concept drift được nghiên cứu trong bối cảnh các mô hình mạng neural phức tạp. Thách thức đặt ra là các mô hình deep learning thường có hàng triệu tham số và quá trình học phức tạp, làm sao tích hợp hoặc thiết kế bộ phát hiện drift hiệu quả? Các hướng tiếp cận chính bao gồm: (i) tích hợp các detector truyền thống (như đã trình bày ở trên) để giám sát đầu ra hoặc đặc trưng trung gian của mạng deep; (ii) thiết kế kiến trúc mạng hoặc chiến lược huấn luyện có khả năng tự nhận biết drift và điều chỉnh cấu trúc; (iii) sử dụng chính các mô hình deep để trực tiếp phân tích sự thay đổi phân phối trong dữ liệu hoặc trong không gian đặc trưng.

Hướng thứ (i) hiện khá phổ biến do tính đơn giản và hiệu quả: người ta gắn các bộ phát hiện drift cổ điển vào pipeline của mô hình deep. Ví dụ, trong giám sát mô hình CNN phân loại ảnh, ta có thể theo dõi độ bất định (entropy) của phân phối dự đoán; khi entropy tăng đột biến (mô hình trở nên kém chắc chắn), một bộ phát hiện như ADWIN được kích hoạt để dò tìm thay đổi trong chuỗi entropy theo thời gian[19][20]. Jourdan và cộng sự (2023) đã áp dụng thành công cách này để phát hiện drift trong hệ thống giám sát sản xuất công nghiệp: sử dụng ADWIN theo dõi độ lệch xác suất dự đoán của mạng CNN, khi ADWIN báo drift thì hệ thống trigger huấn luyện lại mô hình trên dữ liệu mới[21][19]. Tương tự, trong mô hình phát hiện bất thường dùng LSTM, người ta cũng nhúng các detector như DDM hoặc Page-Hinkley để liên tục canh chừng lỗi dự đoán theo thời gian. Việc tích hợp này lợi dụng được tính chất “model-agnostic” của các thuật toán drift detection truyền thống, biến chúng thành cảm biến cho các mô hình deep phức tạp.

Hướng thứ (ii) tìm cách làm cho bản thân mô hình deep learning “nhạy cảm” với drift và tự cấu hình lại khi cần. Một đại diện tiêu biểu là các mạng nơ-ron tiến hóa theo luồng dữ liệu. Chẳng hạn, \textbf{NADINE} (Pratama et al., 2019) là một mạng MLP nhiều lớp có khả năng tiến hóa cấu trúc: NADINE tích hợp một cơ chế phát hiện drift chủ động, dựa trên thuật toán cửa sổ trượt thích ứng kết hợp bất đẳng thức Hoeffding (tương tự ý tưởng của FHDDM) để liên tục kiểm tra dữ liệu mới[22]. Mỗi khi detector phát hiện tín hiệu drift, NADINE sẽ “tiến hóa” bằng cách thêm hoặc bớt các nút ẩn và tầng ẩn tương ứng, nhằm thích nghi với concept mới[22]. Cơ chế này giúp mạng tự điều chỉnh độ phức tạp (tăng nếu concept mới phức tạp hơn, hoặc giảm nếu cần tránh overfitting) và đã cho thấy hiệu quả trên các bài toán phân loại, hồi quy trong môi trường non-stationary. 

Một phương pháp khác là \textbf{CIDD-ADODNN} (2020) – một kiến trúc deep được thiết kế cho dữ liệu mất cân bằng – cũng sử dụng bộ phát hiện drift ADWIN để chủ động phát hiện thay đổi, sau đó dùng thuật toán tối ưu đặc biệt (Adadelta) để điều chỉnh trọng số mạng cho phù hợp với concept mới[23]. Nhờ chiến lược này, mô hình CIDD-ADODNN cải thiện rõ rệt độ chính xác phân loại trên dòng dữ liệu chứa cả drift đột ngột và dần dần, đồng thời xử lý tốt bài toán dữ liệu lệch lớp[23].

Hướng thứ (iii) khai thác trực tiếp năng lực biểu diễn của mô hình deep để nhận biết drift. Ví dụ, một autoencoder (mạng tự mã hóa) có thể học nén dữ liệu đầu vào; nếu phân phối dữ liệu thay đổi, lỗi tái tạo (reconstruction error) của autoencoder sẽ tăng cao. Dựa trên ý tưởng đó, \textbf{AEDetect} (2021) giám sát phân phối lỗi tái tạo của autoencoder, khi phân phối này dịch chuyển đáng kể thì phát tín hiệu drift. 

Tương tự, trong lĩnh vực chuỗi thời gian, \textbf{LSTM-NDT} (Neural Drift Detector dùng LSTM) được đề xuất để học mô hình chuỗi và dùng sai số dự báo của LSTM làm tiêu chí phát hiện drift. Các phương pháp này thường kết hợp chặt chẽ giữa mô hình dự đoán và mô hình phát hiện, đôi khi hòa trộn làm một. Chúng có ưu điểm tận dụng tối đa thông tin trong dữ liệu (nhờ đặc trưng học được của network), nhưng thách thức ở chỗ việc tách bạch “drift” và “nhiễu” trong nội tại mô hình không dễ dàng, và mô hình phức tạp cũng có nguy cơ phản ứng chậm với thay đổi.

Tổng kết lại, nhóm phương pháp học sâu phản ánh xu hướng hiện đại của lĩnh vực concept drift. Từ khoảng năm 2015 đến nay, chúng ta chứng kiến sự gia tăng các công trình kết hợp giữa deep learning và phát hiện concept drift. Ban đầu, các mô hình deep thường dựa vào các “cảm biến” drift bên ngoài (như ADWIN, DDM) để quyết định khi nào cần tái huấn luyện. Dần dần, các kiến trúc deep thích ứng (như NADINE, DEN, ADL, DEVDAN\ldots) ra đời với khả năng tự điều chỉnh cấu trúc khi drift diễn ra[24][25]. Mặc dù vẫn đang trong giai đoạn phát triển, các phương pháp này hứa hẹn đem lại sự linh hoạt và mạnh mẽ, giúp mô hình học sâu vận hành bền vững trong môi trường dữ liệu luôn biến động.
\begin{table}[h]\centering
\caption{Tóm tắt một số mốc chính trong phát triển phương pháp phát hiện concept drift}\label{tab:drift-history}
\begin{tabular}{|c|l|p{7.5cm}|}
\hline
\textbf{Năm} & \textbf{Phương pháp} & \textbf{Đặc điểm chính} \\
\hline
1996 & FLORA${}^*$ & Cửa sổ trượt thích ứng đầu tiên, xử lý drift bằng chọn bộ nhớ ngắn hạn. \\
\hline
2004 & DDM[6] & Giám sát tỉ lệ lỗi mô hình, đặt ngưỡng cảnh báo và drift theo luật SPC; phát hiện drift đột ngột hiệu quả. \\
\hline
2006 & EDDM[10] & Mở rộng DDM, cải thiện phát hiện drift dần dần bằng cách theo dõi khoảng cách giữa các lỗi. \\
\hline
2007 & ADWIN[3] & Cửa sổ trượt thích ứng với đảm bảo lý thuyết, so sánh thống kê hai cửa sổ con để phát hiện thay đổi phân phối. \\
\hline
2015 & HDDM[11] & Sử dụng bất đẳng thức Hoeffding (phi tham số) để phát hiện drift trên dòng lỗi; giảm giả định phân phối so với DDM. \\
\hline
2016 & FHDDM[12] & Phiên bản nhanh của HDDM, tăng tốc độ và độ nhạy khi drift (đột ngột và dần dần). \\
\hline
2017 & RDDM[13] & Phản ứng nhanh với drift đột ngột, rút ngắn giai đoạn cảnh báo của DDM; phù hợp cả drift lặp lại. \\
\hline
2020 & DAWIDD[26] & Phương pháp phi tham số dùng kiểm định độc lập (independence test) thay vì mô hình dự đoán; linh hoạt với nhiều dạng drift khác nhau. \\
\hline
2019--22 & Học sâu thích ứng & Xuất hiện các mô hình deep learning tích hợp phát hiện drift (NADINE[22], ADL, DEVDAN, CIDD-ADODNN[23]…); mạng tự mở rộng hoặc dùng detector gắn ngoài để duy trì hiệu năng dưới concept drift. \\
\hline
\multicolumn{3}{l}{\footnotesize ${}^*$Ghi chú: FLORA (Widmer \& Kubat, 1996) là hệ thống học không có detector tách rời, sử dụng cửa sổ ngắn hạn để thích ứng concept drift.} \\
\hline
\end{tabular}
\end{table}
Như bảng \ref{tab:drift-history} tóm tắt, lĩnh vực phát hiện trôi dạt khái niệm đã phát triển phong phú qua thời gian. Từ những ý tưởng sơ khai về cửa sổ trượt và loại bỏ mẫu, các nhà nghiên cứu đã tiến tới các thuật toán kiểm định thống kê tinh vi và cơ chế giám sát sai số mô hình. Giai đoạn 2004–2010 chứng kiến các phương pháp nền tảng như DDM, EDDM, ADWIN định hình lĩnh vực. Giai đoạn 2010–2020 là thời kỳ nở rộ với hàng loạt cải tiến và biến thể (HDDM, FHDDM, RDDM, v.v.), cùng với những cách tiếp cận mới dựa trên ensemble và meta-learning. Từ 2020 trở đi, xu hướng tích hợp với học sâu trở nên rõ nét, hướng tới các hệ thống vừa có khả năng học biểu diễn mạnh mẽ vừa linh hoạt thích ứng với dữ liệu biến đổi. Sự kết hợp liên ngành giữa thống kê, học máy và học sâu đang tiếp tục mở ra những chương mới cho bài toán concept drift, hứa hẹn các giải pháp ngày càng hiệu quả và toàn diện hơn trong tương lai.
% ________________________________________
% [1] PageHinkley - River
% https://riverml.xyz/dev/api/drift/PageHinkley/
% [2] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] Evolving Strategies in Machine Learning: A Systematic Review of Concept Drift Detection
% https://www.mdpi.com/2078-2489/15/12/786
% [3] ADWIN - River
% https://riverml.xyz/dev/api/drift/ADWIN/
% [19] [20] [21] [Paper] - Model Adaptation - Handling concept drift in deep learning applications for process monitoring.pdf
% file://file-JW6dMZ49D5Rdyy9TiUAxaM
% [22] [23] [Paper] - Model Adaptation - Concept Drift Adaptation Methods under the Deep Learning Framework A Literature Review.pdf
% file://file-D5msT7u3GLEByn7AErXZAZ
% [24] [25] [Paper] - Model Adaptation - Recent Advances in Concept Drift Adaptation Methods for Deep Learning.pdf
% file://file-U3E54GM9N3didgEzPW9ubH
% [26] Towards Non-Parametric Drift Detection via Dynamic Adapting Window Independence Drift Detection (DAWIDD)
% https://proceedings.mlr.press/v119/hinder20a.html
\section{Xác định loại trôi dạt khái niệm}
\label{sec:drift_type_identification}

\subsection{Tổng quan}
Sau khi phát hiện được thời điểm xảy ra trôi dạt (drift point), bước tiếp theo là
\textbf{xác định loại trôi dạt} (drift type identification).  
Khác với các phương pháp truyền thống chỉ xác định có trôi dạt hay không,
phương pháp \textbf{CDT\_MSW} (Concept Drift Type identification based on Multi-Sliding Windows)
được Guo \textit{et al.}~\cite{guo2022cdtmsw} đề xuất nhằm \emph{phân biệt bản chất và tốc độ thay đổi của quá trình drift}.
Phương pháp này dựa trên việc quan sát hành vi thay đổi của độ chính xác giữa nhiều cửa sổ trượt
(traditional sliding windows và adaptive windows), qua đó nhận dạng các loại drift như:
\emph{sudden}, \emph{gradual}, \emph{incremental}, và \emph{recurrent}.

\subsection{Giai đoạn 1: Phát hiện trôi dạt}
Trong giai đoạn đầu, CDT\_MSW định nghĩa \textbf{tỷ lệ phát hiện} (Detection Flow Ratio)
để đo lường sự thay đổi giữa hai cửa sổ dữ liệu $W_A$ và $W_B$:

\begin{equation}
\tilde{P}^{t}_{\text{det}} = \frac{a^B_t}{a^A_t},
\tag{1}
\end{equation}

trong đó $a^A_t$ và $a^B_t$ là độ chính xác của mô hình trên hai cửa sổ $W_A$ (cửa sổ tham chiếu)
và $W_B$ (cửa sổ hiện tại) tại thời điểm $t$.  
Khi $\tilde{P}^{t}_{\text{det}}$ giảm mạnh (tức là độ chính xác trên $W_B$ suy giảm so với $W_A$),
thuật toán xác định đây là vị trí có khả năng xảy ra trôi dạt.  
Điểm phát hiện được ký hiệu là $t_d$.

\subsection{Giai đoạn 2: Đo độ dài trôi dạt}
Sau khi xác định được vị trí $t_d$, thuật toán tiếp tục \textbf{mở rộng vùng quan sát}
để ước lượng độ dài của vùng thay đổi.  
Gọi $t_{\text{start}}$ và $t_{\text{end}}$ lần lượt là điểm bắt đầu và kết thúc của vùng trôi dạt,
thì \textbf{độ dài trôi dạt} (drift length) được tính bởi:

\begin{equation}
L_d = t_{\text{end}} - t_{\text{start}}.
\label{eq:drift_length}
\end{equation}

Nếu $L_d < \lambda$ (với $\lambda$ là ngưỡng định trước), quá trình thay đổi được xem là
\textbf{sudden drift}; ngược lại, nếu $L_d \ge \lambda$, đó là \textbf{progressive drift}
(có thể là gradual hoặc incremental).

Độ chính xác của việc ước lượng vùng drift được đánh giá bằng hai chỉ số~\cite{guo2022cdtmsw}:
\textbf{LOR (Length Overflow Rate)} và \textbf{LRR (Length Recall Rate)}:

\begin{align}
\text{LOR} &=
\frac{\sum_{t_i,\, d \in \text{Length}_i} \text{LOR}_i}{|\{t_i \mid d \in \text{Length}_i\}|},
\quad
\text{LOR}_i = 
\frac{\max\{\min_{e \in \text{BufE}_i}((d+m)-e),\,0\}}{m}, \tag{11–12} \\[0.5em]
\text{LRR} &= 1 - \text{LLR}. \tag{13}
\end{align}

Hai chỉ số này đo độ khớp giữa vùng drift thật và vùng được phát hiện:  
LOR càng nhỏ và LRR càng cao $\Rightarrow$ vùng phát hiện càng chính xác.

\subsection{Giai đoạn 3: Theo dõi và nhận dạng loại drift}
Để phân biệt chi tiết giữa các loại trôi dạt tiến triển, CDT\_MSW định nghĩa
\textbf{tỷ lệ theo dõi} (Tracking Flow Ratio – TFR):

\begin{equation}
\tilde{P}^{i}_{\text{tra}} = \frac{a^{*}_{B_0}}{a^{i}_{A_0}},
\tag{5}
\end{equation}

trong đó:
\begin{itemize}
  \item $a^{*}_{B_0}$: độ chính xác của mô hình huấn luyện trên cửa sổ $W'_B$ tại vị trí ban đầu;
  \item $a^{i}_{A_0}$: độ chính xác của mô hình trên cửa sổ $W'_A$ khi trượt đến vị trí $i$.
\end{itemize}
Dãy $\tilde{P}^{i}_{\text{tra}}$ được tổng hợp thành đường cong TFR,
thể hiện hình dạng và tốc độ thay đổi của khái niệm.  
Đường cong này dùng để phân biệt các loại drift cụ thể:
\begin{itemize}
  \item \textbf{Sudden drift:} $\tilde{P}_{\text{tra}}$ giảm đột ngột, không có giai đoạn chuyển tiếp.
  \item \textbf{Gradual drift:} $\tilde{P}_{\text{tra}}$ dao động nhẹ rồi ổn định.
  \item \textbf{Incremental drift:} $\tilde{P}_{\text{tra}}$ thay đổi tuyến tính theo thời gian.
  \item \textbf{Recurrent drift:} $\tilde{P}_{\text{tra}}$ có dạng chu kỳ lặp lại.
\end{itemize}

\subsection{Đánh giá khả năng nhận dạng loại trôi dạt}
Khả năng phân loại chính xác các loại trôi dạt được đánh giá bằng hai chỉ số~\cite{guo2022cdtmsw}:
\textbf{ACC\textsubscript{cat}} và \textbf{ACC\textsubscript{subcat}},
tương ứng với độ chính xác nhận dạng loại chính (TCD) và loại phụ (PCD):

\begin{align}
\text{ACC}_{\text{cat}} &=
\frac{TT + TP}{TT + FT + TP + FP}, \tag{14} \\[0.5em]
\text{ACC}_{\text{subcat}} &=
\frac{\sum_i T^T_i + \sum_j T^P_j}{TT + TP}. \tag{15}
\end{align}

Trong đó:
\begin{itemize}
  \item $TT$, $FT$: số lượng nhận dạng đúng/sai cho loại trôi dạt chính (TCD);
  \item $TP$, $FP$: số lượng nhận dạng đúng/sai cho loại phụ (PCD);
  \item $T^T_i$, $T^P_j$: số lần nhận dạng đúng từng tiểu loại (sudden, gradual, incremental, recurrent).
\end{itemize}

\subsection{Tổng hợp và ý nghĩa}
Tóm lại, CDT\_MSW nhận dạng loại trôi dạt dựa trên hai chỉ số động:
\textbf{Detection Flow Ratio} (Công thức~1) và \textbf{Tracking Flow Ratio} (Công thức~5),
cùng với các chỉ số đánh giá độ dài và độ chính xác của quá trình phân loại (Công thức~11–15).
Cơ chế này cho phép mô hình không chỉ phát hiện thời điểm drift xảy ra,
mà còn hiểu được bản chất của sự thay đổi (nhanh, chậm, tuyến tính hay lặp lại),
từ đó cung cấp thông tin đầu vào quan trọng cho
\textbf{giai đoạn cập nhật mô hình thích ứng} được trình bày trong Mục~\ref{sec:model_adaptation_strategies}.

\section{Các chiến lược cập nhật mô hình thích ứng}
\label{sec:model_adaptation_strategies}

\subsection{Tổng quan}
Trong các hệ thống học trực tuyến (online learning systems), việc phát hiện trôi dạt khái niệm
(concept drift detection) chỉ là bước đầu tiên; điều quan trọng hơn là cách \textbf{mô hình thích ứng}
(model adaptation) được cập nhật sau khi trôi dạt xảy ra.
Các chiến lược cập nhật mô hình nhằm mục tiêu duy trì độ chính xác, ổn định và tránh hiện tượng quên ngắn hạn (catastrophic forgetting)
trong quá trình học liên tục.

Theo Guo \textit{et al.}~\cite{guo2022cdtmsw}, thông tin về loại trôi dạt (drift type) do phương pháp
CDT\_MSW cung cấp đóng vai trò quan trọng để lựa chọn cơ chế cập nhật phù hợp.
Ngoài ra, các nghiên cứu gần đây~\cite{jourdan2023process}
đã mở rộng khung thích ứng này sang các hệ thống học sâu (deep learning systems),
trong đó chiến lược cập nhật không chỉ phụ thuộc vào loại trôi dạt mà còn vào cấu trúc mô hình, mức độ sẵn có của nhãn, và chi phí tính toán.

\subsection{Phân loại chiến lược cập nhật}
Tổng hợp từ các tài liệu trên, có thể chia các chiến lược cập nhật mô hình thành bốn nhóm chính:

\begin{enumerate}[label=\textbf{(\alph*)}]
  \item \textbf{Cập nhật cục bộ (Local Reset / Fine-tuning):}
  Áp dụng khi xảy ra \emph{sudden drift}, tức là phân phối dữ liệu thay đổi mạnh trong thời gian ngắn.
  Mô hình được tái huấn luyện một phần hoặc toàn bộ trên cửa sổ dữ liệu mới.
  Phương pháp này phù hợp với các bộ phát hiện trôi dạt dựa trên cửa sổ như ADWIN hoặc CDT\_MSW,
  khi $L_d < \lambda$ (độ dài trôi dạt ngắn).
  Ví dụ, trong hệ thống giám sát quá trình sản xuất (process monitoring),
  Jourdan \textit{et al.}~\cite{jourdan2023process} thực hiện \emph{partial reinitialization}
  của các tầng cuối trong mạng nơ-ron khi độ bất định (uncertainty) vượt ngưỡng.

  \item \textbf{Cập nhật dần (Gradual / Incremental Update):}
  Khi mô hình gặp \emph{gradual} hoặc \emph{incremental drift},
  sự thay đổi xảy ra từ từ, cần cập nhật mềm với hệ số học $\eta_t$ nhỏ hơn.
  Theo Xiang \textit{et al.}, có thể mô hình hoá bằng công thức:
  \[
  \theta_{t+1} = \theta_t - \eta_t \nabla_\theta \mathcal{L}(x_t, y_t),
  \quad \text{với } \eta_t = f(L_d, r_t),
  \]
  trong đó $L_d$ là độ dài trôi dạt, $r_t$ là tốc độ thay đổi.
  Khi $r_t$ tăng đều, $\eta_t$ được tăng dần để theo kịp xu hướng dữ liệu mới.
  Các kỹ thuật như \emph{online fine-tuning}, \emph{stochastic gradient with forgetting factor}
  hoặc \emph{momentum adaptation} thường được sử dụng trong nhóm này.

  \item \textbf{Cập nhật theo ngữ cảnh (Recurrent / Memory-based Adaptation):}
  Đối với \emph{recurrent drift}, khi khái niệm cũ tái xuất hiện theo chu kỳ, mô hình nên duy trì
  một \emph{bộ nhớ khái niệm} (concept repository).
  Cách tiếp cận phổ biến là lưu trữ các snapshot $\{M_i\}$ tương ứng với từng khái niệm,
  và lựa chọn mô hình phù hợp nhất khi phân phối dữ liệu hiện tại $P_t(x)$
  tương tự với một snapshot trước đó:
  \[
  M^* = \arg\min_{M_i} \text{Dist}(P_t(x), P_{M_i}(x)).
  \]
  Phương pháp này được áp dụng trong các framework học sâu có bộ nhớ động như
  Deep Ensemble Replay hoặc Continual Learning with Experience Buffer.

  \item \textbf{Cập nhật cấu trúc (Structural or Hybrid Adaptation):}
  Một số nghiên cứu gần đây
  đề xuất không chỉ điều chỉnh tham số, mà còn thay đổi \emph{cấu trúc mạng học sâu} khi có drift.
  Ví dụ, thêm tầng mới hoặc nhánh mới để học khái niệm mới mà không làm mất kiến thức cũ,
  biểu diễn bởi:
  \[
  \mathcal{M}_{t+1} = \mathcal{M}_t \cup \Delta \mathcal{M},
  \]
  trong đó $\Delta \mathcal{M}$ là tập các node hoặc layer mới được thêm.
  Phương pháp này hữu ích với các trôi dạt dài hạn (progressive drift) hoặc trôi dạt phức hợp (hybrid drift).
\end{enumerate}

\subsection{Bảng tổng hợp}
\begin{table}[H]
\centering
\caption{Mối quan hệ giữa loại trôi dạt và chiến lược cập nhật mô hình thích ứng}
\label{tab:model_update_strategies}
\begin{tabular}{p{3cm}p{9.5cm}}
\toprule
\textbf{Loại trôi dạt} & \textbf{Chiến lược cập nhật đề xuất} \\
\midrule
\textbf{Sudden drift} &
Tái huấn luyện nhanh (local reset), bỏ dữ liệu cũ; tăng $\eta_t$; phù hợp với incremental retraining, ADWIN, CDT\_MSW. \\[0.4em]
\textbf{Gradual drift} &
Cập nhật mềm (soft update), giảm hệ số học; áp dụng momentum nhỏ hoặc sliding window dài. \\[0.4em]
\textbf{Incremental drift} &
Cập nhật liên tục (continuous adaptation), sử dụng gradient online và drift-aware scheduler. \\[0.4em]
\textbf{Recurrent drift} &
Duy trì bộ nhớ khái niệm; lựa chọn mô hình tương tự (ensemble selection / memory replay). \\[0.4em]
\textbf{Progressive drift} &
Thay đổi cấu trúc mô hình (dynamic architecture), hoặc học chuyển giao (transfer learning) giữa các giai đoạn. \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Nhận xét tổng hợp}
Từ các kết quả trên có thể rút ra ba quan sát chính:
\begin{enumerate}
  \item Việc xác định đúng loại trôi dạt giúp chọn chiến lược thích ứng hiệu quả, tránh huấn luyện lại toàn bộ.
  \item Các phương pháp học sâu hiện đại hướng đến \emph{cập nhật kết hợp} (hybrid adaptation),
  vừa tinh chỉnh trọng số, vừa thay đổi cấu trúc mạng để xử lý trôi dạt dài hạn.
  \item Các chỉ số định lượng như độ dài trôi dạt $L_d$ và tốc độ thay đổi $r_t$ của CDT\_MSW
  có thể được dùng để điều chỉnh động learning rate hoặc quyết định chiến lược chuyển mô hình (switching strategy).
\end{enumerate}

\subsection{Kết luận}
Tóm lại, chiến lược cập nhật mô hình thích ứng đóng vai trò cầu nối giữa phát hiện trôi dạt và duy trì hiệu năng hệ thống.
Các phương pháp hiện đại kết hợp cả thông tin thống kê từ bộ phát hiện trôi dạt như CDT\_MSW
và đặc trưng động của mô hình học sâu, cho phép \textbf{thích ứng chính xác theo từng loại trôi dạt},
giảm thiểu hiện tượng quên kiến thức cũ và cải thiện độ bền vững của hệ thống học trực tuyến.
