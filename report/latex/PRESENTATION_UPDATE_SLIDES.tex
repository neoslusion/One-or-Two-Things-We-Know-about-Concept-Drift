% ==============================================================================
% NEW SLIDES TO ADD TO presentation.tex
% Replace the old results section (around line 522-606) with these updated slides
% ==============================================================================

\begin{frame}{K·∫øt qu·∫£: Comprehensive Benchmark (18 methods √ó 8 datasets)}
  \begin{table}
    \centering
    \footnotesize
    \begin{tabular}{lccc}
      \toprule
      \textbf{Method} & \textbf{F1-Score} & \textbf{Std} & \textbf{Rank} \\
      \midrule
      ShapeDD\_Adaptive\_None & 0.571 & 0.286 & 1/18 \\
      \textbf{ShapeDD\_SNR\_Adaptive} & \textbf{0.562} & \textbf{0.254} & \textbf{2/18} \\
      ShapeDD\_Adaptive\_v2\_None & 0.557 & 0.281 & 3/18 \\
      ShapeDD (Original) & 0.544 & 0.224 & 4/18 \\
      DAWIDD & 0.515 & 0.132 & 5/18 \\
      ADWIN & 0.507 & 0.345 & 6/18 \\
      MMD & 0.500 & 0.195 & 7/18 \\
      \midrule
      \multicolumn{4}{l}{\textit{(11 ph∆∞∆°ng ph√°p kh√°c c√≥ F1 < 0.50)}} \\
      \bottomrule
    \end{tabular}
  \end{table}

  \vspace{0.5em}
  \begin{block}{ƒêi·ªÉm n·ªïi b·∫≠t}
    \begin{itemize}
      \item \textbf{SNR-Adaptive x·∫øp h·∫°ng 2/18} - ph∆∞∆°ng ph√°p hybrid ƒë·∫ßu ti√™n s·ª≠ d·ª•ng SNR
      \item Std = 0.254 th·∫•p h∆°n c√°c adaptive methods kh√°c (0.286, 0.281)
      \item T·ªïng h·ª£p t·ªët tr√™n nhi·ªÅu lo·∫°i drift kh√°c nhau
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}{Ki·∫øn tr√∫c SNR-Adaptive Method}
  \begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{image/snr_adaptive_architecture.png}
    \caption{H·ªá th·ªëng SNR-Adaptive t·ª± ƒë·ªông l·ª±a ch·ªçn strategy (aggressive/conservative) d·ª±a tr√™n SNR}
  \end{figure}
\end{frame}

\begin{frame}{K·∫øt qu·∫£: Performance Comparison Top 10}
  \begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{image/f1_comparison.png}
    \caption{So s√°nh F1-score c·ªßa top 10 methods. SNR-Adaptive x·∫øp h·∫°ng 2/18.}
  \end{figure}
\end{frame}

\begin{frame}{K·∫øt qu·∫£: Strategy Selection Distribution}
  \begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{image/strategy_selection.png}
    \caption{Ph√¢n b·ªë l·ª±a ch·ªçn strategy: 58.7\% aggressive, 41.3\% conservative (g·∫ßn 50/50 theo Neyman-Pearson optimization)}
  \end{figure}
\end{frame}

\begin{frame}{K·∫øt qu·∫£: Per-Dataset Performance (Best Cases)}
  \textbf{TOP TIER (F1 > 0.70):}

  \begin{table}
    \centering
    \small
    \begin{tabular}{lcccl}
      \toprule
      \textbf{Dataset} & \textbf{F1} & \textbf{Recall} & \textbf{MTTD} & \textbf{K·∫øt qu·∫£} \\
      \midrule
      stagger & \textbf{0.833} & 1.0 & 4.8 & G·∫ßn h·∫°ng 1 (+0.036) \\
      enhanced\_sea & \textbf{0.818} & 0.9 & 7.6 & M·∫°nh (+0.134) \\
      gen\_random\_severe & \textbf{0.727} & 0.8 & 14.5 & \textcolor{red}{\textbf{H·∫°ng 1 (tie)}} \\
      \bottomrule
    \end{tabular}
  \end{table}

  \vspace{0.5em}
  \begin{block}{Ph√¢n t√≠ch}
    \begin{itemize}
      \item \textbf{ƒê·∫°t h·∫°ng 1 (tie)} tr√™n gen\_random\_severe ‚Üí x√°c nh·∫≠n thi·∫øt k·∫ø
      \item \textbf{G·∫ßn h·∫°ng 1} tr√™n stagger (gap ch·ªâ 3.6\%)
      \item \textbf{Perfect recall} (1.0) tr√™n stagger ‚Üí ph√°t hi·ªán t·∫•t c·∫£ 10 drifts
      \item Hi·ªáu qu·∫£ tr√™n \textbf{high-SNR drifts} (c∆∞·ªùng ƒë·ªô cao)
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}{K·∫øt qu·∫£: Per-Dataset Performance (Worst Cases)}
  \textbf{BOTTOM TIER (F1 < 0.30):}

  \begin{table}
    \centering
    \small
    \begin{tabular}{lcccl}
      \toprule
      \textbf{Dataset} & \textbf{F1} & \textbf{Recall} & \textbf{MTTD} & \textbf{Gap to Winner} \\
      \midrule
      hyperplane & 0.267 & 0.2 & 43.0 & +0.289 \\
      standard\_sea & \textcolor{red}{\textbf{0.143}} & 0.1 & 145.0 & +0.429 \\
      \bottomrule
    \end{tabular}
  \end{table}

  \vspace{0.5em}
  \begin{alertblock}{Nguy√™n nh√¢n v√† gi·∫£i th√≠ch}
    \begin{itemize}
      \item \textbf{standard\_sea:} Subtle drift + buffer dilution ‚Üí SNR qu√° th·∫•p
      \begin{itemize}
        \item Ch·ªâ ph√°t hi·ªán 1/10 drifts (10\% recall)
        \item ADWIN (streaming) t·ªët h∆°n 42.9\% (F1=0.571)
      \end{itemize}
      \item \textbf{hyperplane:} Gradual rotation ‚Üí window-based detector kh√≥ ph√°t hi·ªán
      \item \textbf{K·∫øt lu·∫≠n:} Buffer-based approach kh√¥ng ph√π h·ª£p v·ªõi subtle gradual drifts
    \end{itemize}
  \end{alertblock}
\end{frame}

\begin{frame}{Ph√¢n t√≠ch: Performance by Drift Intensity}
  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \textbf{Xu h∆∞·ªõng quan s√°t:}
      \begin{itemize}
        \item \textbf{High} (intensity $\geq$ 1.0):\\
        F1 = 0.667-0.727 ‚úÖ
        \item \textbf{Medium} (0.25-1.0):\\
        F1 = 0.455-0.583 ‚ö†Ô∏è
        \item \textbf{Low} (intensity $\leq$ 0.25):\\
        F1 = 0.143-0.455 ‚ùå
      \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
      \textbf{Gi·∫£i th√≠ch:}
      \begin{itemize}
        \item High intensity ‚Üí high SNR ‚Üí aggressive strategy ‚Üí detection t·ªët
        \item Low intensity ‚Üí low SNR ‚Üí conservative strategy ‚Üí missed detections
        \item Buffer dilution: observed SNR $\sim$ 100√ó th·∫•p h∆°n theoretical SNR
      \end{itemize}
    \end{column}
  \end{columns}

  \vspace{1em}
  \begin{block}{Threshold Optimization}
    Threshold t·ªëi ∆∞u = 0.010 (qua Neyman-Pearson criterion)\\
    C√¢n b·∫±ng precision-recall t·∫°i strategy balance $\sim$ 50/50
  \end{block}
\end{frame}

\begin{frame}{Buffer Dilution Effect}
  \begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{image/buffer_dilution.png}
    \caption{Buffer dilution l√†m gi·∫£m observed SNR kho·∫£ng 100√ó so v·ªõi theoretical SNR}
  \end{figure}

  \vspace{0.5em}
  \textbf{Gi·∫£i th√≠ch:}
  \begin{itemize}
    \item Rolling buffer (750 samples) ch·ª©a c·∫£ stable data v√† drift data
    \item Stable: 90\%, Drift: 10\% ‚Üí dilution ratio = 9:1
    \item Observed SNR = 0.005-0.020 (so v·ªõi theoretical 0.4-4.0)
    \item \textbf{H·ªá qu·∫£:} C·∫ßn recalibrate threshold t·ª´ l√Ω thuy·∫øt sang th·ª±c nghi·ªám
  \end{itemize}
\end{frame}

\begin{frame}{Threshold Sensitivity Analysis}
  \begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{image/threshold_sensitivity.png}
    \caption{Ph√¢n t√≠ch ƒë·ªô nh·∫°y c·ªßa SNR threshold. Optimal = 0.010 c√¢n b·∫±ng precision-recall.}
  \end{figure}
\end{frame}

\begin{frame}{So s√°nh v·ªõi Baseline Methods}
  \begin{table}
    \centering
    \footnotesize
    \begin{tabular}{lccl}
      \toprule
      \textbf{Strategy} & \textbf{F1} & \textbf{Std} & \textbf{ƒê·∫∑c ƒëi·ªÉm} \\
      \midrule
      Adaptive\_None (conservative) & 0.571 & 0.286 & Chi·∫øn l∆∞·ª£c ƒë∆°n \\
      \textbf{SNR-Adaptive (hybrid)} & \textbf{0.562} & \textbf{0.254} & \textbf{Auto-selection} \\
      ShapeDD (original) & 0.544 & 0.224 & Baseline \\
      Adaptive\_v2\_High (aggressive) & 0.464 & 0.292 & Chi·∫øn l∆∞·ª£c ƒë∆°n \\
      \bottomrule
    \end{tabular}
  \end{table}

  \vspace{0.5em}
  \begin{block}{Nh·∫≠n x√©t}
    \begin{itemize}
      \item SNR-Adaptive x·∫øp h·∫°ng 2, cao h∆°n ShapeDD g·ªëc (rank 4)
      \item Std th·∫•p h∆°n conservative methods ‚Üí ·ªïn ƒë·ªãnh h∆°n
      \item Hybrid approach gi√∫p t·ªïng qu√°t h√≥a t·ªët h∆°n pure strategies
      \item Trade-off: Kh√¥ng th·∫Øng tr√™n nhi·ªÅu datasets, nh∆∞ng kh√¥ng bao gi·ªù th·∫•t b·∫°i ho√†n to√†n (tr·ª´ 2 outliers)
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}{Method Ranking Visualization}
  \begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{image/method_ranking.png}
    \caption{B·∫£ng x·∫øp h·∫°ng 18 methods. SNR-Adaptive rank 2/18 v·ªõi F1=0.562.}
  \end{figure}
\end{frame}

\begin{frame}{Optimization Comparison (v1 vs v2)}
  \begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{image/optimization_comparison.png}
    \caption{So s√°nh parameter optimization. Version 2 s·ª≠a inverted threshold bug, c·∫£i thi·ªán hi·ªáu su·∫•t.}
  \end{figure}
\end{frame}

\begin{frame}{Gap Analysis: Distance to Winners}
  \textbf{Kho·∫£ng c√°ch so v·ªõi method t·ªët nh·∫•t m·ªói dataset:}

  \begin{columns}[T]
    \begin{column}{0.5\textwidth}
      \textbf{Excellent gaps ($<$ 0.10):}
      \begin{itemize}
        \item gen\_random\_severe: \textbf{0.000} ‚ú®
        \item stagger: 0.036 ‚ú®
        \item gen\_random\_moderate: 0.083 ‚úÖ
        \item gen\_random\_ultra\_severe: 0.070 ‚úÖ
      \end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}
      \textbf{Large gaps ($>$ 0.20):}
      \begin{itemize}
        \item hyperplane: 0.289 üî¥
        \item standard\_sea: 0.429 üî¥
      \end{itemize}

      \vspace{1em}
      \textbf{Average gap:} 0.153\\
      (15.3\% k√©m h∆°n winner trung b√¨nh)
    \end{column}
  \end{columns}

  \vspace{1em}
  \begin{block}{K·∫øt lu·∫≠n}
    Competitive tr√™n 6/8 datasets (75\%), th·∫•t b·∫°i tr√™n 2 outliers
  \end{block}
\end{frame}

\begin{frame}{ƒê√≥ng g√≥p nghi√™n c·ª©u}
  \begin{enumerate}
    \item \textbf{Ph∆∞∆°ng ph√°p hybrid ƒë·∫ßu ti√™n} s·ª≠ d·ª•ng SNR ƒë·ªÉ auto-select strategy
    \begin{itemize}
      \item Aggressive khi SNR > 0.010
      \item Conservative khi SNR $\leq$ 0.010
      \item Strategy balance $\sim$ 50/50 theo Neyman-Pearson criterion
    \end{itemize}

    \item \textbf{Ch·ª©ng minh buffer dilution effect}
    \begin{itemize}
      \item Observed SNR $\sim$ 100√ó th·∫•p h∆°n theoretical
      \item C·∫ßn recalibrate threshold: 0.4-4.0 ‚Üí 0.010
    \end{itemize}

    \item \textbf{ƒê√°nh gi√° to√†n di·ªán}
    \begin{itemize}
      \item 18 competing methods
      \item 8 diverse datasets (sudden, gradual, high/low intensity)
      \item Per-dataset analysis ‚Üí ƒëi·ªÉm m·∫°nh/y·∫øu r√µ r√†ng
    \end{itemize}

    \item \textbf{ƒê·∫°t rank 2/18} v·ªõi F1=0.562
    \begin{itemize}
      \item Ties 1st tr√™n gen\_random\_severe
      \item Near-win tr√™n stagger (gap = 0.036)
    \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}{H·∫°n ch·∫ø v√† h∆∞·ªõng ph√°t tri·ªÉn}
  \textbf{H·∫°n ch·∫ø ƒë√£ ph√°t hi·ªán:}
  \begin{itemize}
    \item \textbf{Buffer dilution:} Gi·∫£m SNR $\sim$ 100√ó, ·∫£nh h∆∞·ªüng subtle drift detection
    \item \textbf{Gradual drift:} Window-based approach kh√≥ ph√°t hi·ªán continuous changes
    \item \textbf{Subtle drift:} Th·∫•t b·∫°i tr√™n standard\_sea (F1 = 0.143)
    \item \textbf{High variance:} Std = 0.254 (performance dao ƒë·ªông theo drift type)
  \end{itemize}

  \vspace{1em}
  \textbf{H∆∞·ªõng ph√°t tri·ªÉn:}
  \begin{enumerate}
    \item \textbf{Adaptive threshold:} ƒêi·ªÅu ch·ªânh threshold theo dataset characteristics
    \item \textbf{Hybrid buffer:} K·∫øt h·ª£p buffer-based v√† streaming approaches
    \item \textbf{Multi-scale SNR:} ∆Ø·ªõc l∆∞·ª£ng SNR ·ªü nhi·ªÅu time scales kh√°c nhau
    \item \textbf{Gradual drift detection:} Th√™m module ph√°t hi·ªán slow drifts
    \item \textbf{Real-world validation:} Test tr√™n Electricity, Weather, sensor data
  \end{enumerate}
\end{frame}

\begin{frame}{Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng}
  \begin{block}{N√™n s·ª≠ d·ª•ng SNR-Adaptive khi:}
    \begin{itemize}
      \item \textbf{Abrupt drifts} v·ªõi c∆∞·ªùng ƒë·ªô cao (intensity $\geq$ 1.0)
      \item \textbf{Concept-based drifts} v·ªõi concept shifts r√µ r√†ng
      \item \textbf{C·∫ßn t·ªïng qu√°t h√≥a} tr√™n nhi·ªÅu lo·∫°i drift kh√°c nhau
      \item \textbf{C√≥ t√†i nguy√™n} t√≠nh to√°n (buffer storage, permutation tests)
    \end{itemize}
  \end{block}

  \vspace{0.5em}
  \begin{alertblock}{Kh√¥ng n√™n s·ª≠ d·ª•ng khi:}
    \begin{itemize}
      \item \textbf{Subtle gradual drifts} (intensity $\leq$ 0.25) ‚Üí Ch·ªçn ADWIN ho·∫∑c MMD
      \item \textbf{Continuous rotation} (hyperplane-like) ‚Üí Ch·ªçn HDDM\_W
      \item \textbf{Real-time constraints} r·∫•t ch·∫∑t ‚Üí Ch·ªçn ADWIN (5√ó faster)
      \item \textbf{Memory constraints} ‚Üí Ch·ªçn streaming methods (DDM, EDDM)
    \end{itemize}
  \end{alertblock}
\end{frame}
