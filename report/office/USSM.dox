In the challenging landscape of data stream mining, particularly when faced with the issues of concept drift and label scarcity, Ud Din et al. introduce a new online semi-supervised learning algorithm that models concept drifts using a dynamically maintained set of micro-clusters. This approach, implicitly named USSM (based on the paper's filename), seeks to provide a reliable and efficient solution for learning from evolving data streams under common computational constraints such as limited memory and time. The core idea revolves around abstracting incoming streaming data into a compact form of micro-clusters, which effectively preserve the intrinsic data structure and local class distribution. Each micro-cluster is characterized by features such as linear and squared sums of data points, total count, reliability, update time, label, and radius. The algorithm introduces an error-based representative learning mechanism for reliability modeling: when a labeled instance is processed, the reliability (W) of its neighboring micro-clusters is adjusted (increased for consistent predictions, decreased for inconsistent ones).

To ensure adaptation to evolving concepts and forget outdated information, USSM incorporates an exponential decay function that gradually reduces the reliability of micro-clusters over time. Micro-clusters with sufficiently low or negative reliability are consequently eliminated from the model, enabling rapid adaptation to local concept drifts. New instances are either merged into the nearest existing micro-cluster (if within its radius and label-consistent) or a new micro-cluster is created. To maintain memory limits, if the model reaches its maximum capacity (maxMC), the algorithm merges the two closest micro-clusters to create space for new ones. For classification, USSM employs an ensemble of Î“ x k-NN classifiers, where the best-performing classifier (based on average accuracy on recent examples) is dynamically selected for prediction, ensuring robust classification performance. Experimental results demonstrate USSM's superior classification performance against both state-of-the-art semi-supervised (e.g., ReSSL, SPASC, TLP) and supervised learning algorithms on a wide range of real-world and synthetic datasets. Notably, USSM exhibits particularly strong accuracy even with a very small percentage of labeled data (e.g., 1%, 5%, 10%), highlighting its effectiveness in scenarios with label scarcity. The algorithm's efficiency, low memory footprint, and online processing capabilities further underscore its practicality for dynamic data stream applications.
