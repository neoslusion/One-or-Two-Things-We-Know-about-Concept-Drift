The Drift Detection Method (DDM), introduced by Gama et al., provides a fundamental approach to address concept drift in online learning environments where the underlying class-probability distribution of examples can change over time. A central idea in DDM is the concept of a "context," defined as a set of contiguous examples where the data distribution is stationary. The method's core principle is to monitor the online error-rate (p_i) of the learning algorithm. Statistical theory dictates that for a stationary distribution, this error rate should consistently decrease as more examples are processed. Therefore, a significant increase in the error rate signals a change in the class distribution, indicating that the current predictive model may no longer be appropriate. DDM maintains two key registers: p_min and s_min (minimum error rate and its standard deviation, respectively), updating them whenever p_i + s_i is lower than their current minimum sum. To facilitate adaptation, DDM defines two thresholds: a warning level (e.g., p_i + s_i >= p_min + 2*s_min) and a drift level (e.g., p_i + s_i >= p_min + 3*s_min), corresponding to specified confidence levels (e.g., 95% and 99% respectively).

When the error rate sequence reaches the warning level at an example k_w and subsequently the drift level at k_d, DDM declares a new context beginning at k_w and triggers the induction of a new decision model using only the examples from k_w to k_d. Importantly, transient increases in error that return below the warning level are treated as false alarms, preventing unnecessary model revisions. A key strength of DDM is its independence from the specific learning algorithm being used; it can be implemented as a wrapper around batch learners or integrated directly into online/incremental algorithms. The method essentially automates the selection of the most appropriate training set to reflect the current class-distribution. Experimental evaluations across a variety of artificial datasets (simulating abrupt and gradual drift, noise, and irrelevant attributes) and a real-world electricity dataset demonstrated DDM's effectiveness in improving the generalization capacity of diverse learning algorithms, including Perceptrons, Neural Networks, and Decision Trees. Notably, on the Electricity dataset, DDM's 1-day prediction error rate matched the optimal lower bound, showcasing its robust performance in real-world scenarios. Furthermore, DDM proved resilient to false alarms when applied to a stable concept dataset like ADULT.

Phương pháp Phát hiện Trôi dạt (DDM), do Gama và cộng sự giới thiệu, cung cấp một phương pháp tiếp cận cơ bản để giải quyết vấn đề trôi dạt khái niệm trong môi trường học tập trực tuyến, nơi phân phối xác suất lớp cơ bản của các ví dụ có thể thay đổi theo thời gian. Ý tưởng cốt lõi của DDM là khái niệm "bối cảnh", được định nghĩa là một tập hợp các ví dụ liền kề trong đó phân phối dữ liệu là dừng. Nguyên tắc cốt lõi của phương pháp này là theo dõi tỷ lệ lỗi trực tuyến (p_i) của thuật toán học. Lý thuyết thống kê quy định rằng đối với phân phối dừng, tỷ lệ lỗi này phải giảm dần khi xử lý nhiều ví dụ hơn. Do đó, sự gia tăng đáng kể về tỷ lệ lỗi báo hiệu sự thay đổi trong phân phối lớp, cho thấy mô hình dự đoán hiện tại có thể không còn phù hợp. DDM duy trì hai thanh ghi chính: p_min và s_min (lần lượt là tỷ lệ lỗi tối thiểu và độ lệch chuẩn của nó), cập nhật chúng bất cứ khi nào p_i + s_i thấp hơn tổng tối thiểu hiện tại của chúng. Để tạo điều kiện thuận lợi cho việc thích ứng, DDM định nghĩa hai ngưỡng: mức cảnh báo (ví dụ: p_i + s_i >= p_min + 2*s_min) và mức trôi (ví dụ: p_i + s_i >= p_min + 3*s_min), tương ứng với các mức độ tin cậy được chỉ định (ví dụ: lần lượt là 95% và 99%).

Khi chuỗi tỷ lệ lỗi đạt đến mức cảnh báo tại một ví dụ k_w và sau đó đạt đến mức trôi tại k_d, DDM sẽ khai báo một ngữ cảnh mới bắt đầu từ k_w và kích hoạt việc khởi tạo một mô hình quyết định mới chỉ sử dụng các ví dụ từ k_w đến k_d. Điều quan trọng là, sự gia tăng lỗi tạm thời trả về dưới mức cảnh báo được coi là báo động giả, ngăn ngừa việc sửa đổi mô hình không cần thiết. Một điểm mạnh chính của DDM là tính độc lập của nó với thuật toán học cụ thể đang được sử dụng; nó có thể được triển khai như một lớp bao bọc xung quanh các học viên theo lô hoặc được tích hợp trực tiếp vào các thuật toán trực tuyến/gia tăng. Phương pháp này về cơ bản tự động hóa việc lựa chọn tập huấn luyện phù hợp nhất để phản ánh phân phối lớp hiện tại. Các đánh giá thử nghiệm trên nhiều tập dữ liệu nhân tạo (mô phỏng sự trôi đột ngột và dần dần, nhiễu và các thuộc tính không liên quan) và tập dữ liệu điện trong thế giới thực đã chứng minh hiệu quả của DDM trong việc cải thiện khả năng khái quát hóa của nhiều thuật toán học khác nhau, bao gồm Perceptron, Mạng nơ-ron và Cây quyết định. Đáng chú ý, trên tập dữ liệu Điện, tỷ lệ lỗi dự đoán 1 ngày của DDM đã khớp với giới hạn dưới tối ưu, thể hiện hiệu suất mạnh mẽ của nó trong các tình huống thực tế. Hơn nữa, DDM đã chứng minh được khả năng chống chịu với các cảnh báo sai khi áp dụng cho một tập dữ liệu khái niệm ổn định như ADULT.
