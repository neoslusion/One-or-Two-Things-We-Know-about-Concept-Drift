{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drift Detector Evaluation — Report Notebook\n",
    "\n",
    "_VN_: Notebook này **tự động** tạo pipeline, chạy thí nghiệm và tạo bảng/biểu đồ **đủ cho báo cáo**.\n",
    "- Detectors: ADWIN, DDM, EDDM, HDDM_A, HDDM_W, KSWIN, Page-Hinkley (River)\n",
    "- Datasets: SEA (synthetic, có ground-truth drift), Elec2 (real-world), RandomRBFDrift (gradual)\n",
    "- Chỉ số: Accuracy, F1, #alarms, β-score (SEA), delay (samples & %window), **F1@AR**, **Accuracy@AR** + Global scores\n",
    "\n",
    "_EN_: One-click River-based benchmark that outputs report-ready tables and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msubprocess\u001b[39;00m\n\u001b[32m      3\u001b[39m pkgs = [\u001b[33m'\u001b[39m\u001b[33mriver>=0.17\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mpandas>=2.0\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mnumpy>=1.23\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mpyyaml>=6.0\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mpyarrow>=14.0\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mrich>=13.0\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--quiet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mpkgs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mInstalled:\u001b[39m\u001b[33m'\u001b[39m, pkgs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:408\u001b[39m, in \u001b[36mcheck_call\u001b[39m\u001b[34m(*popenargs, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_call\u001b[39m(*popenargs, **kwargs):\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[33;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[33;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    406\u001b[39m \u001b[33;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     retcode = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[32m    410\u001b[39m         cmd = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:391\u001b[39m, in \u001b[36mcall\u001b[39m\u001b[34m(timeout, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[32m    393\u001b[39m         p.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2053\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2053\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2056\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2011\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2009\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2010\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2011\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2013\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2014\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2015\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2016\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 0) Install dependencies (safe to re-run)\n",
    "import sys, subprocess\n",
    "pkgs = ['river>=0.17','pandas>=2.0','numpy>=1.23','pyyaml>=6.0','pyarrow>=14.0','rich>=13.0']\n",
    "subprocess.check_call([sys.executable,'-m','pip','install','--quiet', *pkgs])\n",
    "print('Installed:', pkgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Bootstrap helper package: driftlab/\n",
    "from pathlib import Path\n",
    "import textwrap, os\n",
    "root = Path('driftlab')\n",
    "for p in [root/'src/driftlab', root/'results', root/'configs']: p.mkdir(parents=True, exist_ok=True)\n",
    "(root/'src/__init__.py').write_text('')\n",
    "(root/'src/driftlab/__init__.py').write_text('from . import datasets, detectors, metrics, runner\\n')\n",
    "\n",
    "(root/'src/driftlab/datasets.py').write_text(textwrap.dedent('''\\\n",
    "from __future__ import annotations\n",
    "from typing import Iterator, Dict, Any, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from river import datasets as r_datasets\n",
    "\n",
    "@dataclass\n",
    "class StreamBatch:\n",
    "    x: dict\n",
    "    y: Any\n",
    "    t: int\n",
    "\n",
    "def iter_elec2(limit: Optional[int] = None) -> Iterator[StreamBatch]:\n",
    "    ds = r_datasets.Elec2()\n",
    "    for i,(x,y) in enumerate(ds):\n",
    "        if limit is not None and i >= limit: break\n",
    "        yield StreamBatch(x=x, y=y, t=i+1)\n",
    "\n",
    "def iter_sea(n_samples: int = 100000, drift_positions: List[int] = [30000, 60000], seed: int = 42):\n",
    "    positions = sorted(drift_positions)\n",
    "    segments = [positions[0]] + [positions[i]-positions[i-1] for i in range(1, len(positions))] + [n_samples-positions[-1]]\n",
    "    variants = [0, 1, 2, 3]\n",
    "    t = 0\n",
    "    for seg_len, var in zip(segments, variants):\n",
    "        sea = r_datasets.synth.SEA(variant=var, seed=seed + var)\n",
    "        for (x, y) in sea.take(seg_len):\n",
    "            t += 1\n",
    "            yield StreamBatch(x=x, y=y, t=t)\n",
    "\n",
    "def sea_ground_truth(n_samples: int, drift_positions: List[int]) -> Dict[str, Any]:\n",
    "    positions = sorted(drift_positions)\n",
    "    return {\"drift_times\": positions, \"window_len\": positions[0] if positions else n_samples}\n",
    "\n",
    "def iter_randomrbf(n_samples: int = 100000, speed: float = 0.87, n_centroids: int = 50, seed: int = 42):\n",
    "    gen = r_datasets.synth.RandomRBFDrift(seed_model=seed, seed_sample=seed+1, n_classes=2, n_features=10, n_centroids=n_centroids, change_speed=speed)\n",
    "    for i, (x, y) in enumerate(gen.take(n_samples)):\n",
    "        yield StreamBatch(x=x, y=y, t=i+1)\n",
    "\n",
    "def get_stream(name: str, **kwargs):\n",
    "    name = name.lower()\n",
    "    if name in (\"elec2\",\"electricity\"):\n",
    "        limit = kwargs.get(\"limit\", None)\n",
    "        return iter_elec2(limit=limit), {\"drift_times\": None, \"window_len\": None}\n",
    "    elif name == \"sea\":\n",
    "        n = int(kwargs.get(\"n_samples\", 100000))\n",
    "        drifts = kwargs.get(\"drift_positions\", [30000, 60000])\n",
    "        iterator = iter_sea(n_samples=n, drift_positions=drifts)\n",
    "        gt = sea_ground_truth(n, drifts)\n",
    "        return iterator, gt\n",
    "    elif name in (\"rbf\",\"randomrbf\",\"randomrbfdrift\"):\n",
    "        n = int(kwargs.get(\"n_samples\", 100000))\n",
    "        speed = float(kwargs.get(\"speed\", 0.87))\n",
    "        it = iter_randomrbf(n_samples=n, speed=speed)\n",
    "        return it, {\"drift_times\": None, \"window_len\": None}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {name}\")\n",
    "'''))\n",
    "\n",
    "(root/'src/driftlab/detectors.py').write_text(textwrap.dedent('''\\\n",
    "from river.drift import ADWIN, DDM, EDDM, HDDM_A, HDDM_W, KSWIN, PageHinkley\n",
    "\n",
    "def make_detector(name: str, **kwargs):\n",
    "    n = name.lower()\n",
    "    return {\n",
    "        'adwin': ADWIN, 'ddm': DDM, 'eddm': EDDM,\n",
    "        'hddm_a': HDDM_A, 'hddm_w': HDDM_W, 'kswin': KSWIN,\n",
    "        'pagehinkley': PageHinkley,\n",
    "    }[n](**kwargs)\n",
    "\n",
    "def update_supervised(det, error01: int) -> bool:\n",
    "    det.update(error01)\n",
    "    return bool(det.change_detected)\n",
    "\n",
    "def update_univariate(det, value: float) -> bool:\n",
    "    det.update(value)\n",
    "    return bool(det.change_detected)\n",
    "'''))\n",
    "\n",
    "(root/'src/driftlab/metrics.py').write_text(textwrap.dedent('''\\\n",
    "from __future__ import annotations\n",
    "from typing import List, Optional, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "def match_alarms_to_drifts(alarms: List[int], drifts: List[int], max_delay: Optional[int]=None) -> Dict[str, Any]:\n",
    "    alarms = sorted(alarms); drifts = sorted(drifts)\n",
    "    tp=fp=fn=0; delays=[]; used=set(); j=0\n",
    "    for dt in drifts:\n",
    "        while j < len(alarms) and alarms[j] < dt: j+=1\n",
    "        if j < len(alarms):\n",
    "            d = alarms[j]-dt\n",
    "            if max_delay is None or d <= max_delay:\n",
    "                tp+=1; delays.append(d); used.add(j); j+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "        else:\n",
    "            fn+=1\n",
    "    fp = len([a for idx,a in enumerate(alarms) if idx not in used])\n",
    "    return {\"tp\":tp,\"fp\":fp,\"fn\":fn,\"delays\":delays}\n",
    "\n",
    "def beta_score(tp:int, fp:int, p:int, beta:float=0.5) -> float:\n",
    "    return float('nan') if p<=0 else tp / (p + beta*fp)\n",
    "\n",
    "def delay_stats(delays: List[int]) -> Dict[str,float]:\n",
    "    if not delays: return {\"mean\":float('nan'),\"median\":float('nan'),\"min\":float('nan'),\"max\":float('nan')}\n",
    "    arr = np.array(delays, dtype=float)\n",
    "    return {\"mean\":float(arr.mean()), \"median\":float(np.median(arr)), \"min\":float(arr.min()), \"max\":float(arr.max())}\n",
    "'''))\n",
    "\n",
    "(root/'src/driftlab/runner.py').write_text(textwrap.dedent('''\\\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Optional\n",
    "import math\n",
    "from river import tree, metrics as r_metrics\n",
    "from .datasets import get_stream\n",
    "from .detectors import make_detector, update_supervised, update_univariate\n",
    "from .metrics import match_alarms_to_drifts, beta_score, delay_stats\n",
    "\n",
    "@dataclass\n",
    "class RunConfig:\n",
    "    dataset: str\n",
    "    detector: str\n",
    "    classifier: str = 'HT'\n",
    "    n_samples: int = 100000\n",
    "    sea_drifts: Optional[List[int]] = None\n",
    "    rbf_speed: float = 0.87\n",
    "    seed: int = 42\n",
    "    max_delay: Optional[int] = None\n",
    "    beta: float = 0.5\n",
    "\n",
    "def make_classifier(name:str):\n",
    "    return tree.HoeffdingTreeClassifier()\n",
    "\n",
    "def run_once(cfg: RunConfig) -> Dict[str, Any]:\n",
    "    if cfg.dataset.lower()=='sea':\n",
    "        iterator, gt = get_stream('sea', n_samples=cfg.n_samples, drift_positions=cfg.sea_drifts or [30000,60000])\n",
    "    elif cfg.dataset.lower() in ('rbf','randomrbf','randomrbfdrift'):\n",
    "        iterator, gt = get_stream('randomrbf', n_samples=cfg.n_samples, speed=cfg.rbf_speed)\n",
    "    elif cfg.dataset.lower() in ('elec2','electricity'):\n",
    "        iterator, gt = get_stream('elec2', limit=cfg.n_samples)\n",
    "    else:\n",
    "        raise ValueError('Unsupported dataset')\n",
    "\n",
    "    model = make_classifier(cfg.classifier)\n",
    "    det = make_detector(cfg.detector)\n",
    "\n",
    "    acc = r_metrics.Accuracy(); f1 = r_metrics.F1()\n",
    "    alarms: List[int] = []; n=0\n",
    "\n",
    "    for batch in iterator:\n",
    "        n += 1\n",
    "        x, y = batch.x, batch.y\n",
    "\n",
    "        y_pred = model.predict_one(x)\n",
    "        prob_pred = None\n",
    "        if hasattr(model,'predict_proba_one') and y_pred is not None:\n",
    "            proba_dict = model.predict_proba_one(x)\n",
    "            prob_pred = proba_dict.get(y_pred, None)\n",
    "\n",
    "        if cfg.detector.lower()=='kswin' and prob_pred is not None:\n",
    "            if update_univariate(det, float(prob_pred)): alarms.append(n)\n",
    "        else:\n",
    "            err01 = 1 if (y_pred is None or y_pred != y) else 0\n",
    "            if update_supervised(det, err01): alarms.append(n)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            acc.update(y_true=y, y_pred=y)\n",
    "            f1.update(y_true=y, y_pred=y)\n",
    "\n",
    "        model.learn_one(x, y)\n",
    "        if cfg.n_samples and n >= cfg.n_samples: break\n",
    "\n",
    "    out: Dict[str, Any] = {\n",
    "        'dataset': cfg.dataset,\n",
    "        'detector': cfg.detector,\n",
    "        'classifier': cfg.classifier,\n",
    "        'n_seen': n,\n",
    "        'alarms': len(alarms),\n",
    "        'acc': float(acc.get() or 0.0),\n",
    "        'f1': float(f1.get() or 0.0),\n",
    "        'alarm_times': alarms,\n",
    "    }\n",
    "\n",
    "    if gt.get('drift_times'):\n",
    "        res = match_alarms_to_drifts(alarms, gt['drift_times'], cfg.max_delay)\n",
    "        out.update({'tp':res['tp'],'fp':res['fp'],'fn':res['fn'],'delays':res['delays']})\n",
    "        p = len(gt['drift_times'])\n",
    "        out['beta_score'] = float(beta_score(res['tp'], res['fp'], p, beta=cfg.beta))\n",
    "        dstats = delay_stats(res['delays']) if res['delays'] else {'mean': float('nan')}\n",
    "        out.update({f'delay_{k}': v for k,v in dstats.items()})\n",
    "        if gt.get('window_len') and 'mean' in dstats and not math.isnan(dstats['mean']):\n",
    "            out['delay_percent_mean'] = 100.0 * dstats['mean'] / float(gt['window_len'])\n",
    "    return out\n",
    "'''))\n",
    "\n",
    "print('Bootstrap done in', root.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Run batch experiments (SEA + Elec2 + RBF)\n",
    "import sys\n",
    "sys.path.append('driftlab/src')\n",
    "from driftlab.runner import RunConfig, run_once\n",
    "import pandas as pd\n",
    "\n",
    "jobs=[]\n",
    "detectors=['adwin','ddm','eddm','hddm_a','hddm_w','kswin','pagehinkley']\n",
    "\n",
    "# SEA (ground-truth drifts)\n",
    "for det in detectors:\n",
    "    res = run_once(RunConfig(dataset='sea', detector=det, n_samples=60000, sea_drifts=[20000,40000], beta=0.5, max_delay=5000))\n",
    "    res['context']='sea'; jobs.append(res)\n",
    "\n",
    "# Elec2 (real-world)\n",
    "for det in detectors:\n",
    "    res = run_once(RunConfig(dataset='elec2', detector=det, n_samples=30000))\n",
    "    res['context']='elec2'; jobs.append(res)\n",
    "\n",
    "# RandomRBFDrift (gradual)\n",
    "for det in detectors:\n",
    "    res = run_once(RunConfig(dataset='rbf', detector=det, n_samples=50000, rbf_speed=0.8))\n",
    "    res['context']='rbf'; jobs.append(res)\n",
    "\n",
    "df = pd.DataFrame(jobs)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Save raw results (CSV/Parquet)\n",
    "from pathlib import Path\n",
    "out = Path('driftlab/results/notebook_runs')\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(out/'combined.csv', index=False)\n",
    "try:\n",
    "    df.to_parquet(out/'combined.parquet', index=False)\n",
    "except Exception as e:\n",
    "    print('Parquet skipped:', e)\n",
    "out.resolve()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Visual summaries (matplotlib)\n",
    "- SEA: β-score, mean delay (% of first segment)\n",
    "- Elec2: Accuracy\n",
    "- RBF: F1\n",
    "\n",
    "_Rule_: one chart per figure; no manual colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sea = df[df['context']=='sea'].copy().sort_values('beta_score', ascending=False)\n",
    "plt.figure(); plt.bar(sea['detector'], sea['beta_score'].fillna(0)); plt.title('SEA: β-score'); plt.xlabel('Detector'); plt.ylabel('β-score'); plt.xticks(rotation=45); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.bar(sea['detector'], sea['delay_percent_mean'].fillna(0)); plt.title('SEA: mean delay (%)'); plt.xlabel('Detector'); plt.ylabel('delay %'); plt.xticks(rotation=45); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elec = df[df['context']=='elec2'].copy().sort_values('acc', ascending=False)\n",
    "plt.figure(); plt.bar(elec['detector'], elec['acc'].fillna(0)); plt.title('Elec2: Accuracy'); plt.xlabel('Detector'); plt.ylabel('Accuracy'); plt.xticks(rotation=45); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = df[df['context']=='rbf'].copy().sort_values('f1', ascending=False)\n",
    "plt.figure(); plt.bar(rbf['detector'], rbf['f1'].fillna(0)); plt.title('RBF: F1'); plt.xlabel('Detector'); plt.ylabel('F1'); plt.xticks(rotation=45); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Aggregate metrics: F1@AR & Accuracy@AR (plus normalized Global Scores)\n",
    "**Alarm Rate** per 10k samples: $AR = (\\#\\text{alarms}/N)\\times 10^4$.  \n",
    "**F1@AR**: $F1 - \\lambda \\cdot AR$ (default $\\lambda=0.01$).  \n",
    "**Accuracy@AR**: $Acc - \\lambda_{acc} \\cdot AR$ (default $\\lambda_{acc}=0.01$).  \n",
    "Chuẩn hoá min–max riêng trên từng dataset, sau đó macro-average qua datasets → GlobalScore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "LAMBDA_F1 = 0.01\n",
    "LAMBDA_ACC = 0.01\n",
    "\n",
    "dfm = df.copy()\n",
    "dfm['AR_per10k'] = dfm['alarms'] / dfm['n_seen'] * 1e4\n",
    "dfm['F1@AR'] = dfm['f1'] - LAMBDA_F1 * dfm['AR_per10k']\n",
    "dfm['Acc@AR'] = dfm['acc'] - LAMBDA_ACC * dfm['AR_per10k']\n",
    "\n",
    "def _minmax(s):\n",
    "    mx, mn = s.max(), s.min()\n",
    "    return (s - mn) / (mx - mn) if mx > mn else 1.0\n",
    "\n",
    "dfm['F1@AR_norm']  = dfm.groupby('dataset')['F1@AR'].transform(_minmax)\n",
    "dfm['Acc@AR_norm'] = dfm.groupby('dataset')['Acc@AR'].transform(_minmax)\n",
    "\n",
    "global_f1ar  = dfm.groupby('detector')['F1@AR_norm'].mean().sort_values(ascending=False).rename('GlobalScore_F1@AR')\n",
    "global_accar = dfm.groupby('detector')['Acc@AR_norm'].mean().sort_values(ascending=False).rename('GlobalScore_Acc@AR')\n",
    "\n",
    "display(global_f1ar.to_frame())\n",
    "display(global_accar.to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Export report tables\n",
    "from pathlib import Path\n",
    "report_dir = Path('driftlab/results/report')\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(report_dir/'raw_combined.csv', index=False)\n",
    "dfm.to_csv(report_dir/'with_F1@AR_and_Acc@AR.csv', index=False)\n",
    "global_f1ar.to_csv(report_dir/'global_F1@AR_scores.csv')\n",
    "global_accar.to_csv(report_dir/'global_Acc@AR_scores.csv')\n",
    "print('Saved to', report_dir.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
